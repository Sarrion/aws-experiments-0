{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ec2-user/SageMaker')\n",
    "from toniutils import dirtoni as dirt\n",
    "from toniutils import printoni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Load Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from script import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'engineered_data/experiment-1/'\n",
    "X_train, X_val, Y_train, Y_val = [load(path + i + '.pkl') for i in ('X_train', 'X_val', 'Y_train', 'Y_val')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import float32 as fl32\n",
    "from tensorflow import random_normal as rnorm\n",
    "from tensorflow import matmul, add\n",
    "from tensorflow.nn import relu,dropout, tanh\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(shape = [batch_size, X_train.shape[1]], dtype = fl32)\n",
    "labels = tf.placeholder(shape = [batch_size, Y_train.shape[1]], dtype = fl32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = tf.Variable(rnorm(shape = [inputs.shape[1].value, 110], dtype = fl32, stddev = 0.1))\n",
    "b1 = tf.Variable(rnorm(shape = [110,], dtype = fl32, stddev = 0.1))\n",
    "layer1 = dropout( relu(add(matmul(inputs, w1), b1)), rate = 0.1 )\n",
    "\n",
    "w2 = tf.Variable(rnorm(shape = [layer1.shape[1].value, 220], dtype = fl32, stddev= 0.1))\n",
    "b2 = tf.Variable(rnorm(shape = [220,], dtype = fl32, stddev = 0.1))\n",
    "layer2 = dropout( relu(add(matmul(layer1, w2), b2)), rate = 0.1)\n",
    "\n",
    "w3 = tf.Variable(rnorm(shape = [layer2.shape[1].value, 220], dtype = fl32, stddev= 0.1))\n",
    "b3 = tf.Variable(rnorm(shape = [220,], dtype = fl32, stddev = 0.1))\n",
    "layer3 = dropout( relu(add(matmul(layer2, w3), b3)), rate = 0.1)\n",
    "\n",
    "w4 = tf.Variable(rnorm(shape = [layer2.shape[1].value, 80], dtype = fl32, stddev= 0.1))\n",
    "b4 = tf.Variable(rnorm(shape = [80,], dtype = fl32, stddev = 0.1))\n",
    "layer4 = add(matmul(layer3, w4), b4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.squared_difference(layer4, labels))\n",
    "loss_minimize = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ec2-user/SageMaker')\n",
    "from toniutils import printoni\n",
    "from toniutils import dirtoni as dirt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0  -  val_loss: 0.016237834\n",
      "Epoch: 1  -  val_loss: 0.013941424\n",
      "Epoch: 2  -  val_loss: 0.013412267\n",
      "Epoch: 3  -  val_loss: 0.013136976\n",
      "Epoch: 4  -  val_loss: 0.01303724\n",
      "Epoch: 5  -  val_loss: 0.0130083\n",
      "Epoch: 6  -  val_loss: 0.012979036\n",
      "Epoch: 7  -  val_loss: 0.012879997\n",
      "Epoch: 8  -  val_loss: 0.012906579\n",
      "Epoch: 9  -  val_loss: 0.01278243\n",
      "Epoch: 10  -  val_loss: 0.012797449\n",
      "Epoch: 11  -  val_loss: 0.012765304\n",
      "Epoch: 12  -  val_loss: 0.012699827\n",
      "Epoch: 13  -  val_loss: 0.012660201\n",
      "Epoch: 14  -  val_loss: 0.012716565\n",
      "Epoch: 15  -  val_loss: 0.012711213\n",
      "Epoch: 16  -  val_loss: 0.012649954\n",
      "Epoch: 17  -  val_loss: 0.012678682\n",
      "Epoch: 18  -  val_loss: 0.012641259\n",
      "Epoch: 19  -  val_loss: 0.012662327\n",
      "Epoch: 20  -  val_loss: 0.012647987\n",
      "Epoch: 21  -  val_loss: 0.01257734\n",
      "Epoch: 22  -  val_loss: 0.012599329\n",
      "Epoch: 23  -  val_loss: 0.012608099\n",
      "Epoch: 24  -  val_loss: 0.01258644\n",
      "Epoch: 25  -  val_loss: 0.0126145985\n",
      "Epoch: 26  -  val_loss: 0.012616522\n",
      "Epoch: 27  -  val_loss: 0.012562053\n",
      "Epoch: 28  -  val_loss: 0.012524166\n",
      "Epoch: 29  -  val_loss: 0.012577384\n",
      "Epoch: 30  -  val_loss: 0.0125394305\n",
      "Epoch: 31  -  val_loss: 0.012530668\n",
      "Epoch: 32  -  val_loss: 0.012596619\n",
      "Epoch: 33  -  val_loss: 0.012587731\n",
      "Epoch: 34  -  val_loss: 0.01252863\n",
      "Epoch: 35  -  val_loss: 0.012533326\n",
      "Epoch: 36  -  val_loss: 0.01254704\n",
      "Epoch: 37  -  val_loss: 0.012575449\n",
      "Epoch: 38  -  val_loss: 0.012536137\n",
      "Epoch: 39  -  val_loss: 0.012538796\n",
      "Epoch: 40  -  val_loss: 0.012530101\n",
      "Epoch: 41  -  val_loss: 0.012500669\n",
      "Epoch: 42  -  val_loss: 0.012562427\n",
      "Epoch: 43  -  val_loss: 0.012479743\n",
      "Epoch: 44  -  val_loss: 0.012513804\n",
      "Epoch: 45  -  val_loss: 0.012495973\n",
      "Epoch: 46  -  val_loss: 0.012538615\n",
      "Epoch: 47  -  val_loss: 0.012561003\n",
      "Epoch: 48  -  val_loss: 0.012559353\n",
      "Epoch: 49  -  val_loss: 0.012564772\n",
      "Epoch: 50  -  val_loss: 0.012504992\n",
      "Epoch: 51  -  val_loss: 0.012559944\n",
      "Epoch: 52  -  val_loss: 0.012526323\n",
      "Epoch: 53  -  val_loss: 0.0125318235\n",
      "Epoch: 54  -  val_loss: 0.01247642\n",
      "Epoch: 55  -  val_loss: 0.012546673\n",
      "Epoch: 56  -  val_loss: 0.012485463\n",
      "Epoch: 57  -  val_loss: 0.012523308\n",
      "Epoch: 58  -  val_loss: 0.012550031\n",
      "Epoch: 59  -  val_loss: 0.012489652\n",
      "Epoch: 60  -  val_loss: 0.012574433\n",
      "Epoch: 61  -  val_loss: 0.01247299\n",
      "Epoch: 62  -  val_loss: 0.012492391\n",
      "Epoch: 63  -  val_loss: 0.012527347\n",
      "Epoch: 64  -  val_loss: 0.012520236\n",
      "Epoch: 65  -  val_loss: 0.012469456\n",
      "Epoch: 66  -  val_loss: 0.01256606\n",
      "Epoch: 67  -  val_loss: 0.012490757\n",
      "Epoch: 68  -  val_loss: 0.01243867\n",
      "Epoch: 69  -  val_loss: 0.012422026\n",
      "Epoch: 70  -  val_loss: 0.0124455495\n",
      "Epoch: 71  -  val_loss: 0.012455114\n",
      "Epoch: 72  -  val_loss: 0.012419425\n",
      "Epoch: 73  -  val_loss: 0.01250049\n",
      "Epoch: 74  -  val_loss: 0.0124790305\n",
      "Epoch: 75  -  val_loss: 0.0125701465\n",
      "Epoch: 76  -  val_loss: 0.012438585\n",
      "Epoch: 77  -  val_loss: 0.0124753155\n",
      "Epoch: 78  -  val_loss: 0.012456106\n",
      "Epoch: 79  -  val_loss: 0.012442266\n",
      "Epoch: 80  -  val_loss: 0.0124734305\n",
      "Epoch: 81  -  val_loss: 0.012461687\n",
      "Epoch: 82  -  val_loss: 0.012450754\n",
      "Epoch: 83  -  val_loss: 0.012512308\n",
      "Epoch: 84  -  val_loss: 0.012429987\n",
      "Epoch: 85  -  val_loss: 0.012461123\n",
      "Epoch: 86  -  val_loss: 0.012462258\n",
      "Epoch: 87  -  val_loss: 0.0124285305\n",
      "Epoch: 88  -  val_loss: 0.012456462\n",
      "Epoch: 89  -  val_loss: 0.012450266\n",
      "Epoch: 90  -  val_loss: 0.012489393\n",
      "Epoch: 91  -  val_loss: 0.012468838\n",
      "Epoch: 92  -  val_loss: 0.012414705\n",
      "Epoch: 93  -  val_loss: 0.01240609\n",
      "Epoch: 94  -  val_loss: 0.012530234\n",
      "Epoch: 95  -  val_loss: 0.012411536\n",
      "Epoch: 96  -  val_loss: 0.012454425\n",
      "Epoch: 97  -  val_loss: 0.012487706\n",
      "Epoch: 98  -  val_loss: 0.012463222\n",
      "Epoch: 99  -  val_loss: 0.012415498\n",
      "Epoch: 100  -  val_loss: 0.0124115385\n",
      "Epoch: 101  -  val_loss: 0.012438791\n",
      "Epoch: 102  -  val_loss: 0.012483068\n",
      "Epoch: 103  -  val_loss: 0.012461389\n",
      "Epoch: 104  -  val_loss: 0.012445537\n",
      "Epoch: 105  -  val_loss: 0.012419838\n",
      "Epoch: 106  -  val_loss: 0.0125054475\n",
      "Epoch: 107  -  val_loss: 0.012449547\n",
      "Epoch: 108  -  val_loss: 0.012404603\n",
      "Epoch: 109  -  val_loss: 0.012447616\n",
      "Epoch: 110  -  val_loss: 0.012434613\n",
      "Epoch: 111  -  val_loss: 0.012521669\n",
      "Epoch: 112  -  val_loss: 0.012455978\n",
      "Epoch: 113  -  val_loss: 0.012554237\n",
      "Epoch: 114  -  val_loss: 0.012422102\n",
      "Epoch: 115  -  val_loss: 0.012424152\n",
      "Epoch: 116  -  val_loss: 0.012441705\n",
      "Epoch: 117  -  val_loss: 0.012493703\n",
      "Epoch: 118  -  val_loss: 0.01247721\n",
      "Epoch: 119  -  val_loss: 0.012403579\n",
      "Epoch: 120  -  val_loss: 0.012508856\n",
      "Epoch: 121  -  val_loss: 0.012427894\n",
      "Epoch: 122  -  val_loss: 0.012447412\n",
      "Epoch: 123  -  val_loss: 0.012444165\n",
      "Epoch: 124  -  val_loss: 0.012441513\n",
      "Epoch: 125  -  val_loss: 0.012477369\n",
      "Epoch: 126  -  val_loss: 0.01244823\n",
      "Epoch: 127  -  val_loss: 0.01245484\n",
      "Epoch: 128  -  val_loss: 0.012475591\n",
      "Epoch: 129  -  val_loss: 0.012455145\n",
      "Epoch: 130  -  val_loss: 0.012444769\n",
      "Epoch: 131  -  val_loss: 0.01247731\n",
      "Epoch: 132  -  val_loss: 0.012446773\n",
      "Epoch: 133  -  val_loss: 0.01241556\n",
      "Epoch: 134  -  val_loss: 0.012398346\n",
      "Epoch: 135  -  val_loss: 0.012433923\n",
      "Epoch: 136  -  val_loss: 0.012443881\n",
      "Epoch: 137  -  val_loss: 0.012451283\n",
      "Epoch: 138  -  val_loss: 0.012521595\n",
      "Epoch: 139  -  val_loss: 0.01239406\n",
      "Epoch: 140  -  val_loss: 0.012461213\n",
      "Epoch: 141  -  val_loss: 0.012440424\n",
      "Epoch: 142  -  val_loss: 0.01244957\n",
      "Epoch: 143  -  val_loss: 0.012415368\n",
      "Epoch: 144  -  val_loss: 0.012456544\n",
      "Epoch: 145  -  val_loss: 0.012424593\n",
      "Epoch: 146  -  val_loss: 0.012419711\n",
      "Epoch: 147  -  val_loss: 0.012402301\n",
      "Epoch: 148  -  val_loss: 0.012419503\n",
      "Epoch: 149  -  val_loss: 0.012399973\n",
      "Epoch: 150  -  val_loss: 0.012450052\n",
      "Epoch: 151  -  val_loss: 0.012427257\n",
      "Epoch: 152  -  val_loss: 0.012458658\n",
      "Epoch: 153  -  val_loss: 0.012408087\n",
      "Epoch: 154  -  val_loss: 0.012476898\n",
      "Epoch: 155  -  val_loss: 0.012461286\n",
      "Epoch: 156  -  val_loss: 0.012385292\n",
      "Epoch: 157  -  val_loss: 0.012474574\n",
      "Epoch: 158  -  val_loss: 0.012412672\n",
      "Epoch: 159  -  val_loss: 0.012415265\n",
      "Epoch: 160  -  val_loss: 0.012525371\n",
      "Epoch: 161  -  val_loss: 0.012449764\n",
      "Epoch: 162  -  val_loss: 0.012411585\n",
      "Epoch: 163  -  val_loss: 0.012444777\n",
      "Epoch: 164  -  val_loss: 0.012366557\n",
      "Epoch: 165  -  val_loss: 0.012446089\n",
      "Epoch: 166  -  val_loss: 0.012487473\n",
      "Epoch: 167  -  val_loss: 0.012470988\n",
      "Epoch: 168  -  val_loss: 0.012400135\n",
      "Epoch: 169  -  val_loss: 0.012464502\n",
      "Epoch: 170  -  val_loss: 0.01249793\n",
      "Epoch: 171  -  val_loss: 0.012448266\n",
      "Epoch: 172  -  val_loss: 0.012453313\n",
      "Epoch: 173  -  val_loss: 0.012434319\n",
      "Epoch: 174  -  val_loss: 0.012410602\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(200):\n",
    "    for i in range(X_train.shape[0] // batch_size):\n",
    "        sess.run([loss, loss_minimize], \n",
    "                 feed_dict = {inputs: X_train[i * batch_size:(i + 1)*batch_size, :],\n",
    "                              labels: Y_train[i * batch_size:(i + 1)*batch_size, :]})\n",
    "\n",
    "    test_loss = []   \n",
    "    for i in range(X_val.shape[0] // batch_size):\n",
    "        new_loss,_ = sess.run([loss, loss_minimize], \n",
    "                 feed_dict = {inputs: X_val[i * batch_size:(i + 1)*batch_size, :],\n",
    "                              labels: Y_val[i * batch_size:(i + 1)*batch_size, :]})\n",
    "        test_loss.append(new_loss)\n",
    "\n",
    "    import numpy as np\n",
    "    mean_test_loss = np.array(test_loss).mean()\n",
    "    print('Epoch: ' + str(epoch) + '  -  val_loss: ' + str(mean_test_loss))\n",
    "\n",
    "print(sess.graph)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013327003"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0135560045"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012763917"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Save Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 4205122772179942051, name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 8769741372308327298\n",
       " physical_device_desc: \"device: XLA_CPU device\"]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.io.write_graph(sess.graph, '/tmp/my-model', 'train.pbtxt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
