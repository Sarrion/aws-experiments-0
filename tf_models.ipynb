{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ec2-user/SageMaker')\n",
    "from toniutils import dirtoni as dirt\n",
    "from toniutils import printoni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Load Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from script import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'engineered_data/experiment-1/'\n",
    "X_train, X_val, Y_train, Y_val = [load(path + i + '.pkl') for i in ('X_train', 'X_val', 'Y_train', 'Y_val')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 2192605589297615704, name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 10943925773535420515\n",
       " physical_device_desc: \"device: XLA_CPU device\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import float32 as fl32\n",
    "from tensorflow import random_normal as rnorm\n",
    "from tensorflow import matmul, add\n",
    "from tensorflow.nn import relu,dropout, tanh\n",
    "from tensorflow.initializers import he_uniform, glorot_uniform\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(shape = [batch_size, X_train.shape[1]], dtype = fl32)\n",
    "labels = tf.placeholder(shape = [batch_size, Y_train.shape[1]], dtype = fl32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constant         identity        random_normal        variance_scaling \n",
      "global_variables lecun_normal    random_uniform       zeros            \n",
      "glorot_normal    lecun_uniform   tables_initializer                    \n",
      "glorot_uniform   local_variables truncated_normal                      \n",
      "he_normal        ones            uniform_unit_scaling                  \n",
      "he_uniform       orthogonal      variables                             \n"
     ]
    }
   ],
   "source": [
    "printoni(dirt(tf.initializers), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('l1', reuse = tf.AUTO_REUSE):\n",
    "    w1 = tf.get_variable('w1', [inputs.shape[1].value, 110], initializer = he_uniform())\n",
    "    b1 = tf.get_variable('b1', [110,], initializer = tf.initializers.zeros)\n",
    "    layer1 = dropout( relu(add(matmul(inputs, w1), b1), name = 'relu'), rate = 0.1 )\n",
    "\n",
    "with tf.variable_scope('l2', reuse = tf.AUTO_REUSE):\n",
    "    w2 = tf.get_variable('w2', [layer1.shape[1].value, 220], initializer = he_uniform())\n",
    "    b2 = tf.get_variable('b2', [220,], initializer = tf.initializers.zeros)\n",
    "    layer2 = dropout( relu(add(matmul(layer1, w2), b2), name = 'relu'), rate = 0.1)\n",
    "\n",
    "with tf.variable_scope('l3', reuse = tf.AUTO_REUSE):\n",
    "    w3 = tf.get_variable('w3', [layer2.shape[1].value, 220], initializer = he_uniform())\n",
    "    b3 = tf.get_variable('b3', [220,], initializer = tf.initializers.zeros)\n",
    "    layer3 = dropout( relu(add(matmul(layer2, w3), b3), name = 'relu'), rate = 0.1)\n",
    "    \n",
    "'''with tf.variable_scope('l4', reuse = tf.AUTO_REUSE):\n",
    "    w4 = tf.get_variable('w4', [layer3.shape[1].value, 220], initializer = he_uniform())\n",
    "    b4 = tf.get_variable('b4', [220,], initializer = tf.initializers.zeros)\n",
    "    layer4 = dropout( relu(add(matmul(layer3, w4), b4), name = 'relu'), rate = 0.1)'''\n",
    "\n",
    "with tf.variable_scope('output_layer', reuse = tf.AUTO_REUSE):\n",
    "    w_out = tf.get_variable('w_out', [layer3.shape[1].value, 80], initializer = glorot_uniform())\n",
    "    b_out = tf.get_variable('b_out', [80,], initializer = tf.initializers.zeros)\n",
    "    layer_out = add(matmul(layer3, w_out), b_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('loss', reuse = tf.AUTO_REUSE):\n",
    "    loss = tf.reduce_mean(tf.squared_difference(layer_out, labels))\n",
    "    loss_minimize = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0  -  val_loss: 0.022892792\n",
      "Epoch: 1  -  val_loss: 0.018975047\n",
      "Epoch: 2  -  val_loss: 0.017378725\n",
      "Epoch: 3  -  val_loss: 0.016166413\n",
      "Epoch: 4  -  val_loss: 0.015396588\n",
      "Epoch: 5  -  val_loss: 0.014973759\n",
      "Epoch: 6  -  val_loss: 0.014584862\n",
      "Epoch: 7  -  val_loss: 0.014343356\n",
      "Epoch: 8  -  val_loss: 0.014145414\n",
      "Epoch: 9  -  val_loss: 0.013989105\n",
      "Epoch: 10  -  val_loss: 0.013902401\n",
      "Epoch: 11  -  val_loss: 0.013754128\n",
      "Epoch: 12  -  val_loss: 0.01370909\n",
      "Epoch: 13  -  val_loss: 0.0136349145\n",
      "Epoch: 14  -  val_loss: 0.013568653\n",
      "Epoch: 15  -  val_loss: 0.013487612\n",
      "Epoch: 16  -  val_loss: 0.013475617\n",
      "Epoch: 17  -  val_loss: 0.013398917\n",
      "Epoch: 18  -  val_loss: 0.013344611\n",
      "Epoch: 19  -  val_loss: 0.013323878\n",
      "Epoch: 20  -  val_loss: 0.013275259\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(21):\n",
    "    for i in range(X_train.shape[0] // batch_size):\n",
    "        sess.run([loss, loss_minimize], \n",
    "                 feed_dict = {inputs: X_train[i * batch_size:(i + 1)*batch_size, :],\n",
    "                              labels: Y_train[i * batch_size:(i + 1)*batch_size, :]})\n",
    "\n",
    "    test_loss = []   \n",
    "    for i in range(X_val.shape[0] // batch_size):\n",
    "        new_loss,_ = sess.run([loss, loss_minimize], \n",
    "                 feed_dict = {inputs: X_val[i * batch_size:(i + 1)*batch_size, :],\n",
    "                              labels: Y_val[i * batch_size:(i + 1)*batch_size, :]})\n",
    "        test_loss.append(new_loss)\n",
    "    if epoch % 1000 == 0:\n",
    "        # Append the step number to the checkpoint name:\n",
    "        saver.save(sess, save_path = '/home/ec2-user/SageMaker/tf_models/my-model', global_step = epoch)\n",
    "    \n",
    "    mean_test_loss = np.array(test_loss).mean()\n",
    "    print('Epoch: ' + str(epoch) + '  -  val_loss: ' + str(mean_test_loss))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013327003"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0135560045"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012763917"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0126214735"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_test_loss # 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012417628"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012488576"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Save Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 4205122772179942051, name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 8769741372308327298\n",
       " physical_device_desc: \"device: XLA_CPU device\"]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.io.write_graph(sess.graph, '/tmp/my-model', 'train.pbtxt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
