{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import io\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "fs = s3fs.S3FileSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fondos       = pd.read_csv('s3://bme-bucket/asignacion_fondos.csv', nrows = 79899)\n",
    "#dinero       = pd.read_csv('s3://bme-bucket/asignacion_dinero.csv', nrows = 79899)\n",
    "perfiles     = pd.read_csv('s3://bme-bucket/perfiles_inversores.csv', nrows = 79899)\n",
    "tabla_fondos = pd.read_csv('s3://bme-bucket/tabla_fondos.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Target Engineering</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "for col in tabla_fondos.columns[2:12]:\n",
    "    if col != 'aportacion_minima':\n",
    "        tabla_fondos[col] = tabla_fondos[col].apply(lambda x: float(x[:-1])/100)\n",
    "    tabla_fondos[col] = scaler.fit_transform(tabla_fondos[col].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.zeros(shape = (1,80))\n",
    "for client_n in range(fondos.shape[0]):\n",
    "    row = np.array([])\n",
    "    for fondo in fondos.columns:\n",
    "        sp_fund = fondos[fondo][client_n]\n",
    "        if sp_fund == 'Ninguno':\n",
    "            row = np.append(row, np.zeros(shape = (1,10)))\n",
    "        else:\n",
    "            row = np.append(row,\n",
    "                tabla_fondos[tabla_fondos['Nombre fondo'] == sp_fund].iloc[:, 2:].values)\n",
    "    Y = np.vstack((Y, row.reshape((1,80))))\n",
    "\n",
    "Y = Y[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload without using disk\n",
    "my_array_data = io.BytesIO()\n",
    "pickle.dump(Y, my_array_data)\n",
    "my_array_data.seek(0)\n",
    "s3_client.upload_fileobj(my_array_data, 'bme-bucket', 'engineered_data/Y_minmaxscaled.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download without using disk\n",
    "my_array_data2 = io.BytesIO()\n",
    "s3_client.download_fileobj('bme-bucket', 'engineered_data/Y_minmaxscaled.pkl', my_array_data2)\n",
    "my_array_data2.seek(0)\n",
    "Y = pickle.load(my_array_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that everything is correct\n",
    "np.allclose(Y, Y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature engineering</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderlists = [[1,3,0,4,2],[2,1,0,3],[1,3,0,2],[2,0,1],[3,0,1,2],[0,2,1,4,3]]\n",
    "columns = [0,1,2,3,7,9]\n",
    "imputationsDict = {}\n",
    "for i in range(6):\n",
    "    differentValues = perfiles.iloc[:, columns[i]].value_counts().index.values[orderlists[i]]\n",
    "    imputedValues   = np.linspace(0, len(differentValues) - 1, len(differentValues))\n",
    "    subdict = {key:value for key, value in zip(differentValues, imputedValues)}\n",
    "    imputationsDict[perfiles.columns[columns[i]]] = subdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in imputationsDict.keys():\n",
    "    perfiles[i] = perfiles[i].apply(lambda x : imputationsDict[i][x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Some sklearn preprocessing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "for i in perfiles.columns:\n",
    "    perfiles[i] = scaler.fit_transform(perfiles[i].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = perfiles.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload without using disk\n",
    "my_array_data = io.BytesIO()\n",
    "pickle.dump(X, my_array_data)\n",
    "my_array_data.seek(0)\n",
    "s3_client.upload_fileobj(my_array_data, 'bme-bucket', 'engineered_data/X.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data split on train validation and test</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, Y, test_size=0.1, random_state=123)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload without using disk\n",
    "my_array_data = io.BytesIO()\n",
    "pickle.dump(X_train, my_array_data)\n",
    "my_array_data.seek(0)\n",
    "s3_client.upload_fileobj(my_array_data, 'bme-bucket', 'engineered_data/experiment-1/X_train.pkl')\n",
    "\n",
    "my_array_data = io.BytesIO()\n",
    "pickle.dump(X_test, my_array_data)\n",
    "my_array_data.seek(0)\n",
    "s3_client.upload_fileobj(my_array_data, 'bme-bucket', 'engineered_data/experiment-1/X_test.pkl')\n",
    "\n",
    "my_array_data = io.BytesIO()\n",
    "pickle.dump(X_val, my_array_data)\n",
    "my_array_data.seek(0)\n",
    "s3_client.upload_fileobj(my_array_data, 'bme-bucket', 'engineered_data/experiment-1/X_val.pkl')\n",
    "\n",
    "my_array_data = io.BytesIO()\n",
    "pickle.dump(y_train, my_array_data)\n",
    "my_array_data.seek(0)\n",
    "s3_client.upload_fileobj(my_array_data, 'bme-bucket', 'engineered_data/experiment-1/Y_train.pkl')\n",
    "\n",
    "my_array_data = io.BytesIO()\n",
    "pickle.dump(y_test, my_array_data)\n",
    "my_array_data.seek(0)\n",
    "s3_client.upload_fileobj(my_array_data, 'bme-bucket', 'engineered_data/experiment-1/Y_test.pkl')\n",
    "\n",
    "my_array_data = io.BytesIO()\n",
    "pickle.dump(y_val, my_array_data)\n",
    "my_array_data.seek(0)\n",
    "s3_client.upload_fileobj(my_array_data, 'bme-bucket', 'engineered_data/experiment-1/Y_val.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
