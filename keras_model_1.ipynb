{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
      "\u001b[K    100% |████████████████████████████████| 378kB 24.2MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from keras) (2.8.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from keras) (3.12)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from keras) (1.14.3)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from keras) (1.11.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from keras) (1.1.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.3.1\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Load Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from script import load as download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = [download('engineered_data/experiment-1/' + i + '.pkl') for i in ('X_train', 'X_val', 'Y_train', 'Y_val')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train Models</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_1st_layer = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network\n",
    "models_1st_layer['model-1'] = Sequential()\n",
    "models_1st_layer['model-1'].add(Dense(110, activation='relu'))\n",
    "models_1st_layer['model-1'].add(Dropout(0.2))\n",
    "models_1st_layer['model-1'].add(Dense(80, activation = 'softmax'))\n",
    "models_1st_layer['model-1'].compile(loss='mse', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "models_1st_layer['model-2'] = Sequential()\n",
    "models_1st_layer['model-2'].add(Dense(110, activation='relu'))\n",
    "models_1st_layer['model-2'].add(Dropout(0.2))\n",
    "models_1st_layer['model-2'].add(Dense(110, activation='relu'))\n",
    "models_1st_layer['model-2'].add(Dropout(0.2))\n",
    "models_1st_layer['model-2'].add(Dense(80, activation = 'softmax'))\n",
    "models_1st_layer['model-2'].compile(loss='mse', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "models_1st_layer['model-3'] = Sequential()\n",
    "models_1st_layer['model-3'].add(Dense(110, activation='softmax'))\n",
    "models_1st_layer['model-3'].add(Dropout(0.2))\n",
    "models_1st_layer['model-3'].add(Dense(80, activation = 'softmax'))\n",
    "models_1st_layer['model-3'].compile(loss='mse', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "models_1st_layer['model-4'] = Sequential()\n",
    "models_1st_layer['model-4'].add(Dense(110, activation='relu'))\n",
    "models_1st_layer['model-4'].add(Dropout(0.2))\n",
    "models_1st_layer['model-4'].add(Dense(110, activation='relu'))\n",
    "models_1st_layer['model-4'].add(Dropout(0.2))\n",
    "models_1st_layer['model-4'].add(Dense(110, activation='relu'))\n",
    "models_1st_layer['model-4'].add(Dropout(0.2))\n",
    "models_1st_layer['model-4'].add(Dense(80, activation = 'softmax'))\n",
    "models_1st_layer['model-4'].compile(loss='mse', optimizer='sgd', metrics = ['accuracy'])\n",
    "\n",
    "models_1st_layer['model-5'] = Sequential()\n",
    "models_1st_layer['model-5'].add(Dense(110, activation='relu'))\n",
    "models_1st_layer['model-5'].add(Dropout(0.2))\n",
    "models_1st_layer['model-5'].add(Dense(110, activation='relu'))\n",
    "models_1st_layer['model-5'].add(Dropout(0.2))\n",
    "models_1st_layer['model-5'].add(Dense(110, activation='relu'))\n",
    "models_1st_layer['model-5'].add(Dropout(0.2))\n",
    "models_1st_layer['model-5'].add(Dense(80, activation = 'softmax'))\n",
    "models_1st_layer['model-5'].compile(loss='mse', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "models_1st_layer['model-6'] = Sequential()\n",
    "models_1st_layer['model-6'].add(Dense(550, activation='relu'))\n",
    "models_1st_layer['model-6'].add(Dropout(0.2))\n",
    "models_1st_layer['model-6'].add(Dense(550, activation='relu'))\n",
    "models_1st_layer['model-6'].add(Dropout(0.2))\n",
    "models_1st_layer['model-6'].add(Dense(110, activation='relu'))\n",
    "models_1st_layer['model-6'].add(Dropout(0.2))\n",
    "models_1st_layer['model-6'].add(Dense(80, activation = 'softmax'))\n",
    "models_1st_layer['model-6'].compile(loss='mse', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "models_1st_layer['model-7'] = Sequential()\n",
    "models_1st_layer['model-7'].add(Dense(110, activation='relu'))\n",
    "models_1st_layer['model-7'].add(Dropout(0.2))\n",
    "models_1st_layer['model-7'].add(Dense(110, activation='softmax'))\n",
    "models_1st_layer['model-7'].add(Dropout(0.2))\n",
    "models_1st_layer['model-7'].add(Dense(110, activation='relu'))\n",
    "models_1st_layer['model-7'].add(Dropout(0.2))\n",
    "models_1st_layer['model-7'].add(Dense(80, activation = 'softmax'))\n",
    "models_1st_layer['model-7'].compile(loss='mse', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "models_1st_layer['model-8'] = Sequential()\n",
    "models_1st_layer['model-8'].add(Dense(1100, activation='relu'))\n",
    "models_1st_layer['model-8'].add(Dropout(0.2))\n",
    "models_1st_layer['model-8'].add(Dense(110, activation='relu'))\n",
    "models_1st_layer['model-8'].add(Dropout(0.2))\n",
    "models_1st_layer['model-8'].add(Dense(80, activation = 'softmax'))\n",
    "models_1st_layer['model-8'].compile(loss='mse', optimizer='adam', metrics = ['accuracy'])\n",
    "                                    \n",
    "models_1st_layer['model-9'] = Sequential()\n",
    "models_1st_layer['model-9'].add(Dense(110, activation='relu'))\n",
    "models_1st_layer['model-9'].add(Dropout(0.2))\n",
    "models_1st_layer['model-9'].add(Dense(1100, activation='relu'))\n",
    "models_1st_layer['model-9'].add(Dropout(0.2))\n",
    "models_1st_layer['model-9'].add(Dense(80, activation = 'softmax'))\n",
    "models_1st_layer['model-9'].compile(loss='mse', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "models_1st_layer['model-10'] = Sequential()\n",
    "models_1st_layer['model-10'].add(Dense(110, activation='relu'))\n",
    "models_1st_layer['model-10'].add(Dropout(0.2))\n",
    "models_1st_layer['model-10'].add(Dense(55, activation='relu'))\n",
    "models_1st_layer['model-10'].add(Dropout(0.2))\n",
    "models_1st_layer['model-10'].add(Dense(55, activation='relu'))\n",
    "models_1st_layer['model-10'].add(Dropout(0.2))\n",
    "models_1st_layer['model-10'].add(Dense(55, activation='relu'))\n",
    "models_1st_layer['model-10'].add(Dropout(0.2))\n",
    "models_1st_layer['model-10'].add(Dense(55, activation='relu'))\n",
    "models_1st_layer['model-10'].add(Dropout(0.2))\n",
    "models_1st_layer['model-10'].add(Dense(80, activation = 'softmax'))\n",
    "models_1st_layer['model-10'].compile(loss='mse', optimizer='adam', metrics = ['accuracy'])\n",
    "                 \n",
    "models_1st_layer['model-11'] = Sequential()\n",
    "models_1st_layer['model-11'].add(Dense(110, activation='relu'))\n",
    "models_1st_layer['model-11'].add(Dropout(0.2))\n",
    "models_1st_layer['model-11'].add(Dense(55, activation='relu'))\n",
    "models_1st_layer['model-11'].add(Dropout(0.2))\n",
    "models_1st_layer['model-11'].add(Dense(55, activation='relu'))\n",
    "models_1st_layer['model-11'].add(Dropout(0.2))\n",
    "models_1st_layer['model-11'].add(Dense(55, activation='relu'))\n",
    "models_1st_layer['model-11'].add(Dropout(0.2))\n",
    "models_1st_layer['model-11'].add(Dense(55, activation='relu'))\n",
    "models_1st_layer['model-11'].add(Dropout(0.2))\n",
    "models_1st_layer['model-11'].add(Dense(80, activation = 'sigmoid'))\n",
    "models_1st_layer['model-11'].compile(loss='mse', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "models_1st_layer['model-12'] = Sequential()\n",
    "models_1st_layer['model-12'].add(Dense(110, activation='relu'))\n",
    "models_1st_layer['model-12'].add(Dropout(0.2))\n",
    "models_1st_layer['model-12'].add(Dense(55, activation='relu'))\n",
    "models_1st_layer['model-12'].add(Dropout(0.2))\n",
    "models_1st_layer['model-12'].add(Dense(55, activation='softmax'))\n",
    "models_1st_layer['model-12'].add(Dropout(0.2))\n",
    "models_1st_layer['model-12'].add(Dense(55, activation='relu'))\n",
    "models_1st_layer['model-12'].add(Dropout(0.2))\n",
    "models_1st_layer['model-12'].add(Dense(55, activation='relu'))\n",
    "models_1st_layer['model-12'].add(Dropout(0.2))\n",
    "models_1st_layer['model-12'].add(Dense(80, activation = 'sigmoid'))\n",
    "models_1st_layer['model-12'].compile(loss='mse', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "models_1st_layer['model-13'] = Sequential()\n",
    "models_1st_layer['model-13'].add(Dense(110, activation='relu'))\n",
    "models_1st_layer['model-13'].add(Dropout(0.2))\n",
    "models_1st_layer['model-13'].add(Dense(55, activation='relu'))\n",
    "models_1st_layer['model-13'].add(Dropout(0.2))\n",
    "models_1st_layer['model-13'].add(Dense(55, activation='sigmoid'))\n",
    "models_1st_layer['model-13'].add(Dropout(0.2))\n",
    "models_1st_layer['model-13'].add(Dense(55, activation='relu'))\n",
    "models_1st_layer['model-13'].add(Dropout(0.2))\n",
    "models_1st_layer['model-13'].add(Dense(55, activation='relu'))\n",
    "models_1st_layer['model-13'].add(Dropout(0.2))\n",
    "models_1st_layer['model-13'].add(Dense(80, activation = 'softmax'))\n",
    "models_1st_layer['model-13'].compile(loss='mse', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "models_1st_layer['model-14'] = Sequential()\n",
    "models_1st_layer['model-14'].add(Dense(110, activation='sigmoid'))\n",
    "models_1st_layer['model-14'].add(Dropout(0.2))\n",
    "models_1st_layer['model-14'].add(Dense(110, activation='sigmoid'))\n",
    "models_1st_layer['model-14'].add(Dropout(0.2))\n",
    "models_1st_layer['model-14'].add(Dense(110, activation='softmax'))\n",
    "models_1st_layer['model-14'].add(Dropout(0.2))\n",
    "models_1st_layer['model-14'].add(Dense(80, activation = 'sigmoid'))\n",
    "models_1st_layer['model-14'].compile(loss='mse', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "models_1st_layer['model-15'] = Sequential()\n",
    "models_1st_layer['model-15'].add(Dense(110, activation='relu'))\n",
    "models_1st_layer['model-15'].add(Dropout(0.2))\n",
    "models_1st_layer['model-15'].add(Dense(110, activation='sigmoid'))\n",
    "models_1st_layer['model-15'].add(Dropout(0.2))\n",
    "models_1st_layer['model-15'].add(Dense(110, activation='sigmoid'))\n",
    "models_1st_layer['model-15'].add(Dropout(0.2))\n",
    "models_1st_layer['model-15'].add(Dense(80, activation = 'softmax'))\n",
    "models_1st_layer['model-15'].compile(loss='mse', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "models_1st_layer['model-16'] = Sequential()\n",
    "models_1st_layer['model-16'].add(Dense(110, activation='relu'))\n",
    "models_1st_layer['model-16'].add(Dropout(0.2))\n",
    "models_1st_layer['model-16'].add(Dense(110, activation='relu'))\n",
    "models_1st_layer['model-16'].add(Dropout(0.2))\n",
    "models_1st_layer['model-16'].add(Dense(110, activation='softmax'))\n",
    "models_1st_layer['model-16'].add(Dropout(0.2))\n",
    "models_1st_layer['model-16'].add(Dense(80, activation = 'linear'))\n",
    "models_1st_layer['model-16'].compile(loss='mse', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "models_1st_layer['model-17'] = Sequential()\n",
    "models_1st_layer['model-17'].add(Dense(110, activation='relu'))\n",
    "models_1st_layer['model-17'].add(Dropout(0.2))\n",
    "models_1st_layer['model-17'].add(Dense(220, activation='relu'))\n",
    "models_1st_layer['model-17'].add(Dropout(0.2))\n",
    "models_1st_layer['model-17'].add(Dense(80, activation = 'linear'))\n",
    "models_1st_layer['model-17'].compile(loss='mse', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "models_1st_layer['model-18'] = Sequential()\n",
    "models_1st_layer['model-18'].add(Dense(110, activation='relu'))\n",
    "models_1st_layer['model-18'].add(Dropout(0.1))\n",
    "models_1st_layer['model-18'].add(Dense(220, activation='relu'))\n",
    "models_1st_layer['model-18'].add(Dropout(0.1))\n",
    "models_1st_layer['model-18'].add(Dense(80, activation = 'linear'))\n",
    "models_1st_layer['model-18'].compile(loss='mse', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model-1\n",
      "Train on 57527 samples, validate on 14382 samples\n",
      "Epoch 1/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1443 - accuracy: 0.1668 - val_loss: 0.1429 - val_accuracy: 0.1793\n",
      "Epoch 2/100\n",
      "57527/57527 [==============================] - 3s 47us/step - loss: 0.1432 - accuracy: 0.1588 - val_loss: 0.1427 - val_accuracy: 0.1740\n",
      "Epoch 3/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1430 - accuracy: 0.1588 - val_loss: 0.1425 - val_accuracy: 0.1959\n",
      "Epoch 4/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1429 - accuracy: 0.1664 - val_loss: 0.1425 - val_accuracy: 0.1784\n",
      "Epoch 5/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1429 - accuracy: 0.1731 - val_loss: 0.1424 - val_accuracy: 0.1848\n",
      "Epoch 6/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1429 - accuracy: 0.1750 - val_loss: 0.1424 - val_accuracy: 0.2012\n",
      "Epoch 7/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1428 - accuracy: 0.1774 - val_loss: 0.1424 - val_accuracy: 0.2068\n",
      "Epoch 8/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1428 - accuracy: 0.1808 - val_loss: 0.1424 - val_accuracy: 0.1920\n",
      "Epoch 9/100\n",
      "57527/57527 [==============================] - 3s 47us/step - loss: 0.1428 - accuracy: 0.1798 - val_loss: 0.1423 - val_accuracy: 0.1952\n",
      "Epoch 10/100\n",
      "57527/57527 [==============================] - 3s 47us/step - loss: 0.1428 - accuracy: 0.1814 - val_loss: 0.1423 - val_accuracy: 0.1624\n",
      "Epoch 11/100\n",
      "57527/57527 [==============================] - 3s 47us/step - loss: 0.1428 - accuracy: 0.1805 - val_loss: 0.1423 - val_accuracy: 0.2089\n",
      "Epoch 12/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1428 - accuracy: 0.1837 - val_loss: 0.1423 - val_accuracy: 0.1888\n",
      "Epoch 13/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1858 - val_loss: 0.1423 - val_accuracy: 0.1797\n",
      "Epoch 14/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1854 - val_loss: 0.1423 - val_accuracy: 0.2108\n",
      "Epoch 15/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1865 - val_loss: 0.1423 - val_accuracy: 0.1672\n",
      "Epoch 16/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1878 - val_loss: 0.1423 - val_accuracy: 0.2219\n",
      "Epoch 17/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1894 - val_loss: 0.1423 - val_accuracy: 0.2082\n",
      "Epoch 18/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1895 - val_loss: 0.1423 - val_accuracy: 0.1942\n",
      "Epoch 19/100\n",
      "57527/57527 [==============================] - 3s 47us/step - loss: 0.1427 - accuracy: 0.1871 - val_loss: 0.1423 - val_accuracy: 0.2064\n",
      "Epoch 20/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1915 - val_loss: 0.1423 - val_accuracy: 0.2132\n",
      "Epoch 21/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1890 - val_loss: 0.1423 - val_accuracy: 0.1872\n",
      "Epoch 22/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1902 - val_loss: 0.1423 - val_accuracy: 0.1980\n",
      "Epoch 23/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1908 - val_loss: 0.1423 - val_accuracy: 0.1975\n",
      "Epoch 24/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1896 - val_loss: 0.1423 - val_accuracy: 0.2130\n",
      "Epoch 25/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1904 - val_loss: 0.1423 - val_accuracy: 0.1895\n",
      "Epoch 26/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1878 - val_loss: 0.1423 - val_accuracy: 0.1963\n",
      "Epoch 27/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1928 - val_loss: 0.1423 - val_accuracy: 0.1996\n",
      "Epoch 28/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1905 - val_loss: 0.1423 - val_accuracy: 0.2107\n",
      "Epoch 29/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1924 - val_loss: 0.1423 - val_accuracy: 0.1991\n",
      "Epoch 30/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1886 - val_loss: 0.1423 - val_accuracy: 0.1957\n",
      "Epoch 31/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1427 - accuracy: 0.1879 - val_loss: 0.1423 - val_accuracy: 0.2096\n",
      "Epoch 32/100\n",
      "57527/57527 [==============================] - 3s 50us/step - loss: 0.1427 - accuracy: 0.1930 - val_loss: 0.1423 - val_accuracy: 0.2081\n",
      "Epoch 33/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1920 - val_loss: 0.1423 - val_accuracy: 0.2061\n",
      "Epoch 34/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1939 - val_loss: 0.1423 - val_accuracy: 0.2245\n",
      "Epoch 35/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1921 - val_loss: 0.1423 - val_accuracy: 0.1455\n",
      "Epoch 36/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1951 - val_loss: 0.1423 - val_accuracy: 0.2252\n",
      "Epoch 37/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1924 - val_loss: 0.1423 - val_accuracy: 0.2181\n",
      "Epoch 38/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1920 - val_loss: 0.1423 - val_accuracy: 0.1833\n",
      "Epoch 39/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1928 - val_loss: 0.1423 - val_accuracy: 0.1511\n",
      "Epoch 40/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1924 - val_loss: 0.1423 - val_accuracy: 0.2037\n",
      "Epoch 41/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1945 - val_loss: 0.1423 - val_accuracy: 0.1991\n",
      "Epoch 42/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1955 - val_loss: 0.1423 - val_accuracy: 0.2253\n",
      "Epoch 43/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1968 - val_loss: 0.1423 - val_accuracy: 0.2211\n",
      "Epoch 44/100\n",
      "57527/57527 [==============================] - 3s 47us/step - loss: 0.1427 - accuracy: 0.1928 - val_loss: 0.1423 - val_accuracy: 0.2165\n",
      "Epoch 45/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1919 - val_loss: 0.1423 - val_accuracy: 0.1879\n",
      "Epoch 46/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1934 - val_loss: 0.1423 - val_accuracy: 0.2166\n",
      "Epoch 47/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1940 - val_loss: 0.1423 - val_accuracy: 0.2082\n",
      "Epoch 48/100\n",
      "57527/57527 [==============================] - 3s 47us/step - loss: 0.1427 - accuracy: 0.1969 - val_loss: 0.1423 - val_accuracy: 0.2228\n",
      "Epoch 49/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1975 - val_loss: 0.1423 - val_accuracy: 0.2183\n",
      "Epoch 50/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1944 - val_loss: 0.1423 - val_accuracy: 0.2148\n",
      "Epoch 51/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1950 - val_loss: 0.1423 - val_accuracy: 0.2164\n",
      "Epoch 52/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1967 - val_loss: 0.1423 - val_accuracy: 0.2103\n",
      "Epoch 53/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1966 - val_loss: 0.1423 - val_accuracy: 0.1858\n",
      "Epoch 54/100\n",
      "57527/57527 [==============================] - 3s 47us/step - loss: 0.1427 - accuracy: 0.1942 - val_loss: 0.1423 - val_accuracy: 0.1978\n",
      "Epoch 55/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1964 - val_loss: 0.1423 - val_accuracy: 0.1922\n",
      "Epoch 56/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1978 - val_loss: 0.1423 - val_accuracy: 0.2071\n",
      "Epoch 57/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1972 - val_loss: 0.1423 - val_accuracy: 0.2295\n",
      "Epoch 58/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1951 - val_loss: 0.1423 - val_accuracy: 0.2221\n",
      "Epoch 59/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1944 - val_loss: 0.1423 - val_accuracy: 0.2041\n",
      "Epoch 60/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1983 - val_loss: 0.1423 - val_accuracy: 0.1934\n",
      "Epoch 61/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1969 - val_loss: 0.1423 - val_accuracy: 0.2225\n",
      "Epoch 62/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1956 - val_loss: 0.1423 - val_accuracy: 0.2071\n",
      "Epoch 63/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1961 - val_loss: 0.1423 - val_accuracy: 0.2216\n",
      "Epoch 64/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1987 - val_loss: 0.1423 - val_accuracy: 0.2015\n",
      "Epoch 65/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1964 - val_loss: 0.1423 - val_accuracy: 0.2245\n",
      "Epoch 66/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1971 - val_loss: 0.1423 - val_accuracy: 0.2121\n",
      "Epoch 67/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1992 - val_loss: 0.1423 - val_accuracy: 0.1991\n",
      "Epoch 68/100\n",
      "57527/57527 [==============================] - 3s 47us/step - loss: 0.1427 - accuracy: 0.1985 - val_loss: 0.1423 - val_accuracy: 0.2166\n",
      "Epoch 69/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1988 - val_loss: 0.1423 - val_accuracy: 0.2234\n",
      "Epoch 70/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1960 - val_loss: 0.1423 - val_accuracy: 0.1964\n",
      "Epoch 71/100\n",
      "57527/57527 [==============================] - 3s 47us/step - loss: 0.1427 - accuracy: 0.1980 - val_loss: 0.1423 - val_accuracy: 0.2138\n",
      "Epoch 72/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.2003 - val_loss: 0.1423 - val_accuracy: 0.2235\n",
      "Epoch 73/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1988 - val_loss: 0.1423 - val_accuracy: 0.2249\n",
      "Epoch 74/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1975 - val_loss: 0.1423 - val_accuracy: 0.2028\n",
      "Epoch 75/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1972 - val_loss: 0.1423 - val_accuracy: 0.2014\n",
      "Epoch 76/100\n",
      "57527/57527 [==============================] - 3s 47us/step - loss: 0.1427 - accuracy: 0.1961 - val_loss: 0.1423 - val_accuracy: 0.2281\n",
      "Epoch 77/100\n",
      "57527/57527 [==============================] - 3s 47us/step - loss: 0.1427 - accuracy: 0.1978 - val_loss: 0.1423 - val_accuracy: 0.2267\n",
      "Epoch 78/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1987 - val_loss: 0.1423 - val_accuracy: 0.2233\n",
      "Epoch 79/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1985 - val_loss: 0.1423 - val_accuracy: 0.1883\n",
      "Epoch 80/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1979 - val_loss: 0.1423 - val_accuracy: 0.2170\n",
      "Epoch 81/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1994 - val_loss: 0.1423 - val_accuracy: 0.2249\n",
      "Epoch 82/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.2021 - val_loss: 0.1423 - val_accuracy: 0.2180\n",
      "Epoch 83/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1992 - val_loss: 0.1423 - val_accuracy: 0.2109\n",
      "Epoch 84/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1980 - val_loss: 0.1423 - val_accuracy: 0.2218\n",
      "Epoch 85/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1992 - val_loss: 0.1423 - val_accuracy: 0.1784\n",
      "Epoch 86/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.2004 - val_loss: 0.1423 - val_accuracy: 0.2225\n",
      "Epoch 87/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.2005 - val_loss: 0.1423 - val_accuracy: 0.2273\n",
      "Epoch 88/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.2005 - val_loss: 0.1423 - val_accuracy: 0.2175\n",
      "Epoch 89/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.2018 - val_loss: 0.1423 - val_accuracy: 0.2234\n",
      "Epoch 90/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.2007 - val_loss: 0.1423 - val_accuracy: 0.2016\n",
      "Epoch 91/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1995 - val_loss: 0.1423 - val_accuracy: 0.2197\n",
      "Epoch 92/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1989 - val_loss: 0.1423 - val_accuracy: 0.2152\n",
      "Epoch 93/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.2014 - val_loss: 0.1423 - val_accuracy: 0.2038\n",
      "Epoch 94/100\n",
      "57527/57527 [==============================] - 3s 47us/step - loss: 0.1427 - accuracy: 0.1973 - val_loss: 0.1423 - val_accuracy: 0.2173\n",
      "Epoch 95/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1997 - val_loss: 0.1423 - val_accuracy: 0.2207\n",
      "Epoch 96/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1985 - val_loss: 0.1423 - val_accuracy: 0.2191\n",
      "Epoch 97/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.1999 - val_loss: 0.1423 - val_accuracy: 0.2032\n",
      "Epoch 98/100\n",
      "57527/57527 [==============================] - 3s 46us/step - loss: 0.1427 - accuracy: 0.2009 - val_loss: 0.1423 - val_accuracy: 0.2284\n",
      "Epoch 99/100\n",
      "57527/57527 [==============================] - 3s 52us/step - loss: 0.1427 - accuracy: 0.2018 - val_loss: 0.1423 - val_accuracy: 0.2247\n",
      "Epoch 100/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1427 - accuracy: 0.2006 - val_loss: 0.1423 - val_accuracy: 0.2313\n",
      "training model-2\n",
      "Train on 57527 samples, validate on 14382 samples\n",
      "Epoch 1/100\n",
      "57527/57527 [==============================] - 4s 75us/step - loss: 0.1439 - accuracy: 0.1613 - val_loss: 0.1426 - val_accuracy: 0.1640\n",
      "Epoch 2/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1430 - accuracy: 0.1572 - val_loss: 0.1425 - val_accuracy: 0.1751\n",
      "Epoch 3/100\n",
      "57527/57527 [==============================] - 3s 55us/step - loss: 0.1429 - accuracy: 0.1656 - val_loss: 0.1424 - val_accuracy: 0.1645\n",
      "Epoch 4/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1428 - accuracy: 0.1736 - val_loss: 0.1423 - val_accuracy: 0.2055\n",
      "Epoch 5/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1427 - accuracy: 0.1806 - val_loss: 0.1422 - val_accuracy: 0.2221\n",
      "Epoch 6/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1427 - accuracy: 0.1815 - val_loss: 0.1422 - val_accuracy: 0.1694\n",
      "Epoch 7/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1426 - accuracy: 0.1874 - val_loss: 0.1422 - val_accuracy: 0.1977\n",
      "Epoch 8/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1426 - accuracy: 0.1878 - val_loss: 0.1422 - val_accuracy: 0.2058\n",
      "Epoch 9/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1426 - accuracy: 0.1883 - val_loss: 0.1422 - val_accuracy: 0.1870\n",
      "Epoch 10/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1426 - accuracy: 0.1932 - val_loss: 0.1422 - val_accuracy: 0.2185\n",
      "Epoch 11/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1426 - accuracy: 0.1949 - val_loss: 0.1421 - val_accuracy: 0.2118\n",
      "Epoch 12/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.1964 - val_loss: 0.1421 - val_accuracy: 0.1653\n",
      "Epoch 13/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.1982 - val_loss: 0.1421 - val_accuracy: 0.2056\n",
      "Epoch 14/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.1962 - val_loss: 0.1421 - val_accuracy: 0.2151\n",
      "Epoch 15/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.1985 - val_loss: 0.1421 - val_accuracy: 0.1704\n",
      "Epoch 16/100\n",
      "57527/57527 [==============================] - 3s 55us/step - loss: 0.1425 - accuracy: 0.2001 - val_loss: 0.1421 - val_accuracy: 0.2049\n",
      "Epoch 17/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.1999 - val_loss: 0.1421 - val_accuracy: 0.1920\n",
      "Epoch 18/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.1997 - val_loss: 0.1421 - val_accuracy: 0.2053\n",
      "Epoch 19/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2028 - val_loss: 0.1421 - val_accuracy: 0.1769\n",
      "Epoch 20/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2022 - val_loss: 0.1421 - val_accuracy: 0.1912\n",
      "Epoch 21/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2037 - val_loss: 0.1421 - val_accuracy: 0.2018\n",
      "Epoch 22/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2041 - val_loss: 0.1421 - val_accuracy: 0.1997\n",
      "Epoch 23/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2039 - val_loss: 0.1421 - val_accuracy: 0.2212\n",
      "Epoch 24/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2066 - val_loss: 0.1421 - val_accuracy: 0.1792\n",
      "Epoch 25/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2057 - val_loss: 0.1421 - val_accuracy: 0.2022\n",
      "Epoch 26/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2038 - val_loss: 0.1421 - val_accuracy: 0.2274\n",
      "Epoch 27/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2068 - val_loss: 0.1421 - val_accuracy: 0.2128\n",
      "Epoch 28/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2068 - val_loss: 0.1421 - val_accuracy: 0.1960\n",
      "Epoch 29/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2037 - val_loss: 0.1421 - val_accuracy: 0.2283\n",
      "Epoch 30/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2048 - val_loss: 0.1421 - val_accuracy: 0.2152\n",
      "Epoch 31/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2062 - val_loss: 0.1421 - val_accuracy: 0.2291\n",
      "Epoch 32/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2061 - val_loss: 0.1421 - val_accuracy: 0.2282\n",
      "Epoch 33/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2081 - val_loss: 0.1421 - val_accuracy: 0.2069\n",
      "Epoch 34/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2059 - val_loss: 0.1421 - val_accuracy: 0.1929\n",
      "Epoch 35/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2057 - val_loss: 0.1421 - val_accuracy: 0.2183\n",
      "Epoch 36/100\n",
      "57527/57527 [==============================] - 3s 55us/step - loss: 0.1425 - accuracy: 0.2065 - val_loss: 0.1421 - val_accuracy: 0.2209\n",
      "Epoch 37/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2081 - val_loss: 0.1421 - val_accuracy: 0.2312\n",
      "Epoch 38/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2092 - val_loss: 0.1421 - val_accuracy: 0.2222\n",
      "Epoch 39/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2104 - val_loss: 0.1421 - val_accuracy: 0.2130\n",
      "Epoch 40/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2073 - val_loss: 0.1421 - val_accuracy: 0.2057\n",
      "Epoch 41/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2080 - val_loss: 0.1421 - val_accuracy: 0.2229\n",
      "Epoch 42/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2103 - val_loss: 0.1421 - val_accuracy: 0.2181\n",
      "Epoch 43/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2081 - val_loss: 0.1421 - val_accuracy: 0.2158\n",
      "Epoch 44/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2111 - val_loss: 0.1421 - val_accuracy: 0.2194\n",
      "Epoch 45/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2116 - val_loss: 0.1421 - val_accuracy: 0.2219\n",
      "Epoch 46/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2122 - val_loss: 0.1421 - val_accuracy: 0.2130\n",
      "Epoch 47/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2079 - val_loss: 0.1421 - val_accuracy: 0.1804\n",
      "Epoch 48/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2111 - val_loss: 0.1421 - val_accuracy: 0.2189\n",
      "Epoch 49/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2115 - val_loss: 0.1421 - val_accuracy: 0.2126\n",
      "Epoch 50/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2103 - val_loss: 0.1421 - val_accuracy: 0.2174\n",
      "Epoch 51/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2106 - val_loss: 0.1421 - val_accuracy: 0.2226\n",
      "Epoch 52/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2109 - val_loss: 0.1421 - val_accuracy: 0.1878\n",
      "Epoch 53/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2087 - val_loss: 0.1421 - val_accuracy: 0.2222\n",
      "Epoch 54/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2110 - val_loss: 0.1421 - val_accuracy: 0.2148\n",
      "Epoch 55/100\n",
      "57527/57527 [==============================] - 3s 57us/step - loss: 0.1425 - accuracy: 0.2080 - val_loss: 0.1421 - val_accuracy: 0.2268\n",
      "Epoch 56/100\n",
      "57527/57527 [==============================] - 3s 57us/step - loss: 0.1425 - accuracy: 0.2137 - val_loss: 0.1421 - val_accuracy: 0.2315\n",
      "Epoch 57/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2097 - val_loss: 0.1421 - val_accuracy: 0.2233\n",
      "Epoch 58/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2105 - val_loss: 0.1421 - val_accuracy: 0.2226\n",
      "Epoch 59/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2093 - val_loss: 0.1421 - val_accuracy: 0.2208\n",
      "Epoch 60/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2109 - val_loss: 0.1421 - val_accuracy: 0.2062\n",
      "Epoch 61/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2103 - val_loss: 0.1421 - val_accuracy: 0.2279\n",
      "Epoch 62/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2134 - val_loss: 0.1421 - val_accuracy: 0.2229\n",
      "Epoch 63/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2120 - val_loss: 0.1421 - val_accuracy: 0.2271\n",
      "Epoch 64/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2108 - val_loss: 0.1421 - val_accuracy: 0.2282\n",
      "Epoch 65/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2127 - val_loss: 0.1421 - val_accuracy: 0.2307\n",
      "Epoch 66/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2102 - val_loss: 0.1421 - val_accuracy: 0.2327\n",
      "Epoch 67/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2118 - val_loss: 0.1421 - val_accuracy: 0.2109\n",
      "Epoch 68/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2119 - val_loss: 0.1421 - val_accuracy: 0.2226\n",
      "Epoch 69/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2132 - val_loss: 0.1421 - val_accuracy: 0.2265\n",
      "Epoch 70/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2131 - val_loss: 0.1421 - val_accuracy: 0.2299\n",
      "Epoch 71/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2127 - val_loss: 0.1421 - val_accuracy: 0.2199\n",
      "Epoch 72/100\n",
      "57527/57527 [==============================] - 3s 53us/step - loss: 0.1425 - accuracy: 0.2131 - val_loss: 0.1421 - val_accuracy: 0.2310\n",
      "Epoch 73/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2128 - val_loss: 0.1421 - val_accuracy: 0.2310\n",
      "Epoch 74/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2123 - val_loss: 0.1421 - val_accuracy: 0.2059\n",
      "Epoch 75/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2144 - val_loss: 0.1421 - val_accuracy: 0.2177\n",
      "Epoch 76/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2125 - val_loss: 0.1421 - val_accuracy: 0.2333\n",
      "Epoch 77/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2140 - val_loss: 0.1421 - val_accuracy: 0.2202\n",
      "Epoch 78/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2135 - val_loss: 0.1420 - val_accuracy: 0.2139\n",
      "Epoch 79/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2153 - val_loss: 0.1420 - val_accuracy: 0.2307\n",
      "Epoch 80/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2126 - val_loss: 0.1420 - val_accuracy: 0.1984\n",
      "Epoch 81/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2123 - val_loss: 0.1420 - val_accuracy: 0.2098\n",
      "Epoch 82/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2142 - val_loss: 0.1420 - val_accuracy: 0.2326\n",
      "Epoch 83/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2118 - val_loss: 0.1420 - val_accuracy: 0.2135\n",
      "Epoch 84/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2150 - val_loss: 0.1420 - val_accuracy: 0.2274\n",
      "Epoch 85/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2123 - val_loss: 0.1420 - val_accuracy: 0.2249\n",
      "Epoch 86/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2130 - val_loss: 0.1420 - val_accuracy: 0.2298\n",
      "Epoch 87/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2130 - val_loss: 0.1420 - val_accuracy: 0.2190\n",
      "Epoch 88/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2148 - val_loss: 0.1420 - val_accuracy: 0.2238\n",
      "Epoch 89/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2133 - val_loss: 0.1420 - val_accuracy: 0.2183\n",
      "Epoch 90/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2140 - val_loss: 0.1420 - val_accuracy: 0.2303\n",
      "Epoch 91/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2147 - val_loss: 0.1420 - val_accuracy: 0.2089\n",
      "Epoch 92/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2136 - val_loss: 0.1420 - val_accuracy: 0.2189\n",
      "Epoch 93/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2146 - val_loss: 0.1420 - val_accuracy: 0.2284\n",
      "Epoch 94/100\n",
      "57527/57527 [==============================] - 3s 55us/step - loss: 0.1425 - accuracy: 0.2154 - val_loss: 0.1420 - val_accuracy: 0.2217\n",
      "Epoch 95/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2141 - val_loss: 0.1420 - val_accuracy: 0.2256\n",
      "Epoch 96/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2153 - val_loss: 0.1420 - val_accuracy: 0.2070\n",
      "Epoch 97/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2156 - val_loss: 0.1420 - val_accuracy: 0.2285\n",
      "Epoch 98/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2144 - val_loss: 0.1420 - val_accuracy: 0.2188\n",
      "Epoch 99/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2149 - val_loss: 0.1420 - val_accuracy: 0.2206\n",
      "Epoch 100/100\n",
      "57527/57527 [==============================] - 3s 54us/step - loss: 0.1425 - accuracy: 0.2156 - val_loss: 0.1420 - val_accuracy: 0.2187\n",
      "training model-3\n",
      "Train on 57527 samples, validate on 14382 samples\n",
      "Epoch 1/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1489 - accuracy: 0.2015 - val_loss: 0.1457 - val_accuracy: 0.2267\n",
      "Epoch 2/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1459 - accuracy: 0.2127 - val_loss: 0.1447 - val_accuracy: 0.2170\n",
      "Epoch 3/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1449 - accuracy: 0.2005 - val_loss: 0.1439 - val_accuracy: 0.2194\n",
      "Epoch 4/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1445 - accuracy: 0.1847 - val_loss: 0.1437 - val_accuracy: 0.2158\n",
      "Epoch 5/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1443 - accuracy: 0.1768 - val_loss: 0.1436 - val_accuracy: 0.2165\n",
      "Epoch 6/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1442 - accuracy: 0.1769 - val_loss: 0.1435 - val_accuracy: 0.2171\n",
      "Epoch 7/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1441 - accuracy: 0.1750 - val_loss: 0.1434 - val_accuracy: 0.2171\n",
      "Epoch 8/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1440 - accuracy: 0.1730 - val_loss: 0.1433 - val_accuracy: 0.2166\n",
      "Epoch 9/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1439 - accuracy: 0.1716 - val_loss: 0.1433 - val_accuracy: 0.1923\n",
      "Epoch 10/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1439 - accuracy: 0.1716 - val_loss: 0.1432 - val_accuracy: 0.1805\n",
      "Epoch 11/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1438 - accuracy: 0.1691 - val_loss: 0.1432 - val_accuracy: 0.1740\n",
      "Epoch 12/100\n",
      "57527/57527 [==============================] - 3s 49us/step - loss: 0.1438 - accuracy: 0.1690 - val_loss: 0.1432 - val_accuracy: 0.1690\n",
      "Epoch 13/100\n",
      "57527/57527 [==============================] - 3s 52us/step - loss: 0.1438 - accuracy: 0.1713 - val_loss: 0.1432 - val_accuracy: 0.1763\n",
      "Epoch 14/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1437 - accuracy: 0.1705 - val_loss: 0.1431 - val_accuracy: 0.1765\n",
      "Epoch 15/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1437 - accuracy: 0.1696 - val_loss: 0.1431 - val_accuracy: 0.1763\n",
      "Epoch 16/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1437 - accuracy: 0.1694 - val_loss: 0.1431 - val_accuracy: 0.1699\n",
      "Epoch 17/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1437 - accuracy: 0.1700 - val_loss: 0.1431 - val_accuracy: 0.1732\n",
      "Epoch 18/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1436 - accuracy: 0.1697 - val_loss: 0.1430 - val_accuracy: 0.1728\n",
      "Epoch 19/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1436 - accuracy: 0.1677 - val_loss: 0.1430 - val_accuracy: 0.1759\n",
      "Epoch 20/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1436 - accuracy: 0.1676 - val_loss: 0.1430 - val_accuracy: 0.1767\n",
      "Epoch 21/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1436 - accuracy: 0.1692 - val_loss: 0.1430 - val_accuracy: 0.1779\n",
      "Epoch 22/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1436 - accuracy: 0.1701 - val_loss: 0.1430 - val_accuracy: 0.1709\n",
      "Epoch 23/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1435 - accuracy: 0.1695 - val_loss: 0.1429 - val_accuracy: 0.1796\n",
      "Epoch 24/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1435 - accuracy: 0.1699 - val_loss: 0.1429 - val_accuracy: 0.1722\n",
      "Epoch 25/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1435 - accuracy: 0.1684 - val_loss: 0.1429 - val_accuracy: 0.1713\n",
      "Epoch 26/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1435 - accuracy: 0.1683 - val_loss: 0.1429 - val_accuracy: 0.1722\n",
      "Epoch 27/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1435 - accuracy: 0.1688 - val_loss: 0.1429 - val_accuracy: 0.1704\n",
      "Epoch 28/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1435 - accuracy: 0.1657 - val_loss: 0.1429 - val_accuracy: 0.1715\n",
      "Epoch 29/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1435 - accuracy: 0.1681 - val_loss: 0.1429 - val_accuracy: 0.1707\n",
      "Epoch 30/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1435 - accuracy: 0.1692 - val_loss: 0.1429 - val_accuracy: 0.1693\n",
      "Epoch 31/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1435 - accuracy: 0.1675 - val_loss: 0.1429 - val_accuracy: 0.1692\n",
      "Epoch 32/100\n",
      "57527/57527 [==============================] - 3s 47us/step - loss: 0.1435 - accuracy: 0.1693 - val_loss: 0.1429 - val_accuracy: 0.1715\n",
      "Epoch 33/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1435 - accuracy: 0.1667 - val_loss: 0.1429 - val_accuracy: 0.1690\n",
      "Epoch 34/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1435 - accuracy: 0.1679 - val_loss: 0.1429 - val_accuracy: 0.1694\n",
      "Epoch 35/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1435 - accuracy: 0.1677 - val_loss: 0.1429 - val_accuracy: 0.1734\n",
      "Epoch 36/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1435 - accuracy: 0.1670 - val_loss: 0.1429 - val_accuracy: 0.1722\n",
      "Epoch 37/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1435 - accuracy: 0.1677 - val_loss: 0.1429 - val_accuracy: 0.1767\n",
      "Epoch 38/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1435 - accuracy: 0.1653 - val_loss: 0.1429 - val_accuracy: 0.1704\n",
      "Epoch 39/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1435 - accuracy: 0.1653 - val_loss: 0.1429 - val_accuracy: 0.1729\n",
      "Epoch 40/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1435 - accuracy: 0.1674 - val_loss: 0.1429 - val_accuracy: 0.1692\n",
      "Epoch 41/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1435 - accuracy: 0.1663 - val_loss: 0.1428 - val_accuracy: 0.1711\n",
      "Epoch 42/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1435 - accuracy: 0.1658 - val_loss: 0.1428 - val_accuracy: 0.1682\n",
      "Epoch 43/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1677 - val_loss: 0.1428 - val_accuracy: 0.1683\n",
      "Epoch 44/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1435 - accuracy: 0.1663 - val_loss: 0.1428 - val_accuracy: 0.1695\n",
      "Epoch 45/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1649 - val_loss: 0.1428 - val_accuracy: 0.1694\n",
      "Epoch 46/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1641 - val_loss: 0.1428 - val_accuracy: 0.1688\n",
      "Epoch 47/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1653 - val_loss: 0.1428 - val_accuracy: 0.1767\n",
      "Epoch 48/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1651 - val_loss: 0.1428 - val_accuracy: 0.1717\n",
      "Epoch 49/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1640 - val_loss: 0.1428 - val_accuracy: 0.1772\n",
      "Epoch 50/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1638 - val_loss: 0.1428 - val_accuracy: 0.1685\n",
      "Epoch 51/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1645 - val_loss: 0.1428 - val_accuracy: 0.1683\n",
      "Epoch 52/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1638 - val_loss: 0.1428 - val_accuracy: 0.1672\n",
      "Epoch 53/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1642 - val_loss: 0.1428 - val_accuracy: 0.1742\n",
      "Epoch 54/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1632 - val_loss: 0.1428 - val_accuracy: 0.1669\n",
      "Epoch 55/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1588 - val_loss: 0.1428 - val_accuracy: 0.1693\n",
      "Epoch 56/100\n",
      "57527/57527 [==============================] - 3s 49us/step - loss: 0.1434 - accuracy: 0.1600 - val_loss: 0.1428 - val_accuracy: 0.1669\n",
      "Epoch 57/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1628 - val_loss: 0.1428 - val_accuracy: 0.1710\n",
      "Epoch 58/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1657 - val_loss: 0.1428 - val_accuracy: 0.1770\n",
      "Epoch 59/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1629 - val_loss: 0.1428 - val_accuracy: 0.1729\n",
      "Epoch 60/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1615 - val_loss: 0.1428 - val_accuracy: 0.1733\n",
      "Epoch 61/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1632 - val_loss: 0.1428 - val_accuracy: 0.1707\n",
      "Epoch 62/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1638 - val_loss: 0.1428 - val_accuracy: 0.1670\n",
      "Epoch 63/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1638 - val_loss: 0.1428 - val_accuracy: 0.1764\n",
      "Epoch 64/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1612 - val_loss: 0.1428 - val_accuracy: 0.1753\n",
      "Epoch 65/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1629 - val_loss: 0.1428 - val_accuracy: 0.1722\n",
      "Epoch 66/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1621 - val_loss: 0.1428 - val_accuracy: 0.1767\n",
      "Epoch 67/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1625 - val_loss: 0.1428 - val_accuracy: 0.1713\n",
      "Epoch 68/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1621 - val_loss: 0.1428 - val_accuracy: 0.1733\n",
      "Epoch 69/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1638 - val_loss: 0.1428 - val_accuracy: 0.1733\n",
      "Epoch 70/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1611 - val_loss: 0.1428 - val_accuracy: 0.1762\n",
      "Epoch 71/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1609 - val_loss: 0.1428 - val_accuracy: 0.1683\n",
      "Epoch 72/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1617 - val_loss: 0.1428 - val_accuracy: 0.1724\n",
      "Epoch 73/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1615 - val_loss: 0.1428 - val_accuracy: 0.1664\n",
      "Epoch 74/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1615 - val_loss: 0.1428 - val_accuracy: 0.1781\n",
      "Epoch 75/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1605 - val_loss: 0.1428 - val_accuracy: 0.1697\n",
      "Epoch 76/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1596 - val_loss: 0.1428 - val_accuracy: 0.1724\n",
      "Epoch 77/100\n",
      "57527/57527 [==============================] - 3s 49us/step - loss: 0.1434 - accuracy: 0.1603 - val_loss: 0.1428 - val_accuracy: 0.1726\n",
      "Epoch 78/100\n",
      "57527/57527 [==============================] - 3s 53us/step - loss: 0.1434 - accuracy: 0.1606 - val_loss: 0.1428 - val_accuracy: 0.1778\n",
      "Epoch 79/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1585 - val_loss: 0.1428 - val_accuracy: 0.1794\n",
      "Epoch 80/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1611 - val_loss: 0.1428 - val_accuracy: 0.1722\n",
      "Epoch 81/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1625 - val_loss: 0.1428 - val_accuracy: 0.1761\n",
      "Epoch 82/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1597 - val_loss: 0.1428 - val_accuracy: 0.1825\n",
      "Epoch 83/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1606 - val_loss: 0.1428 - val_accuracy: 0.1806\n",
      "Epoch 84/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1600 - val_loss: 0.1428 - val_accuracy: 0.1771\n",
      "Epoch 85/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1615 - val_loss: 0.1428 - val_accuracy: 0.1782\n",
      "Epoch 86/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1615 - val_loss: 0.1428 - val_accuracy: 0.1823\n",
      "Epoch 87/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1624 - val_loss: 0.1428 - val_accuracy: 0.1814\n",
      "Epoch 88/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1619 - val_loss: 0.1428 - val_accuracy: 0.1822\n",
      "Epoch 89/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1618 - val_loss: 0.1428 - val_accuracy: 0.1825\n",
      "Epoch 90/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1622 - val_loss: 0.1428 - val_accuracy: 0.1792\n",
      "Epoch 91/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1612 - val_loss: 0.1428 - val_accuracy: 0.1767\n",
      "Epoch 92/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1622 - val_loss: 0.1428 - val_accuracy: 0.1790\n",
      "Epoch 93/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1618 - val_loss: 0.1428 - val_accuracy: 0.1819\n",
      "Epoch 94/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1614 - val_loss: 0.1428 - val_accuracy: 0.1831\n",
      "Epoch 95/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1636 - val_loss: 0.1428 - val_accuracy: 0.1773\n",
      "Epoch 96/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1634 - val_loss: 0.1428 - val_accuracy: 0.1758\n",
      "Epoch 97/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1615 - val_loss: 0.1428 - val_accuracy: 0.1850\n",
      "Epoch 98/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1638 - val_loss: 0.1428 - val_accuracy: 0.1813\n",
      "Epoch 99/100\n",
      "57527/57527 [==============================] - 3s 48us/step - loss: 0.1434 - accuracy: 0.1628 - val_loss: 0.1428 - val_accuracy: 0.1813\n",
      "Epoch 100/100\n",
      "57527/57527 [==============================] - 3s 49us/step - loss: 0.1434 - accuracy: 0.1630 - val_loss: 0.1428 - val_accuracy: 0.1806\n",
      "training model-4\n",
      "Train on 57527 samples, validate on 14382 samples\n",
      "Epoch 1/100\n",
      "57527/57527 [==============================] - 4s 78us/step - loss: 0.1541 - accuracy: 0.0094 - val_loss: 0.1537 - val_accuracy: 0.0027\n",
      "Epoch 2/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1541 - accuracy: 0.0103 - val_loss: 0.1537 - val_accuracy: 0.0023\n",
      "Epoch 3/100\n",
      "57527/57527 [==============================] - 3s 57us/step - loss: 0.1541 - accuracy: 0.0094 - val_loss: 0.1537 - val_accuracy: 0.0023\n",
      "Epoch 4/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1540 - accuracy: 0.0090 - val_loss: 0.1536 - val_accuracy: 0.0022\n",
      "Epoch 5/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1540 - accuracy: 0.0091 - val_loss: 0.1536 - val_accuracy: 0.0022\n",
      "Epoch 6/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1540 - accuracy: 0.0084 - val_loss: 0.1536 - val_accuracy: 0.0022\n",
      "Epoch 7/100\n",
      "57527/57527 [==============================] - 3s 57us/step - loss: 0.1540 - accuracy: 0.0088 - val_loss: 0.1536 - val_accuracy: 0.0021\n",
      "Epoch 8/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1540 - accuracy: 0.0089 - val_loss: 0.1536 - val_accuracy: 0.0022\n",
      "Epoch 9/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1540 - accuracy: 0.0085 - val_loss: 0.1536 - val_accuracy: 0.0019\n",
      "Epoch 10/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1539 - accuracy: 0.0081 - val_loss: 0.1536 - val_accuracy: 0.0019\n",
      "Epoch 11/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1539 - accuracy: 0.0092 - val_loss: 0.1535 - val_accuracy: 0.0022\n",
      "Epoch 12/100\n",
      "57527/57527 [==============================] - 3s 57us/step - loss: 0.1539 - accuracy: 0.0091 - val_loss: 0.1535 - val_accuracy: 0.0022\n",
      "Epoch 13/100\n",
      "57527/57527 [==============================] - 3s 57us/step - loss: 0.1539 - accuracy: 0.0093 - val_loss: 0.1535 - val_accuracy: 0.0023\n",
      "Epoch 14/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1539 - accuracy: 0.0094 - val_loss: 0.1535 - val_accuracy: 0.0025\n",
      "Epoch 15/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1539 - accuracy: 0.0096 - val_loss: 0.1535 - val_accuracy: 0.0026\n",
      "Epoch 16/100\n",
      "57527/57527 [==============================] - 3s 57us/step - loss: 0.1538 - accuracy: 0.0098 - val_loss: 0.1534 - val_accuracy: 0.0026\n",
      "Epoch 17/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1538 - accuracy: 0.0106 - val_loss: 0.1534 - val_accuracy: 0.0029\n",
      "Epoch 18/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1538 - accuracy: 0.0113 - val_loss: 0.1534 - val_accuracy: 0.0031\n",
      "Epoch 19/100\n",
      "57527/57527 [==============================] - 3s 57us/step - loss: 0.1538 - accuracy: 0.0107 - val_loss: 0.1534 - val_accuracy: 0.0033\n",
      "Epoch 20/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1537 - accuracy: 0.0132 - val_loss: 0.1533 - val_accuracy: 0.0037\n",
      "Epoch 21/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1537 - accuracy: 0.0132 - val_loss: 0.1533 - val_accuracy: 0.0039\n",
      "Epoch 22/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1537 - accuracy: 0.0139 - val_loss: 0.1533 - val_accuracy: 0.0048\n",
      "Epoch 23/100\n",
      "57527/57527 [==============================] - 3s 57us/step - loss: 0.1537 - accuracy: 0.0153 - val_loss: 0.1533 - val_accuracy: 0.0054\n",
      "Epoch 24/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1536 - accuracy: 0.0171 - val_loss: 0.1532 - val_accuracy: 0.0060\n",
      "Epoch 25/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1536 - accuracy: 0.0186 - val_loss: 0.1532 - val_accuracy: 0.0070\n",
      "Epoch 26/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1536 - accuracy: 0.0212 - val_loss: 0.1532 - val_accuracy: 0.0081\n",
      "Epoch 27/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1535 - accuracy: 0.0231 - val_loss: 0.1531 - val_accuracy: 0.0097\n",
      "Epoch 28/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1535 - accuracy: 0.0250 - val_loss: 0.1531 - val_accuracy: 0.0119\n",
      "Epoch 29/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1534 - accuracy: 0.0277 - val_loss: 0.1530 - val_accuracy: 0.0149\n",
      "Epoch 30/100\n",
      "57527/57527 [==============================] - 3s 57us/step - loss: 0.1534 - accuracy: 0.0327 - val_loss: 0.1530 - val_accuracy: 0.0188\n",
      "Epoch 31/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1533 - accuracy: 0.0360 - val_loss: 0.1529 - val_accuracy: 0.0231\n",
      "Epoch 32/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1533 - accuracy: 0.0428 - val_loss: 0.1529 - val_accuracy: 0.0298\n",
      "Epoch 33/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1532 - accuracy: 0.0479 - val_loss: 0.1528 - val_accuracy: 0.0387\n",
      "Epoch 34/100\n",
      "57527/57527 [==============================] - 3s 57us/step - loss: 0.1531 - accuracy: 0.0551 - val_loss: 0.1527 - val_accuracy: 0.0499\n",
      "Epoch 35/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1531 - accuracy: 0.0647 - val_loss: 0.1526 - val_accuracy: 0.0649\n",
      "Epoch 36/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1530 - accuracy: 0.0707 - val_loss: 0.1525 - val_accuracy: 0.0876\n",
      "Epoch 37/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1529 - accuracy: 0.0836 - val_loss: 0.1524 - val_accuracy: 0.1224\n",
      "Epoch 38/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1527 - accuracy: 0.0970 - val_loss: 0.1523 - val_accuracy: 0.1651\n",
      "Epoch 39/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1526 - accuracy: 0.1087 - val_loss: 0.1521 - val_accuracy: 0.2081\n",
      "Epoch 40/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1524 - accuracy: 0.1249 - val_loss: 0.1520 - val_accuracy: 0.2260\n",
      "Epoch 41/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1522 - accuracy: 0.1443 - val_loss: 0.1517 - val_accuracy: 0.2267\n",
      "Epoch 42/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1520 - accuracy: 0.1666 - val_loss: 0.1514 - val_accuracy: 0.2267\n",
      "Epoch 43/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1516 - accuracy: 0.1930 - val_loss: 0.1509 - val_accuracy: 0.2267\n",
      "Epoch 44/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1510 - accuracy: 0.2111 - val_loss: 0.1502 - val_accuracy: 0.2267\n",
      "Epoch 45/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1502 - accuracy: 0.2229 - val_loss: 0.1493 - val_accuracy: 0.2267\n",
      "Epoch 46/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1495 - accuracy: 0.2251 - val_loss: 0.1486 - val_accuracy: 0.2267\n",
      "Epoch 47/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1490 - accuracy: 0.2253 - val_loss: 0.1481 - val_accuracy: 0.2267\n",
      "Epoch 48/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1486 - accuracy: 0.2211 - val_loss: 0.1477 - val_accuracy: 0.2267\n",
      "Epoch 49/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1483 - accuracy: 0.2110 - val_loss: 0.1474 - val_accuracy: 0.2267\n",
      "Epoch 50/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1481 - accuracy: 0.2024 - val_loss: 0.1472 - val_accuracy: 0.2267\n",
      "Epoch 51/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1478 - accuracy: 0.1965 - val_loss: 0.1469 - val_accuracy: 0.2267\n",
      "Epoch 52/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1475 - accuracy: 0.1957 - val_loss: 0.1465 - val_accuracy: 0.2267\n",
      "Epoch 53/100\n",
      "57527/57527 [==============================] - 3s 57us/step - loss: 0.1471 - accuracy: 0.1902 - val_loss: 0.1461 - val_accuracy: 0.2267\n",
      "Epoch 54/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1469 - accuracy: 0.1846 - val_loss: 0.1459 - val_accuracy: 0.2267\n",
      "Epoch 55/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1468 - accuracy: 0.1829 - val_loss: 0.1459 - val_accuracy: 0.2267\n",
      "Epoch 56/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1467 - accuracy: 0.1798 - val_loss: 0.1458 - val_accuracy: 0.2267\n",
      "Epoch 57/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1466 - accuracy: 0.1811 - val_loss: 0.1458 - val_accuracy: 0.2267\n",
      "Epoch 58/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1466 - accuracy: 0.1811 - val_loss: 0.1457 - val_accuracy: 0.2267\n",
      "Epoch 59/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1466 - accuracy: 0.1834 - val_loss: 0.1457 - val_accuracy: 0.2267\n",
      "Epoch 60/100\n",
      "57527/57527 [==============================] - 3s 57us/step - loss: 0.1465 - accuracy: 0.1847 - val_loss: 0.1457 - val_accuracy: 0.2267\n",
      "Epoch 61/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1465 - accuracy: 0.1831 - val_loss: 0.1457 - val_accuracy: 0.2267\n",
      "Epoch 62/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1465 - accuracy: 0.1857 - val_loss: 0.1457 - val_accuracy: 0.2267\n",
      "Epoch 63/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1464 - accuracy: 0.1849 - val_loss: 0.1456 - val_accuracy: 0.2267\n",
      "Epoch 64/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1464 - accuracy: 0.1840 - val_loss: 0.1456 - val_accuracy: 0.2267\n",
      "Epoch 65/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1464 - accuracy: 0.1884 - val_loss: 0.1456 - val_accuracy: 0.2267\n",
      "Epoch 66/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1464 - accuracy: 0.1880 - val_loss: 0.1456 - val_accuracy: 0.2267\n",
      "Epoch 67/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1463 - accuracy: 0.1892 - val_loss: 0.1456 - val_accuracy: 0.2267\n",
      "Epoch 68/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1463 - accuracy: 0.1871 - val_loss: 0.1456 - val_accuracy: 0.2267\n",
      "Epoch 69/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1463 - accuracy: 0.1888 - val_loss: 0.1456 - val_accuracy: 0.2267\n",
      "Epoch 70/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1463 - accuracy: 0.1885 - val_loss: 0.1456 - val_accuracy: 0.2267\n",
      "Epoch 71/100\n",
      "57527/57527 [==============================] - 3s 57us/step - loss: 0.1463 - accuracy: 0.1909 - val_loss: 0.1456 - val_accuracy: 0.2267\n",
      "Epoch 72/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1462 - accuracy: 0.1919 - val_loss: 0.1456 - val_accuracy: 0.2267\n",
      "Epoch 73/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1462 - accuracy: 0.1938 - val_loss: 0.1456 - val_accuracy: 0.2267\n",
      "Epoch 74/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1462 - accuracy: 0.1924 - val_loss: 0.1456 - val_accuracy: 0.2267\n",
      "Epoch 75/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1462 - accuracy: 0.1927 - val_loss: 0.1456 - val_accuracy: 0.2267\n",
      "Epoch 76/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1462 - accuracy: 0.1942 - val_loss: 0.1456 - val_accuracy: 0.2267\n",
      "Epoch 77/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1462 - accuracy: 0.1947 - val_loss: 0.1456 - val_accuracy: 0.2267\n",
      "Epoch 78/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1462 - accuracy: 0.1953 - val_loss: 0.1456 - val_accuracy: 0.2267\n",
      "Epoch 79/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1462 - accuracy: 0.1964 - val_loss: 0.1456 - val_accuracy: 0.2267\n",
      "Epoch 80/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1461 - accuracy: 0.1981 - val_loss: 0.1456 - val_accuracy: 0.2267\n",
      "Epoch 81/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1461 - accuracy: 0.1962 - val_loss: 0.1456 - val_accuracy: 0.2267\n",
      "Epoch 82/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1461 - accuracy: 0.1988 - val_loss: 0.1456 - val_accuracy: 0.2267\n",
      "Epoch 83/100\n",
      "57527/57527 [==============================] - 3s 57us/step - loss: 0.1461 - accuracy: 0.1979 - val_loss: 0.1455 - val_accuracy: 0.2267\n",
      "Epoch 84/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1461 - accuracy: 0.1994 - val_loss: 0.1455 - val_accuracy: 0.2267\n",
      "Epoch 85/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1461 - accuracy: 0.2006 - val_loss: 0.1455 - val_accuracy: 0.2267\n",
      "Epoch 86/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1461 - accuracy: 0.2026 - val_loss: 0.1455 - val_accuracy: 0.2267\n",
      "Epoch 87/100\n",
      "57527/57527 [==============================] - 3s 57us/step - loss: 0.1461 - accuracy: 0.2010 - val_loss: 0.1455 - val_accuracy: 0.2267\n",
      "Epoch 88/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1461 - accuracy: 0.2021 - val_loss: 0.1455 - val_accuracy: 0.2267\n",
      "Epoch 89/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1461 - accuracy: 0.2021 - val_loss: 0.1455 - val_accuracy: 0.2267\n",
      "Epoch 90/100\n",
      "57527/57527 [==============================] - 3s 61us/step - loss: 0.1461 - accuracy: 0.2018 - val_loss: 0.1455 - val_accuracy: 0.2267\n",
      "Epoch 91/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1461 - accuracy: 0.2021 - val_loss: 0.1455 - val_accuracy: 0.2267\n",
      "Epoch 92/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1461 - accuracy: 0.2041 - val_loss: 0.1455 - val_accuracy: 0.2267\n",
      "Epoch 93/100\n",
      "57527/57527 [==============================] - 3s 57us/step - loss: 0.1460 - accuracy: 0.2030 - val_loss: 0.1455 - val_accuracy: 0.2267\n",
      "Epoch 94/100\n",
      "57527/57527 [==============================] - 3s 57us/step - loss: 0.1460 - accuracy: 0.2045 - val_loss: 0.1455 - val_accuracy: 0.2267\n",
      "Epoch 95/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1460 - accuracy: 0.2045 - val_loss: 0.1455 - val_accuracy: 0.2267\n",
      "Epoch 96/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1460 - accuracy: 0.2069 - val_loss: 0.1455 - val_accuracy: 0.2267\n",
      "Epoch 97/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1460 - accuracy: 0.2066 - val_loss: 0.1455 - val_accuracy: 0.2267\n",
      "Epoch 98/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1460 - accuracy: 0.2061 - val_loss: 0.1455 - val_accuracy: 0.2267\n",
      "Epoch 99/100\n",
      "57527/57527 [==============================] - 3s 57us/step - loss: 0.1460 - accuracy: 0.2052 - val_loss: 0.1455 - val_accuracy: 0.2267\n",
      "Epoch 100/100\n",
      "57527/57527 [==============================] - 3s 56us/step - loss: 0.1460 - accuracy: 0.2063 - val_loss: 0.1455 - val_accuracy: 0.2267\n",
      "training model-5\n",
      "Train on 57527 samples, validate on 14382 samples\n",
      "Epoch 1/100\n",
      "57527/57527 [==============================] - 5s 83us/step - loss: 0.1438 - accuracy: 0.1588 - val_loss: 0.1426 - val_accuracy: 0.1504\n",
      "Epoch 2/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1430 - accuracy: 0.1535 - val_loss: 0.1424 - val_accuracy: 0.1910\n",
      "Epoch 3/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1428 - accuracy: 0.1682 - val_loss: 0.1423 - val_accuracy: 0.2222\n",
      "Epoch 4/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1427 - accuracy: 0.1781 - val_loss: 0.1422 - val_accuracy: 0.1901\n",
      "Epoch 5/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1426 - accuracy: 0.1834 - val_loss: 0.1421 - val_accuracy: 0.2201\n",
      "Epoch 6/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1426 - accuracy: 0.1870 - val_loss: 0.1421 - val_accuracy: 0.2199\n",
      "Epoch 7/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1426 - accuracy: 0.1864 - val_loss: 0.1421 - val_accuracy: 0.1639\n",
      "Epoch 8/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.1919 - val_loss: 0.1421 - val_accuracy: 0.2285\n",
      "Epoch 9/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.1919 - val_loss: 0.1421 - val_accuracy: 0.1570\n",
      "Epoch 10/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.1944 - val_loss: 0.1421 - val_accuracy: 0.1993\n",
      "Epoch 11/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.1981 - val_loss: 0.1421 - val_accuracy: 0.2282\n",
      "Epoch 12/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.1969 - val_loss: 0.1421 - val_accuracy: 0.2224\n",
      "Epoch 13/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.1978 - val_loss: 0.1421 - val_accuracy: 0.2125\n",
      "Epoch 14/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.1975 - val_loss: 0.1421 - val_accuracy: 0.2270\n",
      "Epoch 15/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2020 - val_loss: 0.1421 - val_accuracy: 0.1937\n",
      "Epoch 16/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2016 - val_loss: 0.1421 - val_accuracy: 0.2283\n",
      "Epoch 17/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2003 - val_loss: 0.1421 - val_accuracy: 0.2218\n",
      "Epoch 18/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2036 - val_loss: 0.1421 - val_accuracy: 0.2072\n",
      "Epoch 19/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2003 - val_loss: 0.1421 - val_accuracy: 0.2260\n",
      "Epoch 20/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2032 - val_loss: 0.1421 - val_accuracy: 0.2263\n",
      "Epoch 21/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2021 - val_loss: 0.1421 - val_accuracy: 0.2240\n",
      "Epoch 22/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2024 - val_loss: 0.1421 - val_accuracy: 0.2299\n",
      "Epoch 23/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2038 - val_loss: 0.1421 - val_accuracy: 0.2194\n",
      "Epoch 24/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2012 - val_loss: 0.1421 - val_accuracy: 0.2259\n",
      "Epoch 25/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2048 - val_loss: 0.1421 - val_accuracy: 0.2242\n",
      "Epoch 26/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2032 - val_loss: 0.1421 - val_accuracy: 0.2307\n",
      "Epoch 27/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2066 - val_loss: 0.1421 - val_accuracy: 0.2238\n",
      "Epoch 28/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2061 - val_loss: 0.1421 - val_accuracy: 0.2251\n",
      "Epoch 29/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2057 - val_loss: 0.1421 - val_accuracy: 0.2007\n",
      "Epoch 30/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2048 - val_loss: 0.1421 - val_accuracy: 0.2080\n",
      "Epoch 31/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2081 - val_loss: 0.1421 - val_accuracy: 0.1489\n",
      "Epoch 32/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2041 - val_loss: 0.1421 - val_accuracy: 0.1978\n",
      "Epoch 33/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2059 - val_loss: 0.1421 - val_accuracy: 0.2078\n",
      "Epoch 34/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2053 - val_loss: 0.1421 - val_accuracy: 0.1975\n",
      "Epoch 35/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2063 - val_loss: 0.1421 - val_accuracy: 0.2315\n",
      "Epoch 36/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2048 - val_loss: 0.1421 - val_accuracy: 0.1854\n",
      "Epoch 37/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2061 - val_loss: 0.1421 - val_accuracy: 0.2212\n",
      "Epoch 38/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2054 - val_loss: 0.1421 - val_accuracy: 0.2013\n",
      "Epoch 39/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2078 - val_loss: 0.1421 - val_accuracy: 0.1931\n",
      "Epoch 40/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2060 - val_loss: 0.1421 - val_accuracy: 0.2230\n",
      "Epoch 41/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.2075 - val_loss: 0.1421 - val_accuracy: 0.2290\n",
      "Epoch 42/100\n",
      "57527/57527 [==============================] - 4s 63us/step - loss: 0.1425 - accuracy: 0.2075 - val_loss: 0.1421 - val_accuracy: 0.2242\n",
      "Epoch 43/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2084 - val_loss: 0.1421 - val_accuracy: 0.2238\n",
      "Epoch 44/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2060 - val_loss: 0.1421 - val_accuracy: 0.2238\n",
      "Epoch 45/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2075 - val_loss: 0.1421 - val_accuracy: 0.2314\n",
      "Epoch 46/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2075 - val_loss: 0.1421 - val_accuracy: 0.2306\n",
      "Epoch 47/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2094 - val_loss: 0.1421 - val_accuracy: 0.2268\n",
      "Epoch 48/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2082 - val_loss: 0.1421 - val_accuracy: 0.2267\n",
      "Epoch 49/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2058 - val_loss: 0.1421 - val_accuracy: 0.2071\n",
      "Epoch 50/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2074 - val_loss: 0.1421 - val_accuracy: 0.2322\n",
      "Epoch 51/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2095 - val_loss: 0.1421 - val_accuracy: 0.2299\n",
      "Epoch 52/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2082 - val_loss: 0.1421 - val_accuracy: 0.2158\n",
      "Epoch 53/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2064 - val_loss: 0.1421 - val_accuracy: 0.2136\n",
      "Epoch 54/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2088 - val_loss: 0.1421 - val_accuracy: 0.2297\n",
      "Epoch 55/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2088 - val_loss: 0.1421 - val_accuracy: 0.2225\n",
      "Epoch 56/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2099 - val_loss: 0.1421 - val_accuracy: 0.2238\n",
      "Epoch 57/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2091 - val_loss: 0.1421 - val_accuracy: 0.2235\n",
      "Epoch 58/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2076 - val_loss: 0.1421 - val_accuracy: 0.2300\n",
      "Epoch 59/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2098 - val_loss: 0.1421 - val_accuracy: 0.2153\n",
      "Epoch 60/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2098 - val_loss: 0.1421 - val_accuracy: 0.2288\n",
      "Epoch 61/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2086 - val_loss: 0.1421 - val_accuracy: 0.2158\n",
      "Epoch 62/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2091 - val_loss: 0.1421 - val_accuracy: 0.2262\n",
      "Epoch 63/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2082 - val_loss: 0.1421 - val_accuracy: 0.2332\n",
      "Epoch 64/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2094 - val_loss: 0.1421 - val_accuracy: 0.2280\n",
      "Epoch 65/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2094 - val_loss: 0.1421 - val_accuracy: 0.2328\n",
      "Epoch 66/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2104 - val_loss: 0.1420 - val_accuracy: 0.2170\n",
      "Epoch 67/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2106 - val_loss: 0.1420 - val_accuracy: 0.2178\n",
      "Epoch 68/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2122 - val_loss: 0.1420 - val_accuracy: 0.2055\n",
      "Epoch 69/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2092 - val_loss: 0.1420 - val_accuracy: 0.1674\n",
      "Epoch 70/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2094 - val_loss: 0.1420 - val_accuracy: 0.2316\n",
      "Epoch 71/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2114 - val_loss: 0.1420 - val_accuracy: 0.2300\n",
      "Epoch 72/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2118 - val_loss: 0.1420 - val_accuracy: 0.2206\n",
      "Epoch 73/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2123 - val_loss: 0.1420 - val_accuracy: 0.2192\n",
      "Epoch 74/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2133 - val_loss: 0.1420 - val_accuracy: 0.2245\n",
      "Epoch 75/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2123 - val_loss: 0.1420 - val_accuracy: 0.2301\n",
      "Epoch 76/100\n",
      "57527/57527 [==============================] - 4s 61us/step - loss: 0.1425 - accuracy: 0.2127 - val_loss: 0.1420 - val_accuracy: 0.2320\n",
      "Epoch 77/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2114 - val_loss: 0.1420 - val_accuracy: 0.2138\n",
      "Epoch 78/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2099 - val_loss: 0.1420 - val_accuracy: 0.2284\n",
      "Epoch 79/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2123 - val_loss: 0.1420 - val_accuracy: 0.2311\n",
      "Epoch 80/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2130 - val_loss: 0.1420 - val_accuracy: 0.2257\n",
      "Epoch 81/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2116 - val_loss: 0.1420 - val_accuracy: 0.2234\n",
      "Epoch 82/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2127 - val_loss: 0.1420 - val_accuracy: 0.2197\n",
      "Epoch 83/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2119 - val_loss: 0.1420 - val_accuracy: 0.2027\n",
      "Epoch 84/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2122 - val_loss: 0.1420 - val_accuracy: 0.2262\n",
      "Epoch 85/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2117 - val_loss: 0.1420 - val_accuracy: 0.2317\n",
      "Epoch 86/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2110 - val_loss: 0.1420 - val_accuracy: 0.2302\n",
      "Epoch 87/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2104 - val_loss: 0.1420 - val_accuracy: 0.2263\n",
      "Epoch 88/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2128 - val_loss: 0.1420 - val_accuracy: 0.2306\n",
      "Epoch 89/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2131 - val_loss: 0.1420 - val_accuracy: 0.1999\n",
      "Epoch 90/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2144 - val_loss: 0.1420 - val_accuracy: 0.2310\n",
      "Epoch 91/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2133 - val_loss: 0.1420 - val_accuracy: 0.1964\n",
      "Epoch 92/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2137 - val_loss: 0.1420 - val_accuracy: 0.2128\n",
      "Epoch 93/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1425 - accuracy: 0.2125 - val_loss: 0.1420 - val_accuracy: 0.2305\n",
      "Epoch 94/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.1425 - accuracy: 0.2128 - val_loss: 0.1420 - val_accuracy: 0.2297\n",
      "Epoch 95/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2110 - val_loss: 0.1420 - val_accuracy: 0.2135\n",
      "Epoch 96/100\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1425 - accuracy: 0.2126 - val_loss: 0.1420 - val_accuracy: 0.2226\n",
      "Epoch 97/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2134 - val_loss: 0.1420 - val_accuracy: 0.2094\n",
      "Epoch 98/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2126 - val_loss: 0.1420 - val_accuracy: 0.2210\n",
      "Epoch 99/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2127 - val_loss: 0.1420 - val_accuracy: 0.2295\n",
      "Epoch 100/100\n",
      "57527/57527 [==============================] - 3s 60us/step - loss: 0.1425 - accuracy: 0.2141 - val_loss: 0.1420 - val_accuracy: 0.2101\n",
      "training model-6\n",
      "Train on 57527 samples, validate on 14382 samples\n",
      "Epoch 1/100\n",
      "57527/57527 [==============================] - 11s 195us/step - loss: 0.1435 - accuracy: 0.1557 - val_loss: 0.1423 - val_accuracy: 0.1572\n",
      "Epoch 2/100\n",
      "57527/57527 [==============================] - 10s 172us/step - loss: 0.1427 - accuracy: 0.1706 - val_loss: 0.1422 - val_accuracy: 0.1885\n",
      "Epoch 3/100\n",
      "57527/57527 [==============================] - 10s 171us/step - loss: 0.1426 - accuracy: 0.1800 - val_loss: 0.1421 - val_accuracy: 0.1898\n",
      "Epoch 4/100\n",
      "57527/57527 [==============================] - 10s 175us/step - loss: 0.1425 - accuracy: 0.1814 - val_loss: 0.1421 - val_accuracy: 0.1910\n",
      "Epoch 5/100\n",
      "57527/57527 [==============================] - 10s 169us/step - loss: 0.1425 - accuracy: 0.1868 - val_loss: 0.1421 - val_accuracy: 0.2204\n",
      "Epoch 6/100\n",
      "57527/57527 [==============================] - 10s 170us/step - loss: 0.1425 - accuracy: 0.1880 - val_loss: 0.1421 - val_accuracy: 0.2125\n",
      "Epoch 7/100\n",
      "57527/57527 [==============================] - 10s 171us/step - loss: 0.1425 - accuracy: 0.1887 - val_loss: 0.1421 - val_accuracy: 0.2139\n",
      "Epoch 8/100\n",
      "57527/57527 [==============================] - 10s 171us/step - loss: 0.1425 - accuracy: 0.1934 - val_loss: 0.1421 - val_accuracy: 0.2060\n",
      "Epoch 9/100\n",
      "57527/57527 [==============================] - 10s 170us/step - loss: 0.1425 - accuracy: 0.1951 - val_loss: 0.1421 - val_accuracy: 0.2160\n",
      "Epoch 10/100\n",
      "57527/57527 [==============================] - 10s 175us/step - loss: 0.1425 - accuracy: 0.1956 - val_loss: 0.1421 - val_accuracy: 0.2074\n",
      "Epoch 11/100\n",
      "57527/57527 [==============================] - 10s 177us/step - loss: 0.1425 - accuracy: 0.1966 - val_loss: 0.1421 - val_accuracy: 0.2123\n",
      "Epoch 12/100\n",
      "57527/57527 [==============================] - 10s 173us/step - loss: 0.1425 - accuracy: 0.1980 - val_loss: 0.1420 - val_accuracy: 0.2308\n",
      "Epoch 13/100\n",
      "57527/57527 [==============================] - 10s 168us/step - loss: 0.1425 - accuracy: 0.1992 - val_loss: 0.1420 - val_accuracy: 0.2245\n",
      "Epoch 14/100\n",
      "57527/57527 [==============================] - 10s 172us/step - loss: 0.1425 - accuracy: 0.2002 - val_loss: 0.1420 - val_accuracy: 0.1849\n",
      "Epoch 15/100\n",
      "57527/57527 [==============================] - 10s 176us/step - loss: 0.1425 - accuracy: 0.2021 - val_loss: 0.1420 - val_accuracy: 0.1851\n",
      "Epoch 16/100\n",
      "57527/57527 [==============================] - 11s 189us/step - loss: 0.1425 - accuracy: 0.2035 - val_loss: 0.1421 - val_accuracy: 0.2123\n",
      "Epoch 17/100\n",
      "57527/57527 [==============================] - 10s 174us/step - loss: 0.1425 - accuracy: 0.2004 - val_loss: 0.1420 - val_accuracy: 0.2233\n",
      "Epoch 18/100\n",
      "57527/57527 [==============================] - 10s 178us/step - loss: 0.1425 - accuracy: 0.2026 - val_loss: 0.1420 - val_accuracy: 0.1539\n",
      "Epoch 19/100\n",
      "57527/57527 [==============================] - 10s 172us/step - loss: 0.1425 - accuracy: 0.2019 - val_loss: 0.1420 - val_accuracy: 0.2261\n",
      "Epoch 20/100\n",
      "57527/57527 [==============================] - 10s 168us/step - loss: 0.1425 - accuracy: 0.2031 - val_loss: 0.1420 - val_accuracy: 0.2313\n",
      "Epoch 21/100\n",
      "57527/57527 [==============================] - 10s 171us/step - loss: 0.1425 - accuracy: 0.2025 - val_loss: 0.1420 - val_accuracy: 0.2101\n",
      "Epoch 22/100\n",
      "57527/57527 [==============================] - 10s 178us/step - loss: 0.1425 - accuracy: 0.2037 - val_loss: 0.1420 - val_accuracy: 0.1853\n",
      "Epoch 23/100\n",
      "57527/57527 [==============================] - 10s 175us/step - loss: 0.1425 - accuracy: 0.2049 - val_loss: 0.1420 - val_accuracy: 0.2210\n",
      "Epoch 24/100\n",
      "57527/57527 [==============================] - 10s 171us/step - loss: 0.1425 - accuracy: 0.2045 - val_loss: 0.1420 - val_accuracy: 0.1964\n",
      "Epoch 25/100\n",
      "57527/57527 [==============================] - 10s 169us/step - loss: 0.1425 - accuracy: 0.2020 - val_loss: 0.1420 - val_accuracy: 0.2278\n",
      "Epoch 26/100\n",
      "57527/57527 [==============================] - 10s 173us/step - loss: 0.1425 - accuracy: 0.2059 - val_loss: 0.1420 - val_accuracy: 0.2252\n",
      "Epoch 27/100\n",
      "57527/57527 [==============================] - 10s 172us/step - loss: 0.1425 - accuracy: 0.2043 - val_loss: 0.1420 - val_accuracy: 0.2322\n",
      "Epoch 28/100\n",
      "57527/57527 [==============================] - 10s 174us/step - loss: 0.1425 - accuracy: 0.2054 - val_loss: 0.1420 - val_accuracy: 0.2208\n",
      "Epoch 29/100\n",
      "57527/57527 [==============================] - 10s 173us/step - loss: 0.1425 - accuracy: 0.2032 - val_loss: 0.1420 - val_accuracy: 0.1895\n",
      "Epoch 30/100\n",
      "57527/57527 [==============================] - 10s 174us/step - loss: 0.1425 - accuracy: 0.2029 - val_loss: 0.1420 - val_accuracy: 0.1604\n",
      "Epoch 31/100\n",
      "57527/57527 [==============================] - 10s 172us/step - loss: 0.1425 - accuracy: 0.2053 - val_loss: 0.1420 - val_accuracy: 0.2217\n",
      "Epoch 32/100\n",
      "57527/57527 [==============================] - 10s 171us/step - loss: 0.1425 - accuracy: 0.2022 - val_loss: 0.1420 - val_accuracy: 0.2254\n",
      "Epoch 33/100\n",
      "57527/57527 [==============================] - 10s 175us/step - loss: 0.1425 - accuracy: 0.2036 - val_loss: 0.1420 - val_accuracy: 0.2042\n",
      "Epoch 34/100\n",
      "57527/57527 [==============================] - 11s 187us/step - loss: 0.1425 - accuracy: 0.2023 - val_loss: 0.1420 - val_accuracy: 0.2193\n",
      "Epoch 35/100\n",
      "57527/57527 [==============================] - 10s 174us/step - loss: 0.1425 - accuracy: 0.2031 - val_loss: 0.1420 - val_accuracy: 0.2240\n",
      "Epoch 36/100\n",
      "57527/57527 [==============================] - 10s 174us/step - loss: 0.1425 - accuracy: 0.2054 - val_loss: 0.1420 - val_accuracy: 0.2226\n",
      "Epoch 37/100\n",
      "57527/57527 [==============================] - 10s 171us/step - loss: 0.1425 - accuracy: 0.2017 - val_loss: 0.1420 - val_accuracy: 0.2152\n",
      "Epoch 38/100\n",
      "57527/57527 [==============================] - 10s 172us/step - loss: 0.1425 - accuracy: 0.2029 - val_loss: 0.1420 - val_accuracy: 0.2280\n",
      "Epoch 39/100\n",
      "57527/57527 [==============================] - 10s 169us/step - loss: 0.1424 - accuracy: 0.2076 - val_loss: 0.1420 - val_accuracy: 0.2320\n",
      "Epoch 40/100\n",
      "57527/57527 [==============================] - 10s 176us/step - loss: 0.1425 - accuracy: 0.2033 - val_loss: 0.1420 - val_accuracy: 0.2317\n",
      "Epoch 41/100\n",
      "57527/57527 [==============================] - 10s 169us/step - loss: 0.1424 - accuracy: 0.2084 - val_loss: 0.1420 - val_accuracy: 0.2174\n",
      "Epoch 42/100\n",
      "57527/57527 [==============================] - 10s 173us/step - loss: 0.1424 - accuracy: 0.2076 - val_loss: 0.1420 - val_accuracy: 0.2301\n",
      "Epoch 43/100\n",
      "57527/57527 [==============================] - 10s 172us/step - loss: 0.1424 - accuracy: 0.2049 - val_loss: 0.1420 - val_accuracy: 0.2142\n",
      "Epoch 44/100\n",
      "57527/57527 [==============================] - 10s 171us/step - loss: 0.1424 - accuracy: 0.2066 - val_loss: 0.1420 - val_accuracy: 0.1831\n",
      "Epoch 45/100\n",
      "57527/57527 [==============================] - 10s 171us/step - loss: 0.1424 - accuracy: 0.2073 - val_loss: 0.1420 - val_accuracy: 0.2206\n",
      "Epoch 46/100\n",
      "57527/57527 [==============================] - 10s 174us/step - loss: 0.1424 - accuracy: 0.2068 - val_loss: 0.1420 - val_accuracy: 0.2318\n",
      "Epoch 47/100\n",
      "57527/57527 [==============================] - 10s 171us/step - loss: 0.1424 - accuracy: 0.2051 - val_loss: 0.1420 - val_accuracy: 0.2284\n",
      "Epoch 48/100\n",
      "57527/57527 [==============================] - 10s 174us/step - loss: 0.1424 - accuracy: 0.2064 - val_loss: 0.1420 - val_accuracy: 0.1877\n",
      "Epoch 49/100\n",
      "57527/57527 [==============================] - 10s 169us/step - loss: 0.1424 - accuracy: 0.2063 - val_loss: 0.1420 - val_accuracy: 0.2212\n",
      "Epoch 50/100\n",
      "57527/57527 [==============================] - 10s 168us/step - loss: 0.1424 - accuracy: 0.2067 - val_loss: 0.1420 - val_accuracy: 0.1624\n",
      "Epoch 51/100\n",
      "57527/57527 [==============================] - 10s 170us/step - loss: 0.1424 - accuracy: 0.2050 - val_loss: 0.1420 - val_accuracy: 0.2309\n",
      "Epoch 52/100\n",
      "57527/57527 [==============================] - 12s 203us/step - loss: 0.1424 - accuracy: 0.2063 - val_loss: 0.1420 - val_accuracy: 0.2317\n",
      "Epoch 53/100\n",
      "57527/57527 [==============================] - 11s 190us/step - loss: 0.1424 - accuracy: 0.2070 - val_loss: 0.1420 - val_accuracy: 0.2165\n",
      "Epoch 54/100\n",
      "57527/57527 [==============================] - 11s 184us/step - loss: 0.1424 - accuracy: 0.2047 - val_loss: 0.1420 - val_accuracy: 0.2249\n",
      "Epoch 55/100\n",
      "57527/57527 [==============================] - 10s 180us/step - loss: 0.1424 - accuracy: 0.2098 - val_loss: 0.1420 - val_accuracy: 0.2206\n",
      "Epoch 56/100\n",
      "57527/57527 [==============================] - 10s 169us/step - loss: 0.1424 - accuracy: 0.2055 - val_loss: 0.1421 - val_accuracy: 0.2162\n",
      "Epoch 57/100\n",
      "57527/57527 [==============================] - 10s 172us/step - loss: 0.1424 - accuracy: 0.2047 - val_loss: 0.1420 - val_accuracy: 0.2115\n",
      "Epoch 58/100\n",
      "57527/57527 [==============================] - 10s 178us/step - loss: 0.1424 - accuracy: 0.2060 - val_loss: 0.1420 - val_accuracy: 0.2202\n",
      "Epoch 59/100\n",
      "57527/57527 [==============================] - 10s 178us/step - loss: 0.1424 - accuracy: 0.2065 - val_loss: 0.1420 - val_accuracy: 0.2105\n",
      "Epoch 60/100\n",
      "57527/57527 [==============================] - 10s 172us/step - loss: 0.1424 - accuracy: 0.2077 - val_loss: 0.1420 - val_accuracy: 0.2261\n",
      "Epoch 61/100\n",
      "57527/57527 [==============================] - 10s 171us/step - loss: 0.1424 - accuracy: 0.2060 - val_loss: 0.1420 - val_accuracy: 0.1973\n",
      "Epoch 62/100\n",
      "57527/57527 [==============================] - 10s 168us/step - loss: 0.1424 - accuracy: 0.2075 - val_loss: 0.1420 - val_accuracy: 0.2089\n",
      "Epoch 63/100\n",
      "57527/57527 [==============================] - 10s 174us/step - loss: 0.1424 - accuracy: 0.2053 - val_loss: 0.1420 - val_accuracy: 0.2242\n",
      "Epoch 64/100\n",
      "57527/57527 [==============================] - 10s 176us/step - loss: 0.1424 - accuracy: 0.2089 - val_loss: 0.1420 - val_accuracy: 0.2295\n",
      "Epoch 65/100\n",
      "57527/57527 [==============================] - 10s 172us/step - loss: 0.1424 - accuracy: 0.2073 - val_loss: 0.1420 - val_accuracy: 0.2316\n",
      "Epoch 66/100\n",
      "57527/57527 [==============================] - 10s 174us/step - loss: 0.1424 - accuracy: 0.2064 - val_loss: 0.1420 - val_accuracy: 0.2322\n",
      "Epoch 67/100\n",
      "57527/57527 [==============================] - 10s 170us/step - loss: 0.1424 - accuracy: 0.2054 - val_loss: 0.1420 - val_accuracy: 0.2238\n",
      "Epoch 68/100\n",
      "57527/57527 [==============================] - 10s 171us/step - loss: 0.1424 - accuracy: 0.2074 - val_loss: 0.1420 - val_accuracy: 0.2083\n",
      "Epoch 69/100\n",
      "57527/57527 [==============================] - 10s 181us/step - loss: 0.1424 - accuracy: 0.2054 - val_loss: 0.1420 - val_accuracy: 0.2251\n",
      "Epoch 70/100\n",
      "57527/57527 [==============================] - 10s 181us/step - loss: 0.1424 - accuracy: 0.2072 - val_loss: 0.1420 - val_accuracy: 0.2231\n",
      "Epoch 71/100\n",
      "57527/57527 [==============================] - 10s 173us/step - loss: 0.1424 - accuracy: 0.2078 - val_loss: 0.1420 - val_accuracy: 0.2303\n",
      "Epoch 72/100\n",
      "57527/57527 [==============================] - 10s 177us/step - loss: 0.1424 - accuracy: 0.2067 - val_loss: 0.1420 - val_accuracy: 0.2072\n",
      "Epoch 73/100\n",
      "57527/57527 [==============================] - 10s 178us/step - loss: 0.1424 - accuracy: 0.2062 - val_loss: 0.1420 - val_accuracy: 0.2057\n",
      "Epoch 74/100\n",
      "57527/57527 [==============================] - 11s 184us/step - loss: 0.1424 - accuracy: 0.2084 - val_loss: 0.1420 - val_accuracy: 0.2080\n",
      "Epoch 75/100\n",
      "57527/57527 [==============================] - 11s 189us/step - loss: 0.1424 - accuracy: 0.2080 - val_loss: 0.1420 - val_accuracy: 0.2304\n",
      "Epoch 76/100\n",
      "57527/57527 [==============================] - 11s 193us/step - loss: 0.1424 - accuracy: 0.2091 - val_loss: 0.1420 - val_accuracy: 0.2253\n",
      "Epoch 77/100\n",
      "57527/57527 [==============================] - 11s 191us/step - loss: 0.1424 - accuracy: 0.2054 - val_loss: 0.1420 - val_accuracy: 0.2300\n",
      "Epoch 78/100\n",
      "57527/57527 [==============================] - 10s 182us/step - loss: 0.1424 - accuracy: 0.2077 - val_loss: 0.1420 - val_accuracy: 0.2230\n",
      "Epoch 79/100\n",
      "57527/57527 [==============================] - 11s 184us/step - loss: 0.1424 - accuracy: 0.2077 - val_loss: 0.1420 - val_accuracy: 0.1936\n",
      "Epoch 80/100\n",
      "57527/57527 [==============================] - 10s 181us/step - loss: 0.1424 - accuracy: 0.2084 - val_loss: 0.1420 - val_accuracy: 0.2142\n",
      "Epoch 81/100\n",
      "57527/57527 [==============================] - 11s 193us/step - loss: 0.1424 - accuracy: 0.2087 - val_loss: 0.1420 - val_accuracy: 0.1799\n",
      "Epoch 82/100\n",
      "57527/57527 [==============================] - 11s 183us/step - loss: 0.1424 - accuracy: 0.2084 - val_loss: 0.1420 - val_accuracy: 0.2041\n",
      "Epoch 83/100\n",
      "57527/57527 [==============================] - 11s 187us/step - loss: 0.1424 - accuracy: 0.2071 - val_loss: 0.1420 - val_accuracy: 0.2314\n",
      "Epoch 84/100\n",
      "57527/57527 [==============================] - 11s 185us/step - loss: 0.1424 - accuracy: 0.2051 - val_loss: 0.1420 - val_accuracy: 0.1877\n",
      "Epoch 85/100\n",
      "57527/57527 [==============================] - 11s 186us/step - loss: 0.1424 - accuracy: 0.2071 - val_loss: 0.1420 - val_accuracy: 0.1943\n",
      "Epoch 86/100\n",
      "57527/57527 [==============================] - 11s 198us/step - loss: 0.1424 - accuracy: 0.2064 - val_loss: 0.1420 - val_accuracy: 0.2078\n",
      "Epoch 87/100\n",
      "57527/57527 [==============================] - 11s 188us/step - loss: 0.1424 - accuracy: 0.2092 - val_loss: 0.1420 - val_accuracy: 0.2011\n",
      "Epoch 88/100\n",
      "57527/57527 [==============================] - 11s 189us/step - loss: 0.1424 - accuracy: 0.2077 - val_loss: 0.1420 - val_accuracy: 0.2320\n",
      "Epoch 89/100\n",
      "57527/57527 [==============================] - 11s 184us/step - loss: 0.1424 - accuracy: 0.2076 - val_loss: 0.1420 - val_accuracy: 0.2267\n",
      "Epoch 90/100\n",
      "57527/57527 [==============================] - 10s 182us/step - loss: 0.1424 - accuracy: 0.2072 - val_loss: 0.1420 - val_accuracy: 0.1853\n",
      "Epoch 91/100\n",
      "57527/57527 [==============================] - 10s 181us/step - loss: 0.1424 - accuracy: 0.2076 - val_loss: 0.1420 - val_accuracy: 0.2270\n",
      "Epoch 92/100\n",
      "57527/57527 [==============================] - 11s 188us/step - loss: 0.1424 - accuracy: 0.2059 - val_loss: 0.1420 - val_accuracy: 0.2304\n",
      "Epoch 93/100\n",
      "57527/57527 [==============================] - 11s 183us/step - loss: 0.1424 - accuracy: 0.2067 - val_loss: 0.1420 - val_accuracy: 0.2140\n",
      "Epoch 94/100\n",
      "57527/57527 [==============================] - 11s 186us/step - loss: 0.1424 - accuracy: 0.2089 - val_loss: 0.1420 - val_accuracy: 0.2233\n",
      "Epoch 95/100\n",
      "57527/57527 [==============================] - 11s 187us/step - loss: 0.1424 - accuracy: 0.2078 - val_loss: 0.1420 - val_accuracy: 0.2326\n",
      "Epoch 96/100\n",
      "57527/57527 [==============================] - 11s 190us/step - loss: 0.1424 - accuracy: 0.2064 - val_loss: 0.1420 - val_accuracy: 0.2315\n",
      "Epoch 97/100\n",
      "57527/57527 [==============================] - 11s 188us/step - loss: 0.1424 - accuracy: 0.2075 - val_loss: 0.1420 - val_accuracy: 0.2190\n",
      "Epoch 98/100\n",
      "57527/57527 [==============================] - 11s 190us/step - loss: 0.1424 - accuracy: 0.2075 - val_loss: 0.1420 - val_accuracy: 0.2310\n",
      "Epoch 99/100\n",
      "57527/57527 [==============================] - 11s 188us/step - loss: 0.1424 - accuracy: 0.2086 - val_loss: 0.1420 - val_accuracy: 0.2267\n",
      "Epoch 100/100\n",
      "57527/57527 [==============================] - 11s 186us/step - loss: 0.1424 - accuracy: 0.2070 - val_loss: 0.1420 - val_accuracy: 0.2283\n",
      "training model-7\n",
      "Train on 57527 samples, validate on 14382 samples\n",
      "Epoch 1/100\n",
      "57527/57527 [==============================] - 5s 89us/step - loss: 0.1454 - accuracy: 0.1876 - val_loss: 0.1439 - val_accuracy: 0.1982\n",
      "Epoch 2/100\n",
      "57527/57527 [==============================] - 4s 63us/step - loss: 0.1441 - accuracy: 0.1750 - val_loss: 0.1429 - val_accuracy: 0.1372\n",
      "Epoch 3/100\n",
      "57527/57527 [==============================] - 4s 63us/step - loss: 0.1433 - accuracy: 0.1562 - val_loss: 0.1427 - val_accuracy: 0.1886\n",
      "Epoch 4/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1432 - accuracy: 0.1569 - val_loss: 0.1426 - val_accuracy: 0.1806\n",
      "Epoch 5/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1431 - accuracy: 0.1531 - val_loss: 0.1425 - val_accuracy: 0.1822\n",
      "Epoch 6/100\n",
      "57527/57527 [==============================] - 4s 75us/step - loss: 0.1430 - accuracy: 0.1555 - val_loss: 0.1425 - val_accuracy: 0.1585\n",
      "Epoch 7/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1430 - accuracy: 0.1559 - val_loss: 0.1424 - val_accuracy: 0.1603\n",
      "Epoch 8/100\n",
      "57527/57527 [==============================] - 4s 63us/step - loss: 0.1429 - accuracy: 0.1542 - val_loss: 0.1424 - val_accuracy: 0.1576\n",
      "Epoch 9/100\n",
      "57527/57527 [==============================] - 4s 63us/step - loss: 0.1429 - accuracy: 0.1580 - val_loss: 0.1423 - val_accuracy: 0.1400\n",
      "Epoch 10/100\n",
      "57527/57527 [==============================] - 4s 63us/step - loss: 0.1429 - accuracy: 0.1583 - val_loss: 0.1423 - val_accuracy: 0.1909\n",
      "Epoch 11/100\n",
      "57527/57527 [==============================] - 4s 63us/step - loss: 0.1428 - accuracy: 0.1622 - val_loss: 0.1423 - val_accuracy: 0.1999\n",
      "Epoch 12/100\n",
      "57527/57527 [==============================] - 4s 63us/step - loss: 0.1428 - accuracy: 0.1635 - val_loss: 0.1423 - val_accuracy: 0.1401\n",
      "Epoch 13/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1428 - accuracy: 0.1660 - val_loss: 0.1423 - val_accuracy: 0.2005\n",
      "Epoch 14/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1428 - accuracy: 0.1682 - val_loss: 0.1423 - val_accuracy: 0.2041\n",
      "Epoch 15/100\n",
      "57527/57527 [==============================] - 4s 63us/step - loss: 0.1428 - accuracy: 0.1721 - val_loss: 0.1423 - val_accuracy: 0.1756\n",
      "Epoch 16/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1428 - accuracy: 0.1721 - val_loss: 0.1422 - val_accuracy: 0.1934\n",
      "Epoch 17/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1428 - accuracy: 0.1772 - val_loss: 0.1422 - val_accuracy: 0.2157\n",
      "Epoch 18/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1427 - accuracy: 0.1799 - val_loss: 0.1422 - val_accuracy: 0.1633\n",
      "Epoch 19/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1427 - accuracy: 0.1820 - val_loss: 0.1422 - val_accuracy: 0.1806\n",
      "Epoch 20/100\n",
      "57527/57527 [==============================] - 4s 63us/step - loss: 0.1427 - accuracy: 0.1839 - val_loss: 0.1422 - val_accuracy: 0.1899\n",
      "Epoch 21/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1427 - accuracy: 0.1872 - val_loss: 0.1422 - val_accuracy: 0.2179\n",
      "Epoch 22/100\n",
      "57527/57527 [==============================] - 4s 63us/step - loss: 0.1427 - accuracy: 0.1886 - val_loss: 0.1422 - val_accuracy: 0.2162\n",
      "Epoch 23/100\n",
      "57527/57527 [==============================] - 4s 64us/step - loss: 0.1427 - accuracy: 0.1904 - val_loss: 0.1422 - val_accuracy: 0.2212\n",
      "Epoch 24/100\n",
      "57527/57527 [==============================] - 4s 63us/step - loss: 0.1427 - accuracy: 0.1917 - val_loss: 0.1422 - val_accuracy: 0.2178\n",
      "Epoch 25/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1427 - accuracy: 0.1945 - val_loss: 0.1422 - val_accuracy: 0.2321\n",
      "Epoch 26/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1427 - accuracy: 0.1953 - val_loss: 0.1422 - val_accuracy: 0.2304\n",
      "Epoch 27/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1427 - accuracy: 0.1940 - val_loss: 0.1422 - val_accuracy: 0.2252\n",
      "Epoch 28/100\n",
      "57527/57527 [==============================] - 4s 63us/step - loss: 0.1427 - accuracy: 0.1964 - val_loss: 0.1422 - val_accuracy: 0.2225\n",
      "Epoch 29/100\n",
      "57527/57527 [==============================] - 4s 63us/step - loss: 0.1427 - accuracy: 0.1953 - val_loss: 0.1422 - val_accuracy: 0.2092\n",
      "Epoch 30/100\n",
      "57527/57527 [==============================] - 4s 63us/step - loss: 0.1427 - accuracy: 0.1941 - val_loss: 0.1422 - val_accuracy: 0.2292\n",
      "Epoch 31/100\n",
      "57527/57527 [==============================] - 4s 63us/step - loss: 0.1427 - accuracy: 0.1992 - val_loss: 0.1422 - val_accuracy: 0.2315\n",
      "Epoch 32/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1427 - accuracy: 0.1970 - val_loss: 0.1422 - val_accuracy: 0.2234\n",
      "Epoch 33/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1427 - accuracy: 0.1937 - val_loss: 0.1422 - val_accuracy: 0.1809\n",
      "Epoch 34/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1427 - accuracy: 0.1968 - val_loss: 0.1422 - val_accuracy: 0.2183\n",
      "Epoch 35/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1427 - accuracy: 0.1981 - val_loss: 0.1422 - val_accuracy: 0.2308\n",
      "Epoch 36/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1427 - accuracy: 0.1987 - val_loss: 0.1422 - val_accuracy: 0.1760\n",
      "Epoch 37/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1427 - accuracy: 0.1981 - val_loss: 0.1422 - val_accuracy: 0.2249\n",
      "Epoch 38/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1427 - accuracy: 0.1963 - val_loss: 0.1422 - val_accuracy: 0.2257\n",
      "Epoch 39/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1427 - accuracy: 0.1968 - val_loss: 0.1422 - val_accuracy: 0.2083\n",
      "Epoch 40/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1427 - accuracy: 0.2012 - val_loss: 0.1422 - val_accuracy: 0.2188\n",
      "Epoch 41/100\n",
      "57527/57527 [==============================] - 4s 63us/step - loss: 0.1427 - accuracy: 0.1991 - val_loss: 0.1422 - val_accuracy: 0.2327\n",
      "Epoch 42/100\n",
      "57527/57527 [==============================] - 4s 63us/step - loss: 0.1427 - accuracy: 0.2010 - val_loss: 0.1422 - val_accuracy: 0.2317\n",
      "Epoch 43/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1427 - accuracy: 0.2005 - val_loss: 0.1422 - val_accuracy: 0.2331\n",
      "Epoch 44/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1427 - accuracy: 0.1980 - val_loss: 0.1422 - val_accuracy: 0.2041\n",
      "Epoch 45/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1427 - accuracy: 0.1999 - val_loss: 0.1422 - val_accuracy: 0.2320\n",
      "Epoch 46/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1427 - accuracy: 0.2028 - val_loss: 0.1422 - val_accuracy: 0.2310\n",
      "Epoch 47/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1427 - accuracy: 0.2003 - val_loss: 0.1422 - val_accuracy: 0.2112\n",
      "Epoch 48/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1427 - accuracy: 0.2014 - val_loss: 0.1422 - val_accuracy: 0.2242\n",
      "Epoch 49/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1427 - accuracy: 0.2009 - val_loss: 0.1422 - val_accuracy: 0.2130\n",
      "Epoch 50/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1427 - accuracy: 0.2008 - val_loss: 0.1422 - val_accuracy: 0.2292\n",
      "Epoch 51/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1427 - accuracy: 0.2046 - val_loss: 0.1422 - val_accuracy: 0.2200\n",
      "Epoch 52/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1427 - accuracy: 0.2030 - val_loss: 0.1422 - val_accuracy: 0.2288\n",
      "Epoch 53/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1427 - accuracy: 0.2017 - val_loss: 0.1422 - val_accuracy: 0.2210\n",
      "Epoch 54/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1427 - accuracy: 0.2021 - val_loss: 0.1422 - val_accuracy: 0.2337\n",
      "Epoch 55/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1427 - accuracy: 0.2041 - val_loss: 0.1422 - val_accuracy: 0.2229\n",
      "Epoch 56/100\n",
      "57527/57527 [==============================] - 4s 74us/step - loss: 0.1427 - accuracy: 0.2040 - val_loss: 0.1422 - val_accuracy: 0.1966\n",
      "Epoch 57/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2023 - val_loss: 0.1422 - val_accuracy: 0.2114\n",
      "Epoch 58/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2032 - val_loss: 0.1422 - val_accuracy: 0.1966\n",
      "Epoch 59/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2038 - val_loss: 0.1422 - val_accuracy: 0.2322\n",
      "Epoch 60/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2052 - val_loss: 0.1422 - val_accuracy: 0.2052\n",
      "Epoch 61/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2039 - val_loss: 0.1422 - val_accuracy: 0.2286\n",
      "Epoch 62/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2042 - val_loss: 0.1422 - val_accuracy: 0.2128\n",
      "Epoch 63/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2040 - val_loss: 0.1422 - val_accuracy: 0.2002\n",
      "Epoch 64/100\n",
      "57527/57527 [==============================] - 4s 61us/step - loss: 0.1426 - accuracy: 0.2075 - val_loss: 0.1422 - val_accuracy: 0.2281\n",
      "Epoch 65/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2073 - val_loss: 0.1422 - val_accuracy: 0.2303\n",
      "Epoch 66/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2072 - val_loss: 0.1422 - val_accuracy: 0.2331\n",
      "Epoch 67/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2048 - val_loss: 0.1422 - val_accuracy: 0.2328\n",
      "Epoch 68/100\n",
      "57527/57527 [==============================] - 4s 63us/step - loss: 0.1426 - accuracy: 0.2076 - val_loss: 0.1422 - val_accuracy: 0.2308\n",
      "Epoch 69/100\n",
      "57527/57527 [==============================] - 4s 61us/step - loss: 0.1426 - accuracy: 0.2033 - val_loss: 0.1422 - val_accuracy: 0.2124\n",
      "Epoch 70/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2043 - val_loss: 0.1422 - val_accuracy: 0.1977\n",
      "Epoch 71/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2067 - val_loss: 0.1422 - val_accuracy: 0.2306\n",
      "Epoch 72/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2073 - val_loss: 0.1422 - val_accuracy: 0.2046\n",
      "Epoch 73/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2060 - val_loss: 0.1422 - val_accuracy: 0.2246\n",
      "Epoch 74/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2060 - val_loss: 0.1422 - val_accuracy: 0.2322\n",
      "Epoch 75/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2068 - val_loss: 0.1422 - val_accuracy: 0.2333\n",
      "Epoch 76/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2067 - val_loss: 0.1422 - val_accuracy: 0.2295\n",
      "Epoch 77/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2075 - val_loss: 0.1422 - val_accuracy: 0.2146\n",
      "Epoch 78/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2084 - val_loss: 0.1422 - val_accuracy: 0.1971\n",
      "Epoch 79/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2062 - val_loss: 0.1421 - val_accuracy: 0.2172\n",
      "Epoch 80/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2072 - val_loss: 0.1421 - val_accuracy: 0.2260\n",
      "Epoch 81/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2072 - val_loss: 0.1421 - val_accuracy: 0.2310\n",
      "Epoch 82/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2085 - val_loss: 0.1421 - val_accuracy: 0.2233\n",
      "Epoch 83/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2087 - val_loss: 0.1421 - val_accuracy: 0.2298\n",
      "Epoch 84/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2053 - val_loss: 0.1421 - val_accuracy: 0.2098\n",
      "Epoch 85/100\n",
      "57527/57527 [==============================] - 4s 61us/step - loss: 0.1426 - accuracy: 0.2089 - val_loss: 0.1421 - val_accuracy: 0.2188\n",
      "Epoch 86/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2069 - val_loss: 0.1421 - val_accuracy: 0.2240\n",
      "Epoch 87/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2099 - val_loss: 0.1421 - val_accuracy: 0.2320\n",
      "Epoch 88/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2083 - val_loss: 0.1421 - val_accuracy: 0.2183\n",
      "Epoch 89/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2087 - val_loss: 0.1421 - val_accuracy: 0.2303\n",
      "Epoch 90/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2085 - val_loss: 0.1421 - val_accuracy: 0.2322\n",
      "Epoch 91/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2085 - val_loss: 0.1421 - val_accuracy: 0.2160\n",
      "Epoch 92/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2075 - val_loss: 0.1421 - val_accuracy: 0.2301\n",
      "Epoch 93/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2090 - val_loss: 0.1421 - val_accuracy: 0.2264\n",
      "Epoch 94/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1425 - accuracy: 0.2075 - val_loss: 0.1421 - val_accuracy: 0.2265\n",
      "Epoch 95/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1426 - accuracy: 0.2110 - val_loss: 0.1421 - val_accuracy: 0.2317\n",
      "Epoch 96/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1425 - accuracy: 0.2086 - val_loss: 0.1421 - val_accuracy: 0.2028\n",
      "Epoch 97/100\n",
      "57527/57527 [==============================] - 4s 63us/step - loss: 0.1425 - accuracy: 0.2101 - val_loss: 0.1421 - val_accuracy: 0.2327\n",
      "Epoch 98/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1425 - accuracy: 0.2098 - val_loss: 0.1421 - val_accuracy: 0.2283\n",
      "Epoch 99/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1425 - accuracy: 0.2080 - val_loss: 0.1421 - val_accuracy: 0.2232\n",
      "Epoch 100/100\n",
      "57527/57527 [==============================] - 4s 62us/step - loss: 0.1425 - accuracy: 0.2094 - val_loss: 0.1421 - val_accuracy: 0.2331\n",
      "training model-8\n",
      "Train on 57527 samples, validate on 14382 samples\n",
      "Epoch 1/100\n",
      "57527/57527 [==============================] - 8s 144us/step - loss: 0.1436 - accuracy: 0.1569 - val_loss: 0.1425 - val_accuracy: 0.1405\n",
      "Epoch 2/100\n",
      "57527/57527 [==============================] - 8s 132us/step - loss: 0.1428 - accuracy: 0.1608 - val_loss: 0.1423 - val_accuracy: 0.2131\n",
      "Epoch 3/100\n",
      "57527/57527 [==============================] - 7s 125us/step - loss: 0.1427 - accuracy: 0.1729 - val_loss: 0.1422 - val_accuracy: 0.1984\n",
      "Epoch 4/100\n",
      "57527/57527 [==============================] - 7s 123us/step - loss: 0.1426 - accuracy: 0.1803 - val_loss: 0.1422 - val_accuracy: 0.2119\n",
      "Epoch 5/100\n",
      "57527/57527 [==============================] - 7s 121us/step - loss: 0.1426 - accuracy: 0.1845 - val_loss: 0.1422 - val_accuracy: 0.2178\n",
      "Epoch 6/100\n",
      "57527/57527 [==============================] - 7s 122us/step - loss: 0.1426 - accuracy: 0.1871 - val_loss: 0.1422 - val_accuracy: 0.2103\n",
      "Epoch 7/100\n",
      "57527/57527 [==============================] - 7s 121us/step - loss: 0.1426 - accuracy: 0.1914 - val_loss: 0.1422 - val_accuracy: 0.1898\n",
      "Epoch 8/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1426 - accuracy: 0.1905 - val_loss: 0.1421 - val_accuracy: 0.2224\n",
      "Epoch 9/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.1950 - val_loss: 0.1421 - val_accuracy: 0.1955\n",
      "Epoch 10/100\n",
      "57527/57527 [==============================] - 7s 118us/step - loss: 0.1425 - accuracy: 0.1940 - val_loss: 0.1421 - val_accuracy: 0.1964\n",
      "Epoch 11/100\n",
      "57527/57527 [==============================] - 7s 121us/step - loss: 0.1425 - accuracy: 0.1960 - val_loss: 0.1421 - val_accuracy: 0.1548\n",
      "Epoch 12/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.1992 - val_loss: 0.1421 - val_accuracy: 0.2244\n",
      "Epoch 13/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2005 - val_loss: 0.1421 - val_accuracy: 0.2131\n",
      "Epoch 14/100\n",
      "57527/57527 [==============================] - 7s 122us/step - loss: 0.1425 - accuracy: 0.1998 - val_loss: 0.1421 - val_accuracy: 0.1993\n",
      "Epoch 15/100\n",
      "57527/57527 [==============================] - 7s 121us/step - loss: 0.1425 - accuracy: 0.1983 - val_loss: 0.1421 - val_accuracy: 0.1612\n",
      "Epoch 16/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.1992 - val_loss: 0.1421 - val_accuracy: 0.1804\n",
      "Epoch 17/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2001 - val_loss: 0.1421 - val_accuracy: 0.2212\n",
      "Epoch 18/100\n",
      "57527/57527 [==============================] - 7s 118us/step - loss: 0.1425 - accuracy: 0.2014 - val_loss: 0.1421 - val_accuracy: 0.1773\n",
      "Epoch 19/100\n",
      "57527/57527 [==============================] - 7s 120us/step - loss: 0.1425 - accuracy: 0.2023 - val_loss: 0.1421 - val_accuracy: 0.2187\n",
      "Epoch 20/100\n",
      "57527/57527 [==============================] - 7s 120us/step - loss: 0.1425 - accuracy: 0.1991 - val_loss: 0.1421 - val_accuracy: 0.2189\n",
      "Epoch 21/100\n",
      "57527/57527 [==============================] - 7s 120us/step - loss: 0.1425 - accuracy: 0.2021 - val_loss: 0.1421 - val_accuracy: 0.2061\n",
      "Epoch 22/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2025 - val_loss: 0.1421 - val_accuracy: 0.2184\n",
      "Epoch 23/100\n",
      "57527/57527 [==============================] - 7s 118us/step - loss: 0.1425 - accuracy: 0.2009 - val_loss: 0.1421 - val_accuracy: 0.2124\n",
      "Epoch 24/100\n",
      "57527/57527 [==============================] - 7s 120us/step - loss: 0.1425 - accuracy: 0.2039 - val_loss: 0.1421 - val_accuracy: 0.2133\n",
      "Epoch 25/100\n",
      "57527/57527 [==============================] - 7s 118us/step - loss: 0.1425 - accuracy: 0.2027 - val_loss: 0.1421 - val_accuracy: 0.2162\n",
      "Epoch 26/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2019 - val_loss: 0.1421 - val_accuracy: 0.1621\n",
      "Epoch 27/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2028 - val_loss: 0.1421 - val_accuracy: 0.1886\n",
      "Epoch 28/100\n",
      "57527/57527 [==============================] - 8s 131us/step - loss: 0.1425 - accuracy: 0.2041 - val_loss: 0.1421 - val_accuracy: 0.2114\n",
      "Epoch 29/100\n",
      "57527/57527 [==============================] - 7s 123us/step - loss: 0.1425 - accuracy: 0.2041 - val_loss: 0.1421 - val_accuracy: 0.2087\n",
      "Epoch 30/100\n",
      "57527/57527 [==============================] - 7s 120us/step - loss: 0.1425 - accuracy: 0.2026 - val_loss: 0.1421 - val_accuracy: 0.2131\n",
      "Epoch 31/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2040 - val_loss: 0.1421 - val_accuracy: 0.2159\n",
      "Epoch 32/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2041 - val_loss: 0.1421 - val_accuracy: 0.2134\n",
      "Epoch 33/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2035 - val_loss: 0.1421 - val_accuracy: 0.2317\n",
      "Epoch 34/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2043 - val_loss: 0.1421 - val_accuracy: 0.2027\n",
      "Epoch 35/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2042 - val_loss: 0.1421 - val_accuracy: 0.2161\n",
      "Epoch 36/100\n",
      "57527/57527 [==============================] - 7s 118us/step - loss: 0.1425 - accuracy: 0.2035 - val_loss: 0.1421 - val_accuracy: 0.2206\n",
      "Epoch 37/100\n",
      "57527/57527 [==============================] - 7s 123us/step - loss: 0.1425 - accuracy: 0.2048 - val_loss: 0.1421 - val_accuracy: 0.2183\n",
      "Epoch 38/100\n",
      "57527/57527 [==============================] - 7s 121us/step - loss: 0.1425 - accuracy: 0.2046 - val_loss: 0.1421 - val_accuracy: 0.2321\n",
      "Epoch 39/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2057 - val_loss: 0.1421 - val_accuracy: 0.2153\n",
      "Epoch 40/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2053 - val_loss: 0.1421 - val_accuracy: 0.2242\n",
      "Epoch 41/100\n",
      "57527/57527 [==============================] - 7s 121us/step - loss: 0.1425 - accuracy: 0.2043 - val_loss: 0.1421 - val_accuracy: 0.1866\n",
      "Epoch 42/100\n",
      "57527/57527 [==============================] - 7s 120us/step - loss: 0.1425 - accuracy: 0.2063 - val_loss: 0.1421 - val_accuracy: 0.2310\n",
      "Epoch 43/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2048 - val_loss: 0.1421 - val_accuracy: 0.2123\n",
      "Epoch 44/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2068 - val_loss: 0.1421 - val_accuracy: 0.2282\n",
      "Epoch 45/100\n",
      "57527/57527 [==============================] - 7s 120us/step - loss: 0.1425 - accuracy: 0.2063 - val_loss: 0.1421 - val_accuracy: 0.2028\n",
      "Epoch 46/100\n",
      "57527/57527 [==============================] - 7s 123us/step - loss: 0.1425 - accuracy: 0.2063 - val_loss: 0.1421 - val_accuracy: 0.1871\n",
      "Epoch 47/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2067 - val_loss: 0.1421 - val_accuracy: 0.2167\n",
      "Epoch 48/100\n",
      "57527/57527 [==============================] - 7s 120us/step - loss: 0.1425 - accuracy: 0.2055 - val_loss: 0.1421 - val_accuracy: 0.2322\n",
      "Epoch 49/100\n",
      "57527/57527 [==============================] - 7s 120us/step - loss: 0.1425 - accuracy: 0.2072 - val_loss: 0.1421 - val_accuracy: 0.2239\n",
      "Epoch 50/100\n",
      "57527/57527 [==============================] - 7s 121us/step - loss: 0.1425 - accuracy: 0.2056 - val_loss: 0.1421 - val_accuracy: 0.2067\n",
      "Epoch 51/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2069 - val_loss: 0.1420 - val_accuracy: 0.2289\n",
      "Epoch 52/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2065 - val_loss: 0.1421 - val_accuracy: 0.1817\n",
      "Epoch 53/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2075 - val_loss: 0.1421 - val_accuracy: 0.1790\n",
      "Epoch 54/100\n",
      "57527/57527 [==============================] - 8s 130us/step - loss: 0.1425 - accuracy: 0.2070 - val_loss: 0.1421 - val_accuracy: 0.2221\n",
      "Epoch 55/100\n",
      "57527/57527 [==============================] - 7s 122us/step - loss: 0.1425 - accuracy: 0.2085 - val_loss: 0.1421 - val_accuracy: 0.2195\n",
      "Epoch 56/100\n",
      "57527/57527 [==============================] - 7s 120us/step - loss: 0.1425 - accuracy: 0.2069 - val_loss: 0.1420 - val_accuracy: 0.2021\n",
      "Epoch 57/100\n",
      "57527/57527 [==============================] - 7s 122us/step - loss: 0.1425 - accuracy: 0.2066 - val_loss: 0.1421 - val_accuracy: 0.2210\n",
      "Epoch 58/100\n",
      "57527/57527 [==============================] - 7s 120us/step - loss: 0.1425 - accuracy: 0.2067 - val_loss: 0.1420 - val_accuracy: 0.2167\n",
      "Epoch 59/100\n",
      "57527/57527 [==============================] - 7s 120us/step - loss: 0.1425 - accuracy: 0.2085 - val_loss: 0.1421 - val_accuracy: 0.2154\n",
      "Epoch 60/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2082 - val_loss: 0.1420 - val_accuracy: 0.2176\n",
      "Epoch 61/100\n",
      "57527/57527 [==============================] - 7s 118us/step - loss: 0.1425 - accuracy: 0.2096 - val_loss: 0.1421 - val_accuracy: 0.2057\n",
      "Epoch 62/100\n",
      "57527/57527 [==============================] - 7s 118us/step - loss: 0.1425 - accuracy: 0.2064 - val_loss: 0.1421 - val_accuracy: 0.2137\n",
      "Epoch 63/100\n",
      "57527/57527 [==============================] - 7s 120us/step - loss: 0.1425 - accuracy: 0.2063 - val_loss: 0.1421 - val_accuracy: 0.2297\n",
      "Epoch 64/100\n",
      "57527/57527 [==============================] - 7s 120us/step - loss: 0.1425 - accuracy: 0.2097 - val_loss: 0.1420 - val_accuracy: 0.2274\n",
      "Epoch 65/100\n",
      "57527/57527 [==============================] - 7s 120us/step - loss: 0.1425 - accuracy: 0.2093 - val_loss: 0.1421 - val_accuracy: 0.2117\n",
      "Epoch 66/100\n",
      "57527/57527 [==============================] - 7s 118us/step - loss: 0.1425 - accuracy: 0.2093 - val_loss: 0.1421 - val_accuracy: 0.2223\n",
      "Epoch 67/100\n",
      "57527/57527 [==============================] - 7s 120us/step - loss: 0.1425 - accuracy: 0.2101 - val_loss: 0.1421 - val_accuracy: 0.2165\n",
      "Epoch 68/100\n",
      "57527/57527 [==============================] - 7s 121us/step - loss: 0.1425 - accuracy: 0.2080 - val_loss: 0.1421 - val_accuracy: 0.2167\n",
      "Epoch 69/100\n",
      "57527/57527 [==============================] - 7s 122us/step - loss: 0.1425 - accuracy: 0.2089 - val_loss: 0.1420 - val_accuracy: 0.2311\n",
      "Epoch 70/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2098 - val_loss: 0.1421 - val_accuracy: 0.2244\n",
      "Epoch 71/100\n",
      "57527/57527 [==============================] - 7s 120us/step - loss: 0.1425 - accuracy: 0.2064 - val_loss: 0.1421 - val_accuracy: 0.1914\n",
      "Epoch 72/100\n",
      "57527/57527 [==============================] - 7s 122us/step - loss: 0.1425 - accuracy: 0.2084 - val_loss: 0.1421 - val_accuracy: 0.2162\n",
      "Epoch 73/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2081 - val_loss: 0.1421 - val_accuracy: 0.2195\n",
      "Epoch 74/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2125 - val_loss: 0.1420 - val_accuracy: 0.1959\n",
      "Epoch 75/100\n",
      "57527/57527 [==============================] - 7s 120us/step - loss: 0.1425 - accuracy: 0.2100 - val_loss: 0.1420 - val_accuracy: 0.2259\n",
      "Epoch 76/100\n",
      "57527/57527 [==============================] - 7s 121us/step - loss: 0.1425 - accuracy: 0.2101 - val_loss: 0.1420 - val_accuracy: 0.2206\n",
      "Epoch 77/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2120 - val_loss: 0.1420 - val_accuracy: 0.2183\n",
      "Epoch 78/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2098 - val_loss: 0.1421 - val_accuracy: 0.2187\n",
      "Epoch 79/100\n",
      "57527/57527 [==============================] - 7s 118us/step - loss: 0.1425 - accuracy: 0.2086 - val_loss: 0.1420 - val_accuracy: 0.2320\n",
      "Epoch 80/100\n",
      "57527/57527 [==============================] - 8s 132us/step - loss: 0.1425 - accuracy: 0.2121 - val_loss: 0.1421 - val_accuracy: 0.2275\n",
      "Epoch 81/100\n",
      "57527/57527 [==============================] - 7s 121us/step - loss: 0.1425 - accuracy: 0.2102 - val_loss: 0.1421 - val_accuracy: 0.2286\n",
      "Epoch 82/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2089 - val_loss: 0.1421 - val_accuracy: 0.2231\n",
      "Epoch 83/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2095 - val_loss: 0.1421 - val_accuracy: 0.2201\n",
      "Epoch 84/100\n",
      "57527/57527 [==============================] - 7s 120us/step - loss: 0.1425 - accuracy: 0.2107 - val_loss: 0.1420 - val_accuracy: 0.2165\n",
      "Epoch 85/100\n",
      "57527/57527 [==============================] - 7s 118us/step - loss: 0.1425 - accuracy: 0.2095 - val_loss: 0.1421 - val_accuracy: 0.2267\n",
      "Epoch 86/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2106 - val_loss: 0.1420 - val_accuracy: 0.2149\n",
      "Epoch 87/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2113 - val_loss: 0.1420 - val_accuracy: 0.2146\n",
      "Epoch 88/100\n",
      "57527/57527 [==============================] - 7s 120us/step - loss: 0.1425 - accuracy: 0.2104 - val_loss: 0.1421 - val_accuracy: 0.2190\n",
      "Epoch 89/100\n",
      "57527/57527 [==============================] - 7s 124us/step - loss: 0.1425 - accuracy: 0.2119 - val_loss: 0.1421 - val_accuracy: 0.2215\n",
      "Epoch 90/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2105 - val_loss: 0.1420 - val_accuracy: 0.2155\n",
      "Epoch 91/100\n",
      "57527/57527 [==============================] - 7s 120us/step - loss: 0.1425 - accuracy: 0.2082 - val_loss: 0.1420 - val_accuracy: 0.2167\n",
      "Epoch 92/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2122 - val_loss: 0.1421 - val_accuracy: 0.2199\n",
      "Epoch 93/100\n",
      "57527/57527 [==============================] - 7s 119us/step - loss: 0.1425 - accuracy: 0.2087 - val_loss: 0.1420 - val_accuracy: 0.2133\n",
      "Epoch 94/100\n",
      "57527/57527 [==============================] - 7s 118us/step - loss: 0.1425 - accuracy: 0.2080 - val_loss: 0.1421 - val_accuracy: 0.2285\n",
      "Epoch 95/100\n",
      "57527/57527 [==============================] - 7s 120us/step - loss: 0.1425 - accuracy: 0.2090 - val_loss: 0.1420 - val_accuracy: 0.2121\n",
      "Epoch 96/100\n",
      "57527/57527 [==============================] - 7s 118us/step - loss: 0.1425 - accuracy: 0.2099 - val_loss: 0.1420 - val_accuracy: 0.2261\n",
      "Epoch 97/100\n",
      "57527/57527 [==============================] - 7s 118us/step - loss: 0.1425 - accuracy: 0.2114 - val_loss: 0.1420 - val_accuracy: 0.2244\n",
      "Epoch 98/100\n",
      "57527/57527 [==============================] - 7s 120us/step - loss: 0.1425 - accuracy: 0.2106 - val_loss: 0.1421 - val_accuracy: 0.1996\n",
      "Epoch 99/100\n",
      "57527/57527 [==============================] - 7s 120us/step - loss: 0.1425 - accuracy: 0.2101 - val_loss: 0.1420 - val_accuracy: 0.2092\n",
      "Epoch 100/100\n",
      "57527/57527 [==============================] - 7s 120us/step - loss: 0.1425 - accuracy: 0.2098 - val_loss: 0.1421 - val_accuracy: 0.2169\n",
      "training model-9\n",
      "Train on 57527 samples, validate on 14382 samples\n",
      "Epoch 1/100\n",
      "57527/57527 [==============================] - 9s 163us/step - loss: 0.1435 - accuracy: 0.1578 - val_loss: 0.1425 - val_accuracy: 0.1471\n",
      "Epoch 2/100\n",
      "57527/57527 [==============================] - 8s 136us/step - loss: 0.1429 - accuracy: 0.1592 - val_loss: 0.1424 - val_accuracy: 0.1716\n",
      "Epoch 3/100\n",
      "57527/57527 [==============================] - 8s 138us/step - loss: 0.1428 - accuracy: 0.1611 - val_loss: 0.1423 - val_accuracy: 0.2053\n",
      "Epoch 4/100\n",
      "57527/57527 [==============================] - 8s 136us/step - loss: 0.1427 - accuracy: 0.1689 - val_loss: 0.1422 - val_accuracy: 0.1662\n",
      "Epoch 5/100\n",
      "57527/57527 [==============================] - 9s 153us/step - loss: 0.1427 - accuracy: 0.1724 - val_loss: 0.1422 - val_accuracy: 0.2101\n",
      "Epoch 6/100\n",
      "57527/57527 [==============================] - 8s 138us/step - loss: 0.1426 - accuracy: 0.1797 - val_loss: 0.1422 - val_accuracy: 0.1928\n",
      "Epoch 7/100\n",
      "57527/57527 [==============================] - 8s 138us/step - loss: 0.1426 - accuracy: 0.1823 - val_loss: 0.1422 - val_accuracy: 0.2178\n",
      "Epoch 8/100\n",
      "57527/57527 [==============================] - 8s 136us/step - loss: 0.1426 - accuracy: 0.1874 - val_loss: 0.1422 - val_accuracy: 0.1869\n",
      "Epoch 9/100\n",
      "57527/57527 [==============================] - 8s 136us/step - loss: 0.1426 - accuracy: 0.1911 - val_loss: 0.1422 - val_accuracy: 0.2158\n",
      "Epoch 10/100\n",
      "57527/57527 [==============================] - 8s 137us/step - loss: 0.1426 - accuracy: 0.1903 - val_loss: 0.1422 - val_accuracy: 0.1777\n",
      "Epoch 11/100\n",
      "57527/57527 [==============================] - 8s 136us/step - loss: 0.1426 - accuracy: 0.1916 - val_loss: 0.1422 - val_accuracy: 0.1839\n",
      "Epoch 12/100\n",
      "57527/57527 [==============================] - 8s 138us/step - loss: 0.1426 - accuracy: 0.1947 - val_loss: 0.1422 - val_accuracy: 0.1746\n",
      "Epoch 13/100\n",
      "57527/57527 [==============================] - 8s 136us/step - loss: 0.1426 - accuracy: 0.1922 - val_loss: 0.1422 - val_accuracy: 0.1953\n",
      "Epoch 14/100\n",
      "57527/57527 [==============================] - 8s 136us/step - loss: 0.1426 - accuracy: 0.1941 - val_loss: 0.1422 - val_accuracy: 0.2252\n",
      "Epoch 15/100\n",
      "57527/57527 [==============================] - 8s 136us/step - loss: 0.1425 - accuracy: 0.1960 - val_loss: 0.1421 - val_accuracy: 0.2092\n",
      "Epoch 16/100\n",
      "57527/57527 [==============================] - 8s 136us/step - loss: 0.1425 - accuracy: 0.1957 - val_loss: 0.1421 - val_accuracy: 0.2222\n",
      "Epoch 17/100\n",
      "57527/57527 [==============================] - 8s 136us/step - loss: 0.1425 - accuracy: 0.1984 - val_loss: 0.1421 - val_accuracy: 0.2254\n",
      "Epoch 18/100\n",
      "57527/57527 [==============================] - 8s 136us/step - loss: 0.1425 - accuracy: 0.1986 - val_loss: 0.1421 - val_accuracy: 0.1982\n",
      "Epoch 19/100\n",
      "57527/57527 [==============================] - 8s 135us/step - loss: 0.1425 - accuracy: 0.2005 - val_loss: 0.1421 - val_accuracy: 0.1461\n",
      "Epoch 20/100\n",
      "57527/57527 [==============================] - 8s 137us/step - loss: 0.1425 - accuracy: 0.1984 - val_loss: 0.1421 - val_accuracy: 0.2215\n",
      "Epoch 21/100\n",
      "57527/57527 [==============================] - 8s 136us/step - loss: 0.1425 - accuracy: 0.2024 - val_loss: 0.1421 - val_accuracy: 0.1634\n",
      "Epoch 22/100\n",
      "57527/57527 [==============================] - 8s 137us/step - loss: 0.1425 - accuracy: 0.2001 - val_loss: 0.1421 - val_accuracy: 0.2176\n",
      "Epoch 23/100\n",
      "57527/57527 [==============================] - 8s 136us/step - loss: 0.1425 - accuracy: 0.2008 - val_loss: 0.1421 - val_accuracy: 0.2038\n",
      "Epoch 24/100\n",
      "57527/57527 [==============================] - 8s 140us/step - loss: 0.1425 - accuracy: 0.2038 - val_loss: 0.1421 - val_accuracy: 0.2270\n",
      "Epoch 25/100\n",
      "57527/57527 [==============================] - 8s 140us/step - loss: 0.1425 - accuracy: 0.2042 - val_loss: 0.1421 - val_accuracy: 0.2228\n",
      "Epoch 26/100\n",
      "57527/57527 [==============================] - 8s 137us/step - loss: 0.1425 - accuracy: 0.2039 - val_loss: 0.1421 - val_accuracy: 0.2298\n",
      "Epoch 27/100\n",
      "57527/57527 [==============================] - 8s 145us/step - loss: 0.1425 - accuracy: 0.2024 - val_loss: 0.1421 - val_accuracy: 0.2157\n",
      "Epoch 28/100\n",
      "57527/57527 [==============================] - 9s 159us/step - loss: 0.1425 - accuracy: 0.2037 - val_loss: 0.1421 - val_accuracy: 0.2250\n",
      "Epoch 29/100\n",
      "57527/57527 [==============================] - 8s 147us/step - loss: 0.1425 - accuracy: 0.2039 - val_loss: 0.1421 - val_accuracy: 0.1788\n",
      "Epoch 30/100\n",
      "57527/57527 [==============================] - 9s 148us/step - loss: 0.1425 - accuracy: 0.2039 - val_loss: 0.1421 - val_accuracy: 0.2247\n",
      "Epoch 31/100\n",
      "57527/57527 [==============================] - 9s 155us/step - loss: 0.1425 - accuracy: 0.2049 - val_loss: 0.1421 - val_accuracy: 0.2311\n",
      "Epoch 32/100\n",
      "57527/57527 [==============================] - 8s 144us/step - loss: 0.1425 - accuracy: 0.2055 - val_loss: 0.1421 - val_accuracy: 0.1931\n",
      "Epoch 33/100\n",
      "57527/57527 [==============================] - 8s 144us/step - loss: 0.1425 - accuracy: 0.2036 - val_loss: 0.1421 - val_accuracy: 0.1978\n",
      "Epoch 34/100\n",
      "57527/57527 [==============================] - 9s 149us/step - loss: 0.1425 - accuracy: 0.2043 - val_loss: 0.1421 - val_accuracy: 0.2003\n",
      "Epoch 35/100\n",
      "57527/57527 [==============================] - 9s 149us/step - loss: 0.1425 - accuracy: 0.2065 - val_loss: 0.1421 - val_accuracy: 0.2066\n",
      "Epoch 36/100\n",
      "57527/57527 [==============================] - 8s 147us/step - loss: 0.1425 - accuracy: 0.2038 - val_loss: 0.1421 - val_accuracy: 0.2254\n",
      "Epoch 37/100\n",
      "57527/57527 [==============================] - 9s 150us/step - loss: 0.1425 - accuracy: 0.2051 - val_loss: 0.1421 - val_accuracy: 0.2130\n",
      "Epoch 38/100\n",
      "57527/57527 [==============================] - 9s 148us/step - loss: 0.1425 - accuracy: 0.2059 - val_loss: 0.1421 - val_accuracy: 0.1897\n",
      "Epoch 39/100\n",
      "57527/57527 [==============================] - 8s 146us/step - loss: 0.1425 - accuracy: 0.2074 - val_loss: 0.1421 - val_accuracy: 0.2171\n",
      "Epoch 40/100\n",
      "57527/57527 [==============================] - 8s 143us/step - loss: 0.1425 - accuracy: 0.2066 - val_loss: 0.1421 - val_accuracy: 0.1944\n",
      "Epoch 41/100\n",
      "57527/57527 [==============================] - 8s 143us/step - loss: 0.1425 - accuracy: 0.2051 - val_loss: 0.1421 - val_accuracy: 0.2152\n",
      "Epoch 42/100\n",
      "57527/57527 [==============================] - 8s 145us/step - loss: 0.1425 - accuracy: 0.2079 - val_loss: 0.1421 - val_accuracy: 0.1901\n",
      "Epoch 43/100\n",
      "57527/57527 [==============================] - 8s 146us/step - loss: 0.1425 - accuracy: 0.2068 - val_loss: 0.1421 - val_accuracy: 0.1969\n",
      "Epoch 44/100\n",
      "57527/57527 [==============================] - 8s 144us/step - loss: 0.1425 - accuracy: 0.2071 - val_loss: 0.1421 - val_accuracy: 0.2212\n",
      "Epoch 45/100\n",
      "57527/57527 [==============================] - 8s 140us/step - loss: 0.1425 - accuracy: 0.2061 - val_loss: 0.1421 - val_accuracy: 0.2085\n",
      "Epoch 46/100\n",
      "57527/57527 [==============================] - 8s 142us/step - loss: 0.1425 - accuracy: 0.2073 - val_loss: 0.1421 - val_accuracy: 0.2014\n",
      "Epoch 47/100\n",
      "57527/57527 [==============================] - 8s 141us/step - loss: 0.1425 - accuracy: 0.2088 - val_loss: 0.1421 - val_accuracy: 0.2306\n",
      "Epoch 48/100\n",
      "57527/57527 [==============================] - 8s 139us/step - loss: 0.1425 - accuracy: 0.2071 - val_loss: 0.1421 - val_accuracy: 0.2170\n",
      "Epoch 49/100\n",
      "57527/57527 [==============================] - 9s 159us/step - loss: 0.1425 - accuracy: 0.2090 - val_loss: 0.1421 - val_accuracy: 0.2297\n",
      "Epoch 50/100\n",
      "57527/57527 [==============================] - 8s 139us/step - loss: 0.1425 - accuracy: 0.2064 - val_loss: 0.1421 - val_accuracy: 0.2229\n",
      "Epoch 51/100\n",
      "57527/57527 [==============================] - 8s 140us/step - loss: 0.1425 - accuracy: 0.2076 - val_loss: 0.1421 - val_accuracy: 0.2276\n",
      "Epoch 52/100\n",
      "57527/57527 [==============================] - 8s 139us/step - loss: 0.1425 - accuracy: 0.2096 - val_loss: 0.1421 - val_accuracy: 0.2167\n",
      "Epoch 53/100\n",
      "57527/57527 [==============================] - 8s 137us/step - loss: 0.1425 - accuracy: 0.2091 - val_loss: 0.1421 - val_accuracy: 0.2217\n",
      "Epoch 54/100\n",
      "57527/57527 [==============================] - 8s 140us/step - loss: 0.1425 - accuracy: 0.2095 - val_loss: 0.1421 - val_accuracy: 0.2265\n",
      "Epoch 55/100\n",
      "57527/57527 [==============================] - 8s 141us/step - loss: 0.1425 - accuracy: 0.2080 - val_loss: 0.1421 - val_accuracy: 0.2174\n",
      "Epoch 56/100\n",
      "57527/57527 [==============================] - 8s 142us/step - loss: 0.1425 - accuracy: 0.2084 - val_loss: 0.1421 - val_accuracy: 0.2070\n",
      "Epoch 57/100\n",
      "57527/57527 [==============================] - 8s 142us/step - loss: 0.1425 - accuracy: 0.2094 - val_loss: 0.1421 - val_accuracy: 0.2275\n",
      "Epoch 58/100\n",
      "57527/57527 [==============================] - 8s 139us/step - loss: 0.1425 - accuracy: 0.2107 - val_loss: 0.1421 - val_accuracy: 0.2233\n",
      "Epoch 59/100\n",
      "57527/57527 [==============================] - 8s 139us/step - loss: 0.1425 - accuracy: 0.2087 - val_loss: 0.1421 - val_accuracy: 0.2290\n",
      "Epoch 60/100\n",
      "57527/57527 [==============================] - 8s 140us/step - loss: 0.1425 - accuracy: 0.2102 - val_loss: 0.1421 - val_accuracy: 0.2162\n",
      "Epoch 61/100\n",
      "57527/57527 [==============================] - 8s 136us/step - loss: 0.1425 - accuracy: 0.2119 - val_loss: 0.1421 - val_accuracy: 0.2050\n",
      "Epoch 62/100\n",
      "57527/57527 [==============================] - 8s 138us/step - loss: 0.1425 - accuracy: 0.2099 - val_loss: 0.1421 - val_accuracy: 0.2287\n",
      "Epoch 63/100\n",
      "57527/57527 [==============================] - 8s 139us/step - loss: 0.1425 - accuracy: 0.2089 - val_loss: 0.1421 - val_accuracy: 0.2285\n",
      "Epoch 64/100\n",
      "57527/57527 [==============================] - 9s 149us/step - loss: 0.1425 - accuracy: 0.2115 - val_loss: 0.1421 - val_accuracy: 0.2105\n",
      "Epoch 65/100\n",
      "57527/57527 [==============================] - 8s 141us/step - loss: 0.1425 - accuracy: 0.2087 - val_loss: 0.1421 - val_accuracy: 0.2286\n",
      "Epoch 66/100\n",
      "57527/57527 [==============================] - 8s 138us/step - loss: 0.1425 - accuracy: 0.2109 - val_loss: 0.1421 - val_accuracy: 0.2126\n",
      "Epoch 67/100\n",
      "57527/57527 [==============================] - 8s 139us/step - loss: 0.1425 - accuracy: 0.2101 - val_loss: 0.1421 - val_accuracy: 0.2048\n",
      "Epoch 68/100\n",
      "57527/57527 [==============================] - 8s 137us/step - loss: 0.1425 - accuracy: 0.2094 - val_loss: 0.1421 - val_accuracy: 0.2281\n",
      "Epoch 69/100\n",
      "57527/57527 [==============================] - 8s 137us/step - loss: 0.1425 - accuracy: 0.2134 - val_loss: 0.1421 - val_accuracy: 0.2256\n",
      "Epoch 70/100\n",
      "57527/57527 [==============================] - 8s 136us/step - loss: 0.1425 - accuracy: 0.2125 - val_loss: 0.1421 - val_accuracy: 0.2028\n",
      "Epoch 71/100\n",
      "57527/57527 [==============================] - 9s 155us/step - loss: 0.1425 - accuracy: 0.2123 - val_loss: 0.1421 - val_accuracy: 0.2203\n",
      "Epoch 72/100\n",
      "57527/57527 [==============================] - 8s 140us/step - loss: 0.1425 - accuracy: 0.2103 - val_loss: 0.1421 - val_accuracy: 0.2264\n",
      "Epoch 73/100\n",
      "57527/57527 [==============================] - 8s 141us/step - loss: 0.1425 - accuracy: 0.2089 - val_loss: 0.1421 - val_accuracy: 0.2283\n",
      "Epoch 74/100\n",
      "57527/57527 [==============================] - 8s 141us/step - loss: 0.1425 - accuracy: 0.2125 - val_loss: 0.1421 - val_accuracy: 0.2183\n",
      "Epoch 75/100\n",
      "57527/57527 [==============================] - 8s 139us/step - loss: 0.1425 - accuracy: 0.2110 - val_loss: 0.1421 - val_accuracy: 0.2249\n",
      "Epoch 76/100\n",
      "57527/57527 [==============================] - 8s 138us/step - loss: 0.1425 - accuracy: 0.2112 - val_loss: 0.1421 - val_accuracy: 0.2254\n",
      "Epoch 77/100\n",
      "57527/57527 [==============================] - 8s 138us/step - loss: 0.1425 - accuracy: 0.2106 - val_loss: 0.1421 - val_accuracy: 0.2036\n",
      "Epoch 78/100\n",
      "57527/57527 [==============================] - 8s 139us/step - loss: 0.1425 - accuracy: 0.2119 - val_loss: 0.1421 - val_accuracy: 0.2226\n",
      "Epoch 79/100\n",
      "57527/57527 [==============================] - 8s 142us/step - loss: 0.1425 - accuracy: 0.2118 - val_loss: 0.1421 - val_accuracy: 0.2271\n",
      "Epoch 80/100\n",
      "57527/57527 [==============================] - 8s 138us/step - loss: 0.1425 - accuracy: 0.2103 - val_loss: 0.1421 - val_accuracy: 0.2177\n",
      "Epoch 81/100\n",
      "57527/57527 [==============================] - 8s 139us/step - loss: 0.1425 - accuracy: 0.2114 - val_loss: 0.1421 - val_accuracy: 0.2279\n",
      "Epoch 82/100\n",
      "57527/57527 [==============================] - 8s 138us/step - loss: 0.1425 - accuracy: 0.2107 - val_loss: 0.1421 - val_accuracy: 0.2287\n",
      "Epoch 83/100\n",
      "57527/57527 [==============================] - 8s 137us/step - loss: 0.1425 - accuracy: 0.2092 - val_loss: 0.1421 - val_accuracy: 0.2188\n",
      "Epoch 84/100\n",
      "57527/57527 [==============================] - 8s 138us/step - loss: 0.1425 - accuracy: 0.2121 - val_loss: 0.1421 - val_accuracy: 0.1987\n",
      "Epoch 85/100\n",
      "57527/57527 [==============================] - 8s 138us/step - loss: 0.1425 - accuracy: 0.2109 - val_loss: 0.1421 - val_accuracy: 0.2279\n",
      "Epoch 86/100\n",
      "57527/57527 [==============================] - 8s 140us/step - loss: 0.1425 - accuracy: 0.2128 - val_loss: 0.1421 - val_accuracy: 0.2197\n",
      "Epoch 87/100\n",
      "57527/57527 [==============================] - 8s 138us/step - loss: 0.1425 - accuracy: 0.2127 - val_loss: 0.1421 - val_accuracy: 0.2194\n",
      "Epoch 88/100\n",
      "57527/57527 [==============================] - 8s 137us/step - loss: 0.1425 - accuracy: 0.2110 - val_loss: 0.1421 - val_accuracy: 0.2260\n",
      "Epoch 89/100\n",
      "57527/57527 [==============================] - 8s 138us/step - loss: 0.1425 - accuracy: 0.2124 - val_loss: 0.1421 - val_accuracy: 0.2167\n",
      "Epoch 90/100\n",
      "57527/57527 [==============================] - 8s 137us/step - loss: 0.1425 - accuracy: 0.2139 - val_loss: 0.1421 - val_accuracy: 0.2311\n",
      "Epoch 91/100\n",
      "57527/57527 [==============================] - 8s 138us/step - loss: 0.1425 - accuracy: 0.2126 - val_loss: 0.1421 - val_accuracy: 0.2218\n",
      "Epoch 92/100\n",
      "57527/57527 [==============================] - 8s 139us/step - loss: 0.1425 - accuracy: 0.2110 - val_loss: 0.1421 - val_accuracy: 0.2233\n",
      "Epoch 93/100\n",
      "57527/57527 [==============================] - 8s 142us/step - loss: 0.1425 - accuracy: 0.2121 - val_loss: 0.1421 - val_accuracy: 0.2319\n",
      "Epoch 94/100\n",
      "57527/57527 [==============================] - 9s 152us/step - loss: 0.1425 - accuracy: 0.2116 - val_loss: 0.1421 - val_accuracy: 0.2132\n",
      "Epoch 95/100\n",
      "57527/57527 [==============================] - 8s 138us/step - loss: 0.1425 - accuracy: 0.2113 - val_loss: 0.1421 - val_accuracy: 0.2219\n",
      "Epoch 96/100\n",
      "57527/57527 [==============================] - 8s 137us/step - loss: 0.1425 - accuracy: 0.2124 - val_loss: 0.1421 - val_accuracy: 0.2309\n",
      "Epoch 97/100\n",
      "57527/57527 [==============================] - 8s 138us/step - loss: 0.1425 - accuracy: 0.2130 - val_loss: 0.1421 - val_accuracy: 0.2270\n",
      "Epoch 98/100\n",
      "57527/57527 [==============================] - 8s 138us/step - loss: 0.1425 - accuracy: 0.2113 - val_loss: 0.1421 - val_accuracy: 0.2256\n",
      "Epoch 99/100\n",
      "57527/57527 [==============================] - 8s 137us/step - loss: 0.1425 - accuracy: 0.2145 - val_loss: 0.1421 - val_accuracy: 0.2242\n",
      "Epoch 100/100\n",
      "57527/57527 [==============================] - 8s 137us/step - loss: 0.1425 - accuracy: 0.2114 - val_loss: 0.1421 - val_accuracy: 0.2282\n",
      "training model-10\n",
      "Train on 57527 samples, validate on 14382 samples\n",
      "Epoch 1/100\n",
      "57527/57527 [==============================] - 6s 97us/step - loss: 0.1441 - accuracy: 0.1640 - val_loss: 0.1428 - val_accuracy: 0.1506\n",
      "Epoch 2/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1432 - accuracy: 0.1581 - val_loss: 0.1425 - val_accuracy: 0.1643\n",
      "Epoch 3/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1430 - accuracy: 0.1531 - val_loss: 0.1424 - val_accuracy: 0.1379\n",
      "Epoch 4/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1429 - accuracy: 0.1561 - val_loss: 0.1424 - val_accuracy: 0.1391\n",
      "Epoch 5/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1428 - accuracy: 0.1598 - val_loss: 0.1423 - val_accuracy: 0.1384\n",
      "Epoch 6/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1428 - accuracy: 0.1619 - val_loss: 0.1423 - val_accuracy: 0.2126\n",
      "Epoch 7/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1427 - accuracy: 0.1641 - val_loss: 0.1422 - val_accuracy: 0.2171\n",
      "Epoch 8/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1427 - accuracy: 0.1674 - val_loss: 0.1422 - val_accuracy: 0.1787\n",
      "Epoch 9/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1427 - accuracy: 0.1714 - val_loss: 0.1422 - val_accuracy: 0.2079\n",
      "Epoch 10/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1426 - accuracy: 0.1775 - val_loss: 0.1422 - val_accuracy: 0.1968\n",
      "Epoch 11/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1426 - accuracy: 0.1788 - val_loss: 0.1421 - val_accuracy: 0.2128\n",
      "Epoch 12/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1426 - accuracy: 0.1818 - val_loss: 0.1421 - val_accuracy: 0.2053\n",
      "Epoch 13/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1426 - accuracy: 0.1860 - val_loss: 0.1421 - val_accuracy: 0.2151\n",
      "Epoch 14/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1426 - accuracy: 0.1854 - val_loss: 0.1421 - val_accuracy: 0.2085\n",
      "Epoch 15/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.1426 - accuracy: 0.1862 - val_loss: 0.1421 - val_accuracy: 0.1828\n",
      "Epoch 16/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1426 - accuracy: 0.1849 - val_loss: 0.1421 - val_accuracy: 0.1979\n",
      "Epoch 17/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1426 - accuracy: 0.1847 - val_loss: 0.1421 - val_accuracy: 0.2048\n",
      "Epoch 18/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1426 - accuracy: 0.1855 - val_loss: 0.1421 - val_accuracy: 0.2173\n",
      "Epoch 19/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.1426 - accuracy: 0.1866 - val_loss: 0.1421 - val_accuracy: 0.2214\n",
      "Epoch 20/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.1426 - accuracy: 0.1900 - val_loss: 0.1421 - val_accuracy: 0.2105\n",
      "Epoch 21/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1426 - accuracy: 0.1899 - val_loss: 0.1421 - val_accuracy: 0.1902\n",
      "Epoch 22/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1426 - accuracy: 0.1903 - val_loss: 0.1421 - val_accuracy: 0.2116\n",
      "Epoch 23/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1426 - accuracy: 0.1897 - val_loss: 0.1421 - val_accuracy: 0.2028\n",
      "Epoch 24/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1426 - accuracy: 0.1928 - val_loss: 0.1421 - val_accuracy: 0.2066\n",
      "Epoch 25/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1426 - accuracy: 0.1902 - val_loss: 0.1421 - val_accuracy: 0.2069\n",
      "Epoch 26/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1426 - accuracy: 0.1913 - val_loss: 0.1421 - val_accuracy: 0.2094\n",
      "Epoch 27/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1426 - accuracy: 0.1932 - val_loss: 0.1421 - val_accuracy: 0.2002\n",
      "Epoch 28/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1426 - accuracy: 0.1940 - val_loss: 0.1421 - val_accuracy: 0.2183\n",
      "Epoch 29/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1426 - accuracy: 0.1951 - val_loss: 0.1421 - val_accuracy: 0.2228\n",
      "Epoch 30/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.1425 - accuracy: 0.1934 - val_loss: 0.1421 - val_accuracy: 0.2185\n",
      "Epoch 31/100\n",
      "57527/57527 [==============================] - 4s 75us/step - loss: 0.1425 - accuracy: 0.1928 - val_loss: 0.1421 - val_accuracy: 0.2211\n",
      "Epoch 32/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1935 - val_loss: 0.1421 - val_accuracy: 0.1932\n",
      "Epoch 33/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1942 - val_loss: 0.1421 - val_accuracy: 0.2082\n",
      "Epoch 34/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1936 - val_loss: 0.1421 - val_accuracy: 0.1671\n",
      "Epoch 35/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1982 - val_loss: 0.1421 - val_accuracy: 0.2095\n",
      "Epoch 36/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.1425 - accuracy: 0.1975 - val_loss: 0.1421 - val_accuracy: 0.2199\n",
      "Epoch 37/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1973 - val_loss: 0.1421 - val_accuracy: 0.2207\n",
      "Epoch 38/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1963 - val_loss: 0.1421 - val_accuracy: 0.1825\n",
      "Epoch 39/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1964 - val_loss: 0.1421 - val_accuracy: 0.2181\n",
      "Epoch 40/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1924 - val_loss: 0.1421 - val_accuracy: 0.2190\n",
      "Epoch 41/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1966 - val_loss: 0.1421 - val_accuracy: 0.2073\n",
      "Epoch 42/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1962 - val_loss: 0.1421 - val_accuracy: 0.2274\n",
      "Epoch 43/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1998 - val_loss: 0.1421 - val_accuracy: 0.1999\n",
      "Epoch 44/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1985 - val_loss: 0.1421 - val_accuracy: 0.2158\n",
      "Epoch 45/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1969 - val_loss: 0.1421 - val_accuracy: 0.2319\n",
      "Epoch 46/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.1425 - accuracy: 0.1987 - val_loss: 0.1421 - val_accuracy: 0.2179\n",
      "Epoch 47/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1988 - val_loss: 0.1421 - val_accuracy: 0.1762\n",
      "Epoch 48/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1985 - val_loss: 0.1421 - val_accuracy: 0.2290\n",
      "Epoch 49/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1994 - val_loss: 0.1421 - val_accuracy: 0.2302\n",
      "Epoch 50/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1987 - val_loss: 0.1421 - val_accuracy: 0.2308\n",
      "Epoch 51/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1981 - val_loss: 0.1421 - val_accuracy: 0.2263\n",
      "Epoch 52/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.1425 - accuracy: 0.1974 - val_loss: 0.1421 - val_accuracy: 0.1876\n",
      "Epoch 53/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1975 - val_loss: 0.1421 - val_accuracy: 0.2292\n",
      "Epoch 54/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1981 - val_loss: 0.1421 - val_accuracy: 0.2021\n",
      "Epoch 55/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1946 - val_loss: 0.1421 - val_accuracy: 0.2314\n",
      "Epoch 56/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1964 - val_loss: 0.1421 - val_accuracy: 0.2293\n",
      "Epoch 57/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1999 - val_loss: 0.1421 - val_accuracy: 0.2289\n",
      "Epoch 58/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1968 - val_loss: 0.1421 - val_accuracy: 0.1989\n",
      "Epoch 59/100\n",
      "57527/57527 [==============================] - 4s 65us/step - loss: 0.1425 - accuracy: 0.2006 - val_loss: 0.1421 - val_accuracy: 0.1854\n",
      "Epoch 60/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.2000 - val_loss: 0.1421 - val_accuracy: 0.1906\n",
      "Epoch 61/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.2039 - val_loss: 0.1421 - val_accuracy: 0.2181\n",
      "Epoch 62/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.1425 - accuracy: 0.1966 - val_loss: 0.1421 - val_accuracy: 0.2293\n",
      "Epoch 63/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1995 - val_loss: 0.1421 - val_accuracy: 0.2306\n",
      "Epoch 64/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1988 - val_loss: 0.1421 - val_accuracy: 0.2274\n",
      "Epoch 65/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1982 - val_loss: 0.1421 - val_accuracy: 0.2214\n",
      "Epoch 66/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1975 - val_loss: 0.1421 - val_accuracy: 0.2295\n",
      "Epoch 67/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1991 - val_loss: 0.1421 - val_accuracy: 0.2184\n",
      "Epoch 68/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.2002 - val_loss: 0.1421 - val_accuracy: 0.2265\n",
      "Epoch 69/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.2012 - val_loss: 0.1421 - val_accuracy: 0.1879\n",
      "Epoch 70/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1983 - val_loss: 0.1421 - val_accuracy: 0.2302\n",
      "Epoch 71/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.2009 - val_loss: 0.1421 - val_accuracy: 0.2299\n",
      "Epoch 72/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1955 - val_loss: 0.1421 - val_accuracy: 0.2160\n",
      "Epoch 73/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.1425 - accuracy: 0.1993 - val_loss: 0.1421 - val_accuracy: 0.2323\n",
      "Epoch 74/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.1425 - accuracy: 0.1995 - val_loss: 0.1421 - val_accuracy: 0.2294\n",
      "Epoch 75/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.2025 - val_loss: 0.1421 - val_accuracy: 0.2055\n",
      "Epoch 76/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.2000 - val_loss: 0.1421 - val_accuracy: 0.2123\n",
      "Epoch 77/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.1425 - accuracy: 0.1995 - val_loss: 0.1421 - val_accuracy: 0.1989\n",
      "Epoch 78/100\n",
      "57527/57527 [==============================] - 4s 77us/step - loss: 0.1425 - accuracy: 0.1971 - val_loss: 0.1421 - val_accuracy: 0.2236\n",
      "Epoch 79/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.2019 - val_loss: 0.1421 - val_accuracy: 0.2228\n",
      "Epoch 80/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.2010 - val_loss: 0.1421 - val_accuracy: 0.1948\n",
      "Epoch 81/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.1425 - accuracy: 0.1992 - val_loss: 0.1421 - val_accuracy: 0.2288\n",
      "Epoch 82/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.2004 - val_loss: 0.1421 - val_accuracy: 0.2295\n",
      "Epoch 83/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1984 - val_loss: 0.1421 - val_accuracy: 0.2320\n",
      "Epoch 84/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1978 - val_loss: 0.1421 - val_accuracy: 0.2308\n",
      "Epoch 85/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.1425 - accuracy: 0.1999 - val_loss: 0.1421 - val_accuracy: 0.1969\n",
      "Epoch 86/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.1425 - accuracy: 0.2016 - val_loss: 0.1421 - val_accuracy: 0.2242\n",
      "Epoch 87/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.2016 - val_loss: 0.1421 - val_accuracy: 0.2329\n",
      "Epoch 88/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.2007 - val_loss: 0.1421 - val_accuracy: 0.2310\n",
      "Epoch 89/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.2005 - val_loss: 0.1421 - val_accuracy: 0.2285\n",
      "Epoch 90/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1986 - val_loss: 0.1421 - val_accuracy: 0.2287\n",
      "Epoch 91/100\n",
      "57527/57527 [==============================] - 4s 65us/step - loss: 0.1425 - accuracy: 0.2015 - val_loss: 0.1421 - val_accuracy: 0.2292\n",
      "Epoch 92/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.2020 - val_loss: 0.1421 - val_accuracy: 0.2112\n",
      "Epoch 93/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.1425 - accuracy: 0.2009 - val_loss: 0.1421 - val_accuracy: 0.2167\n",
      "Epoch 94/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.2012 - val_loss: 0.1421 - val_accuracy: 0.2315\n",
      "Epoch 95/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.2022 - val_loss: 0.1421 - val_accuracy: 0.2276\n",
      "Epoch 96/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1977 - val_loss: 0.1421 - val_accuracy: 0.2291\n",
      "Epoch 97/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.1981 - val_loss: 0.1421 - val_accuracy: 0.2312\n",
      "Epoch 98/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.1425 - accuracy: 0.1978 - val_loss: 0.1421 - val_accuracy: 0.2102\n",
      "Epoch 99/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.2015 - val_loss: 0.1421 - val_accuracy: 0.2023\n",
      "Epoch 100/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.1425 - accuracy: 0.2023 - val_loss: 0.1421 - val_accuracy: 0.2100\n",
      "training model-11\n",
      "Train on 57527 samples, validate on 14382 samples\n",
      "Epoch 1/100\n",
      "57527/57527 [==============================] - 6s 98us/step - loss: 0.0326 - accuracy: 0.1571 - val_loss: 0.0221 - val_accuracy: 0.1301\n",
      "Epoch 2/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0208 - accuracy: 0.1433 - val_loss: 0.0172 - val_accuracy: 0.1323\n",
      "Epoch 3/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0183 - accuracy: 0.1496 - val_loss: 0.0163 - val_accuracy: 0.1608\n",
      "Epoch 4/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0169 - accuracy: 0.1620 - val_loss: 0.0153 - val_accuracy: 0.1692\n",
      "Epoch 5/100\n",
      "57527/57527 [==============================] - 4s 65us/step - loss: 0.0160 - accuracy: 0.1815 - val_loss: 0.0148 - val_accuracy: 0.1851\n",
      "Epoch 6/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.0157 - accuracy: 0.1858 - val_loss: 0.0148 - val_accuracy: 0.1761\n",
      "Epoch 7/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0154 - accuracy: 0.1877 - val_loss: 0.0144 - val_accuracy: 0.2072\n",
      "Epoch 8/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0153 - accuracy: 0.1895 - val_loss: 0.0142 - val_accuracy: 0.2276\n",
      "Epoch 9/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0149 - accuracy: 0.1875 - val_loss: 0.0136 - val_accuracy: 0.2211\n",
      "Epoch 10/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0145 - accuracy: 0.1861 - val_loss: 0.0135 - val_accuracy: 0.2234\n",
      "Epoch 11/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0144 - accuracy: 0.1886 - val_loss: 0.0133 - val_accuracy: 0.2297\n",
      "Epoch 12/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0142 - accuracy: 0.1864 - val_loss: 0.0130 - val_accuracy: 0.2027\n",
      "Epoch 13/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0140 - accuracy: 0.1850 - val_loss: 0.0128 - val_accuracy: 0.2032\n",
      "Epoch 14/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.0138 - accuracy: 0.1854 - val_loss: 0.0130 - val_accuracy: 0.1703\n",
      "Epoch 15/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0136 - accuracy: 0.1883 - val_loss: 0.0126 - val_accuracy: 0.2232\n",
      "Epoch 16/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0135 - accuracy: 0.1904 - val_loss: 0.0127 - val_accuracy: 0.1912\n",
      "Epoch 17/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.0134 - accuracy: 0.1928 - val_loss: 0.0126 - val_accuracy: 0.2092\n",
      "Epoch 18/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0134 - accuracy: 0.1949 - val_loss: 0.0125 - val_accuracy: 0.2115\n",
      "Epoch 19/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0134 - accuracy: 0.1973 - val_loss: 0.0124 - val_accuracy: 0.2257\n",
      "Epoch 20/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0132 - accuracy: 0.1981 - val_loss: 0.0126 - val_accuracy: 0.2069\n",
      "Epoch 21/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0133 - accuracy: 0.2023 - val_loss: 0.0127 - val_accuracy: 0.2211\n",
      "Epoch 22/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0133 - accuracy: 0.2000 - val_loss: 0.0125 - val_accuracy: 0.2103\n",
      "Epoch 23/100\n",
      "57527/57527 [==============================] - 4s 72us/step - loss: 0.0133 - accuracy: 0.2019 - val_loss: 0.0125 - val_accuracy: 0.2181\n",
      "Epoch 24/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0132 - accuracy: 0.2047 - val_loss: 0.0124 - val_accuracy: 0.2181\n",
      "Epoch 25/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0132 - accuracy: 0.2017 - val_loss: 0.0124 - val_accuracy: 0.2152\n",
      "Epoch 26/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0132 - accuracy: 0.2028 - val_loss: 0.0124 - val_accuracy: 0.2295\n",
      "Epoch 27/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0131 - accuracy: 0.2072 - val_loss: 0.0126 - val_accuracy: 0.2306\n",
      "Epoch 28/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0131 - accuracy: 0.2057 - val_loss: 0.0125 - val_accuracy: 0.2238\n",
      "Epoch 29/100\n",
      "57527/57527 [==============================] - 4s 65us/step - loss: 0.0132 - accuracy: 0.2031 - val_loss: 0.0125 - val_accuracy: 0.2045\n",
      "Epoch 30/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.0132 - accuracy: 0.2051 - val_loss: 0.0123 - val_accuracy: 0.2247\n",
      "Epoch 31/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0132 - accuracy: 0.2024 - val_loss: 0.0123 - val_accuracy: 0.2093\n",
      "Epoch 32/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0131 - accuracy: 0.2050 - val_loss: 0.0123 - val_accuracy: 0.2131\n",
      "Epoch 33/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0131 - accuracy: 0.2059 - val_loss: 0.0124 - val_accuracy: 0.2301\n",
      "Epoch 34/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0132 - accuracy: 0.2037 - val_loss: 0.0123 - val_accuracy: 0.2202\n",
      "Epoch 35/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0130 - accuracy: 0.2075 - val_loss: 0.0123 - val_accuracy: 0.1907\n",
      "Epoch 36/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0131 - accuracy: 0.2038 - val_loss: 0.0124 - val_accuracy: 0.2194\n",
      "Epoch 37/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0131 - accuracy: 0.2035 - val_loss: 0.0124 - val_accuracy: 0.2284\n",
      "Epoch 38/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.0131 - accuracy: 0.2069 - val_loss: 0.0123 - val_accuracy: 0.2257\n",
      "Epoch 39/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.0131 - accuracy: 0.2061 - val_loss: 0.0123 - val_accuracy: 0.2208\n",
      "Epoch 40/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0131 - accuracy: 0.2032 - val_loss: 0.0123 - val_accuracy: 0.2199\n",
      "Epoch 41/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0130 - accuracy: 0.2051 - val_loss: 0.0126 - val_accuracy: 0.1965\n",
      "Epoch 42/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0131 - accuracy: 0.2064 - val_loss: 0.0125 - val_accuracy: 0.2226\n",
      "Epoch 43/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0131 - accuracy: 0.2041 - val_loss: 0.0125 - val_accuracy: 0.1983\n",
      "Epoch 44/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0130 - accuracy: 0.2058 - val_loss: 0.0123 - val_accuracy: 0.2057\n",
      "Epoch 45/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0131 - accuracy: 0.2029 - val_loss: 0.0124 - val_accuracy: 0.2261\n",
      "Epoch 46/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0131 - accuracy: 0.2059 - val_loss: 0.0123 - val_accuracy: 0.2186\n",
      "Epoch 47/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0130 - accuracy: 0.2054 - val_loss: 0.0122 - val_accuracy: 0.2288\n",
      "Epoch 48/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0130 - accuracy: 0.2057 - val_loss: 0.0124 - val_accuracy: 0.1719\n",
      "Epoch 49/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0130 - accuracy: 0.2090 - val_loss: 0.0123 - val_accuracy: 0.2280\n",
      "Epoch 50/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0130 - accuracy: 0.2058 - val_loss: 0.0124 - val_accuracy: 0.2303\n",
      "Epoch 51/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0130 - accuracy: 0.2074 - val_loss: 0.0124 - val_accuracy: 0.2227\n",
      "Epoch 52/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0130 - accuracy: 0.2046 - val_loss: 0.0122 - val_accuracy: 0.2231\n",
      "Epoch 53/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0130 - accuracy: 0.2044 - val_loss: 0.0124 - val_accuracy: 0.1918\n",
      "Epoch 54/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.0131 - accuracy: 0.2079 - val_loss: 0.0122 - val_accuracy: 0.2146\n",
      "Epoch 55/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0130 - accuracy: 0.2052 - val_loss: 0.0123 - val_accuracy: 0.2251\n",
      "Epoch 56/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0129 - accuracy: 0.2088 - val_loss: 0.0125 - val_accuracy: 0.2303\n",
      "Epoch 57/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0129 - accuracy: 0.2071 - val_loss: 0.0123 - val_accuracy: 0.2037\n",
      "Epoch 58/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0130 - accuracy: 0.2078 - val_loss: 0.0125 - val_accuracy: 0.2078\n",
      "Epoch 59/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0130 - accuracy: 0.2097 - val_loss: 0.0123 - val_accuracy: 0.2043\n",
      "Epoch 60/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0130 - accuracy: 0.2092 - val_loss: 0.0123 - val_accuracy: 0.2283\n",
      "Epoch 61/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0129 - accuracy: 0.2105 - val_loss: 0.0122 - val_accuracy: 0.2224\n",
      "Epoch 62/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0130 - accuracy: 0.2093 - val_loss: 0.0122 - val_accuracy: 0.2161\n",
      "Epoch 63/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0129 - accuracy: 0.2063 - val_loss: 0.0122 - val_accuracy: 0.2293\n",
      "Epoch 64/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0129 - accuracy: 0.2100 - val_loss: 0.0124 - val_accuracy: 0.2285\n",
      "Epoch 65/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0129 - accuracy: 0.2076 - val_loss: 0.0123 - val_accuracy: 0.2298\n",
      "Epoch 66/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0130 - accuracy: 0.2075 - val_loss: 0.0122 - val_accuracy: 0.1853\n",
      "Epoch 67/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.0130 - accuracy: 0.2106 - val_loss: 0.0123 - val_accuracy: 0.2265\n",
      "Epoch 68/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0130 - accuracy: 0.2090 - val_loss: 0.0123 - val_accuracy: 0.2303\n",
      "Epoch 69/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0129 - accuracy: 0.2087 - val_loss: 0.0123 - val_accuracy: 0.2116\n",
      "Epoch 70/100\n",
      "57527/57527 [==============================] - 4s 73us/step - loss: 0.0129 - accuracy: 0.2065 - val_loss: 0.0123 - val_accuracy: 0.2299\n",
      "Epoch 71/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0129 - accuracy: 0.2093 - val_loss: 0.0125 - val_accuracy: 0.2016\n",
      "Epoch 72/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0130 - accuracy: 0.2086 - val_loss: 0.0122 - val_accuracy: 0.2262\n",
      "Epoch 73/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0129 - accuracy: 0.2105 - val_loss: 0.0122 - val_accuracy: 0.2318\n",
      "Epoch 74/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0129 - accuracy: 0.2119 - val_loss: 0.0124 - val_accuracy: 0.2298\n",
      "Epoch 75/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0130 - accuracy: 0.2105 - val_loss: 0.0122 - val_accuracy: 0.2308\n",
      "Epoch 76/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0130 - accuracy: 0.2075 - val_loss: 0.0123 - val_accuracy: 0.2064\n",
      "Epoch 77/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0129 - accuracy: 0.2119 - val_loss: 0.0124 - val_accuracy: 0.2040\n",
      "Epoch 78/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0130 - accuracy: 0.2089 - val_loss: 0.0122 - val_accuracy: 0.2111\n",
      "Epoch 79/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0129 - accuracy: 0.2104 - val_loss: 0.0122 - val_accuracy: 0.2319\n",
      "Epoch 80/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0129 - accuracy: 0.2074 - val_loss: 0.0122 - val_accuracy: 0.1874\n",
      "Epoch 81/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0129 - accuracy: 0.2108 - val_loss: 0.0124 - val_accuracy: 0.2224\n",
      "Epoch 82/100\n",
      "57527/57527 [==============================] - 4s 65us/step - loss: 0.0130 - accuracy: 0.2100 - val_loss: 0.0122 - val_accuracy: 0.2292\n",
      "Epoch 83/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0129 - accuracy: 0.2081 - val_loss: 0.0124 - val_accuracy: 0.2219\n",
      "Epoch 84/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0128 - accuracy: 0.2100 - val_loss: 0.0122 - val_accuracy: 0.2289\n",
      "Epoch 85/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.0128 - accuracy: 0.2082 - val_loss: 0.0122 - val_accuracy: 0.2092\n",
      "Epoch 86/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0129 - accuracy: 0.2094 - val_loss: 0.0123 - val_accuracy: 0.2093\n",
      "Epoch 87/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0129 - accuracy: 0.2091 - val_loss: 0.0123 - val_accuracy: 0.1966\n",
      "Epoch 88/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.0128 - accuracy: 0.2110 - val_loss: 0.0122 - val_accuracy: 0.2254\n",
      "Epoch 89/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0129 - accuracy: 0.2096 - val_loss: 0.0121 - val_accuracy: 0.2110\n",
      "Epoch 90/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0129 - accuracy: 0.2075 - val_loss: 0.0122 - val_accuracy: 0.2230\n",
      "Epoch 91/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0129 - accuracy: 0.2089 - val_loss: 0.0122 - val_accuracy: 0.2276\n",
      "Epoch 92/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0129 - accuracy: 0.2094 - val_loss: 0.0122 - val_accuracy: 0.2307\n",
      "Epoch 93/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0128 - accuracy: 0.2085 - val_loss: 0.0121 - val_accuracy: 0.2305\n",
      "Epoch 94/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0129 - accuracy: 0.2115 - val_loss: 0.0121 - val_accuracy: 0.2255\n",
      "Epoch 95/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0129 - accuracy: 0.2112 - val_loss: 0.0121 - val_accuracy: 0.2304\n",
      "Epoch 96/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.0128 - accuracy: 0.2098 - val_loss: 0.0122 - val_accuracy: 0.2101\n",
      "Epoch 97/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0129 - accuracy: 0.2095 - val_loss: 0.0122 - val_accuracy: 0.2222\n",
      "Epoch 98/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.0129 - accuracy: 0.2069 - val_loss: 0.0121 - val_accuracy: 0.1973\n",
      "Epoch 99/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0128 - accuracy: 0.2106 - val_loss: 0.0121 - val_accuracy: 0.2153\n",
      "Epoch 100/100\n",
      "57527/57527 [==============================] - 4s 66us/step - loss: 0.0129 - accuracy: 0.2103 - val_loss: 0.0122 - val_accuracy: 0.2281\n",
      "training model-12\n",
      "Train on 57527 samples, validate on 14382 samples\n",
      "Epoch 1/100\n",
      "57527/57527 [==============================] - 6s 102us/step - loss: 0.0386 - accuracy: 0.1776 - val_loss: 0.0258 - val_accuracy: 0.1470\n",
      "Epoch 2/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0255 - accuracy: 0.1464 - val_loss: 0.0211 - val_accuracy: 0.1462\n",
      "Epoch 3/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0223 - accuracy: 0.1569 - val_loss: 0.0200 - val_accuracy: 0.1650\n",
      "Epoch 4/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0194 - accuracy: 0.1600 - val_loss: 0.0164 - val_accuracy: 0.1523\n",
      "Epoch 5/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0177 - accuracy: 0.1535 - val_loss: 0.0155 - val_accuracy: 0.1571\n",
      "Epoch 6/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0169 - accuracy: 0.1647 - val_loss: 0.0151 - val_accuracy: 0.1877\n",
      "Epoch 7/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0165 - accuracy: 0.1792 - val_loss: 0.0148 - val_accuracy: 0.2035\n",
      "Epoch 8/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0160 - accuracy: 0.1822 - val_loss: 0.0148 - val_accuracy: 0.1870\n",
      "Epoch 9/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0157 - accuracy: 0.1832 - val_loss: 0.0146 - val_accuracy: 0.1800\n",
      "Epoch 10/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0154 - accuracy: 0.1810 - val_loss: 0.0144 - val_accuracy: 0.1569\n",
      "Epoch 11/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.0153 - accuracy: 0.1821 - val_loss: 0.0143 - val_accuracy: 0.2035\n",
      "Epoch 12/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0151 - accuracy: 0.1852 - val_loss: 0.0142 - val_accuracy: 0.2196\n",
      "Epoch 13/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0149 - accuracy: 0.1814 - val_loss: 0.0139 - val_accuracy: 0.1914\n",
      "Epoch 14/100\n",
      "57527/57527 [==============================] - 4s 78us/step - loss: 0.0145 - accuracy: 0.1831 - val_loss: 0.0132 - val_accuracy: 0.2149\n",
      "Epoch 15/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0142 - accuracy: 0.1814 - val_loss: 0.0129 - val_accuracy: 0.1732\n",
      "Epoch 16/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0139 - accuracy: 0.1779 - val_loss: 0.0127 - val_accuracy: 0.2238\n",
      "Epoch 17/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0137 - accuracy: 0.1749 - val_loss: 0.0126 - val_accuracy: 0.1918\n",
      "Epoch 18/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0136 - accuracy: 0.1812 - val_loss: 0.0126 - val_accuracy: 0.2195\n",
      "Epoch 19/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.0134 - accuracy: 0.1830 - val_loss: 0.0125 - val_accuracy: 0.2123\n",
      "Epoch 20/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0134 - accuracy: 0.1860 - val_loss: 0.0125 - val_accuracy: 0.2238\n",
      "Epoch 21/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0134 - accuracy: 0.1884 - val_loss: 0.0124 - val_accuracy: 0.2295\n",
      "Epoch 22/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0133 - accuracy: 0.1907 - val_loss: 0.0124 - val_accuracy: 0.2188\n",
      "Epoch 23/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.0133 - accuracy: 0.1961 - val_loss: 0.0124 - val_accuracy: 0.2201\n",
      "Epoch 24/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0132 - accuracy: 0.1935 - val_loss: 0.0124 - val_accuracy: 0.1996\n",
      "Epoch 25/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0132 - accuracy: 0.1944 - val_loss: 0.0124 - val_accuracy: 0.2217\n",
      "Epoch 26/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0132 - accuracy: 0.1995 - val_loss: 0.0124 - val_accuracy: 0.2252\n",
      "Epoch 27/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0131 - accuracy: 0.2013 - val_loss: 0.0124 - val_accuracy: 0.2244\n",
      "Epoch 28/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0131 - accuracy: 0.1999 - val_loss: 0.0124 - val_accuracy: 0.2036\n",
      "Epoch 29/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0131 - accuracy: 0.2014 - val_loss: 0.0125 - val_accuracy: 0.1949\n",
      "Epoch 30/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0131 - accuracy: 0.2006 - val_loss: 0.0124 - val_accuracy: 0.2309\n",
      "Epoch 31/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0131 - accuracy: 0.2015 - val_loss: 0.0124 - val_accuracy: 0.1863\n",
      "Epoch 32/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0131 - accuracy: 0.2025 - val_loss: 0.0125 - val_accuracy: 0.2222\n",
      "Epoch 33/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0130 - accuracy: 0.2061 - val_loss: 0.0124 - val_accuracy: 0.2303\n",
      "Epoch 34/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0130 - accuracy: 0.2041 - val_loss: 0.0123 - val_accuracy: 0.2122\n",
      "Epoch 35/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0130 - accuracy: 0.2047 - val_loss: 0.0123 - val_accuracy: 0.1967\n",
      "Epoch 36/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0130 - accuracy: 0.2072 - val_loss: 0.0124 - val_accuracy: 0.1989\n",
      "Epoch 37/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0130 - accuracy: 0.2071 - val_loss: 0.0123 - val_accuracy: 0.2039\n",
      "Epoch 38/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0130 - accuracy: 0.2061 - val_loss: 0.0124 - val_accuracy: 0.2171\n",
      "Epoch 39/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0129 - accuracy: 0.2049 - val_loss: 0.0123 - val_accuracy: 0.2114\n",
      "Epoch 40/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0130 - accuracy: 0.2085 - val_loss: 0.0124 - val_accuracy: 0.2301\n",
      "Epoch 41/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0129 - accuracy: 0.2065 - val_loss: 0.0123 - val_accuracy: 0.2292\n",
      "Epoch 42/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0130 - accuracy: 0.2076 - val_loss: 0.0123 - val_accuracy: 0.2303\n",
      "Epoch 43/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.0129 - accuracy: 0.2096 - val_loss: 0.0123 - val_accuracy: 0.2301\n",
      "Epoch 44/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0129 - accuracy: 0.2081 - val_loss: 0.0122 - val_accuracy: 0.2306\n",
      "Epoch 45/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0130 - accuracy: 0.2060 - val_loss: 0.0122 - val_accuracy: 0.2064\n",
      "Epoch 46/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0129 - accuracy: 0.2101 - val_loss: 0.0123 - val_accuracy: 0.2227\n",
      "Epoch 47/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0129 - accuracy: 0.2097 - val_loss: 0.0123 - val_accuracy: 0.2225\n",
      "Epoch 48/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0129 - accuracy: 0.2100 - val_loss: 0.0123 - val_accuracy: 0.2160\n",
      "Epoch 49/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0129 - accuracy: 0.2107 - val_loss: 0.0123 - val_accuracy: 0.2048\n",
      "Epoch 50/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0129 - accuracy: 0.2105 - val_loss: 0.0123 - val_accuracy: 0.1858\n",
      "Epoch 51/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0129 - accuracy: 0.2082 - val_loss: 0.0122 - val_accuracy: 0.2042\n",
      "Epoch 52/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0129 - accuracy: 0.2072 - val_loss: 0.0122 - val_accuracy: 0.2288\n",
      "Epoch 53/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0129 - accuracy: 0.2111 - val_loss: 0.0122 - val_accuracy: 0.1928\n",
      "Epoch 54/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0129 - accuracy: 0.2086 - val_loss: 0.0122 - val_accuracy: 0.2024\n",
      "Epoch 55/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0129 - accuracy: 0.2088 - val_loss: 0.0122 - val_accuracy: 0.2001\n",
      "Epoch 56/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0129 - accuracy: 0.2072 - val_loss: 0.0122 - val_accuracy: 0.2236\n",
      "Epoch 57/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0129 - accuracy: 0.2088 - val_loss: 0.0123 - val_accuracy: 0.1930\n",
      "Epoch 58/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0129 - accuracy: 0.2076 - val_loss: 0.0122 - val_accuracy: 0.2298\n",
      "Epoch 59/100\n",
      "57527/57527 [==============================] - 4s 71us/step - loss: 0.0128 - accuracy: 0.2119 - val_loss: 0.0122 - val_accuracy: 0.2138\n",
      "Epoch 60/100\n",
      "57527/57527 [==============================] - 4s 74us/step - loss: 0.0128 - accuracy: 0.2116 - val_loss: 0.0123 - val_accuracy: 0.2211\n",
      "Epoch 61/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0128 - accuracy: 0.2076 - val_loss: 0.0122 - val_accuracy: 0.2143\n",
      "Epoch 62/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0128 - accuracy: 0.2105 - val_loss: 0.0122 - val_accuracy: 0.2308\n",
      "Epoch 63/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0128 - accuracy: 0.2105 - val_loss: 0.0122 - val_accuracy: 0.2073\n",
      "Epoch 64/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0128 - accuracy: 0.2128 - val_loss: 0.0121 - val_accuracy: 0.2227\n",
      "Epoch 65/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0128 - accuracy: 0.2109 - val_loss: 0.0122 - val_accuracy: 0.2282\n",
      "Epoch 66/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0128 - accuracy: 0.2091 - val_loss: 0.0124 - val_accuracy: 0.2230\n",
      "Epoch 67/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0128 - accuracy: 0.2125 - val_loss: 0.0121 - val_accuracy: 0.2117\n",
      "Epoch 68/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0128 - accuracy: 0.2110 - val_loss: 0.0122 - val_accuracy: 0.2190\n",
      "Epoch 69/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.0128 - accuracy: 0.2102 - val_loss: 0.0122 - val_accuracy: 0.2261\n",
      "Epoch 70/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0127 - accuracy: 0.2119 - val_loss: 0.0121 - val_accuracy: 0.2227\n",
      "Epoch 71/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0128 - accuracy: 0.2118 - val_loss: 0.0122 - val_accuracy: 0.2308\n",
      "Epoch 72/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0128 - accuracy: 0.2081 - val_loss: 0.0121 - val_accuracy: 0.2190\n",
      "Epoch 73/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0128 - accuracy: 0.2123 - val_loss: 0.0122 - val_accuracy: 0.2320\n",
      "Epoch 74/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0127 - accuracy: 0.2106 - val_loss: 0.0121 - val_accuracy: 0.2228\n",
      "Epoch 75/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0128 - accuracy: 0.2092 - val_loss: 0.0122 - val_accuracy: 0.2305\n",
      "Epoch 76/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0128 - accuracy: 0.2128 - val_loss: 0.0121 - val_accuracy: 0.2228\n",
      "Epoch 77/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0128 - accuracy: 0.2104 - val_loss: 0.0122 - val_accuracy: 0.2245\n",
      "Epoch 78/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0127 - accuracy: 0.2107 - val_loss: 0.0121 - val_accuracy: 0.2236\n",
      "Epoch 79/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0127 - accuracy: 0.2101 - val_loss: 0.0121 - val_accuracy: 0.2096\n",
      "Epoch 80/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0127 - accuracy: 0.2097 - val_loss: 0.0121 - val_accuracy: 0.2210\n",
      "Epoch 81/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0127 - accuracy: 0.2117 - val_loss: 0.0122 - val_accuracy: 0.2249\n",
      "Epoch 82/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0127 - accuracy: 0.2091 - val_loss: 0.0122 - val_accuracy: 0.2317\n",
      "Epoch 83/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0127 - accuracy: 0.2086 - val_loss: 0.0121 - val_accuracy: 0.2298\n",
      "Epoch 84/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0127 - accuracy: 0.2106 - val_loss: 0.0121 - val_accuracy: 0.2046\n",
      "Epoch 85/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0127 - accuracy: 0.2137 - val_loss: 0.0121 - val_accuracy: 0.2246\n",
      "Epoch 86/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0127 - accuracy: 0.2136 - val_loss: 0.0121 - val_accuracy: 0.2167\n",
      "Epoch 87/100\n",
      "57527/57527 [==============================] - 4s 67us/step - loss: 0.0127 - accuracy: 0.2122 - val_loss: 0.0121 - val_accuracy: 0.2319\n",
      "Epoch 88/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0127 - accuracy: 0.2122 - val_loss: 0.0121 - val_accuracy: 0.2238\n",
      "Epoch 89/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0127 - accuracy: 0.2147 - val_loss: 0.0122 - val_accuracy: 0.2295\n",
      "Epoch 90/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0127 - accuracy: 0.2133 - val_loss: 0.0122 - val_accuracy: 0.2082\n",
      "Epoch 91/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0127 - accuracy: 0.2118 - val_loss: 0.0122 - val_accuracy: 0.2256\n",
      "Epoch 92/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0128 - accuracy: 0.2123 - val_loss: 0.0123 - val_accuracy: 0.2309\n",
      "Epoch 93/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0127 - accuracy: 0.2099 - val_loss: 0.0121 - val_accuracy: 0.2306\n",
      "Epoch 94/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0127 - accuracy: 0.2125 - val_loss: 0.0121 - val_accuracy: 0.2276\n",
      "Epoch 95/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0127 - accuracy: 0.2137 - val_loss: 0.0121 - val_accuracy: 0.2317\n",
      "Epoch 96/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0127 - accuracy: 0.2125 - val_loss: 0.0122 - val_accuracy: 0.1612\n",
      "Epoch 97/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0127 - accuracy: 0.2117 - val_loss: 0.0121 - val_accuracy: 0.2234\n",
      "Epoch 98/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0126 - accuracy: 0.2108 - val_loss: 0.0121 - val_accuracy: 0.2326\n",
      "Epoch 99/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0127 - accuracy: 0.2128 - val_loss: 0.0122 - val_accuracy: 0.2323\n",
      "Epoch 100/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0127 - accuracy: 0.2128 - val_loss: 0.0121 - val_accuracy: 0.2324\n",
      "training model-13\n",
      "Train on 57527 samples, validate on 14382 samples\n",
      "Epoch 1/100\n",
      "57527/57527 [==============================] - 6s 104us/step - loss: 0.1447 - accuracy: 0.1818 - val_loss: 0.1428 - val_accuracy: 0.1299\n",
      "Epoch 2/100\n",
      "57527/57527 [==============================] - 4s 71us/step - loss: 0.1432 - accuracy: 0.1548 - val_loss: 0.1426 - val_accuracy: 0.1688\n",
      "Epoch 3/100\n",
      "57527/57527 [==============================] - 5s 79us/step - loss: 0.1430 - accuracy: 0.1564 - val_loss: 0.1424 - val_accuracy: 0.1905\n",
      "Epoch 4/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1429 - accuracy: 0.1582 - val_loss: 0.1424 - val_accuracy: 0.1324\n",
      "Epoch 5/100\n",
      "57527/57527 [==============================] - 4s 71us/step - loss: 0.1429 - accuracy: 0.1580 - val_loss: 0.1423 - val_accuracy: 0.1699\n",
      "Epoch 6/100\n",
      "57527/57527 [==============================] - 4s 71us/step - loss: 0.1428 - accuracy: 0.1568 - val_loss: 0.1423 - val_accuracy: 0.1858\n",
      "Epoch 7/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1428 - accuracy: 0.1556 - val_loss: 0.1423 - val_accuracy: 0.1837\n",
      "Epoch 8/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1427 - accuracy: 0.1589 - val_loss: 0.1423 - val_accuracy: 0.1337\n",
      "Epoch 9/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1427 - accuracy: 0.1564 - val_loss: 0.1422 - val_accuracy: 0.1668\n",
      "Epoch 10/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1427 - accuracy: 0.1575 - val_loss: 0.1422 - val_accuracy: 0.1855\n",
      "Epoch 11/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1427 - accuracy: 0.1611 - val_loss: 0.1422 - val_accuracy: 0.1880\n",
      "Epoch 12/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1427 - accuracy: 0.1602 - val_loss: 0.1422 - val_accuracy: 0.1637\n",
      "Epoch 13/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1427 - accuracy: 0.1643 - val_loss: 0.1422 - val_accuracy: 0.1858\n",
      "Epoch 14/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1427 - accuracy: 0.1646 - val_loss: 0.1422 - val_accuracy: 0.1537\n",
      "Epoch 15/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1426 - accuracy: 0.1687 - val_loss: 0.1422 - val_accuracy: 0.1779\n",
      "Epoch 16/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1426 - accuracy: 0.1707 - val_loss: 0.1422 - val_accuracy: 0.1631\n",
      "Epoch 17/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1426 - accuracy: 0.1762 - val_loss: 0.1422 - val_accuracy: 0.1910\n",
      "Epoch 18/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1426 - accuracy: 0.1786 - val_loss: 0.1422 - val_accuracy: 0.1939\n",
      "Epoch 19/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1426 - accuracy: 0.1808 - val_loss: 0.1422 - val_accuracy: 0.2040\n",
      "Epoch 20/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1426 - accuracy: 0.1857 - val_loss: 0.1422 - val_accuracy: 0.1837\n",
      "Epoch 21/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1426 - accuracy: 0.1869 - val_loss: 0.1422 - val_accuracy: 0.2167\n",
      "Epoch 22/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1426 - accuracy: 0.1883 - val_loss: 0.1422 - val_accuracy: 0.1957\n",
      "Epoch 23/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1426 - accuracy: 0.1905 - val_loss: 0.1421 - val_accuracy: 0.2055\n",
      "Epoch 24/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1426 - accuracy: 0.1882 - val_loss: 0.1421 - val_accuracy: 0.1901\n",
      "Epoch 25/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1426 - accuracy: 0.1894 - val_loss: 0.1421 - val_accuracy: 0.2085\n",
      "Epoch 26/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1426 - accuracy: 0.1888 - val_loss: 0.1421 - val_accuracy: 0.1563\n",
      "Epoch 27/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1426 - accuracy: 0.1893 - val_loss: 0.1421 - val_accuracy: 0.2153\n",
      "Epoch 28/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1426 - accuracy: 0.1876 - val_loss: 0.1421 - val_accuracy: 0.2080\n",
      "Epoch 29/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1426 - accuracy: 0.1886 - val_loss: 0.1421 - val_accuracy: 0.2146\n",
      "Epoch 30/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1426 - accuracy: 0.1893 - val_loss: 0.1421 - val_accuracy: 0.2274\n",
      "Epoch 31/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1426 - accuracy: 0.1908 - val_loss: 0.1421 - val_accuracy: 0.1508\n",
      "Epoch 32/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1426 - accuracy: 0.1886 - val_loss: 0.1421 - val_accuracy: 0.1660\n",
      "Epoch 33/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1426 - accuracy: 0.1895 - val_loss: 0.1421 - val_accuracy: 0.1765\n",
      "Epoch 34/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1426 - accuracy: 0.1892 - val_loss: 0.1421 - val_accuracy: 0.2301\n",
      "Epoch 35/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1426 - accuracy: 0.1881 - val_loss: 0.1421 - val_accuracy: 0.2126\n",
      "Epoch 36/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1426 - accuracy: 0.1910 - val_loss: 0.1421 - val_accuracy: 0.2043\n",
      "Epoch 37/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1426 - accuracy: 0.1911 - val_loss: 0.1421 - val_accuracy: 0.1975\n",
      "Epoch 38/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1426 - accuracy: 0.1933 - val_loss: 0.1421 - val_accuracy: 0.2233\n",
      "Epoch 39/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1426 - accuracy: 0.1879 - val_loss: 0.1421 - val_accuracy: 0.1981\n",
      "Epoch 40/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1426 - accuracy: 0.1914 - val_loss: 0.1421 - val_accuracy: 0.2265\n",
      "Epoch 41/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.1931 - val_loss: 0.1421 - val_accuracy: 0.2156\n",
      "Epoch 42/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1426 - accuracy: 0.1940 - val_loss: 0.1421 - val_accuracy: 0.2114\n",
      "Epoch 43/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1425 - accuracy: 0.1953 - val_loss: 0.1421 - val_accuracy: 0.2001\n",
      "Epoch 44/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1425 - accuracy: 0.1961 - val_loss: 0.1421 - val_accuracy: 0.2263\n",
      "Epoch 45/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.1977 - val_loss: 0.1421 - val_accuracy: 0.2325\n",
      "Epoch 46/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1425 - accuracy: 0.1942 - val_loss: 0.1421 - val_accuracy: 0.2199\n",
      "Epoch 47/100\n",
      "57527/57527 [==============================] - 4s 72us/step - loss: 0.1425 - accuracy: 0.1943 - val_loss: 0.1421 - val_accuracy: 0.2056\n",
      "Epoch 48/100\n",
      "57527/57527 [==============================] - 4s 75us/step - loss: 0.1425 - accuracy: 0.1958 - val_loss: 0.1421 - val_accuracy: 0.1667\n",
      "Epoch 49/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.1977 - val_loss: 0.1421 - val_accuracy: 0.2158\n",
      "Epoch 50/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1425 - accuracy: 0.1981 - val_loss: 0.1421 - val_accuracy: 0.2203\n",
      "Epoch 51/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.1999 - val_loss: 0.1421 - val_accuracy: 0.2172\n",
      "Epoch 52/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1425 - accuracy: 0.2013 - val_loss: 0.1421 - val_accuracy: 0.1950\n",
      "Epoch 53/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2002 - val_loss: 0.1421 - val_accuracy: 0.2327\n",
      "Epoch 54/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1425 - accuracy: 0.1978 - val_loss: 0.1421 - val_accuracy: 0.2281\n",
      "Epoch 55/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1425 - accuracy: 0.2005 - val_loss: 0.1421 - val_accuracy: 0.2217\n",
      "Epoch 56/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1425 - accuracy: 0.2024 - val_loss: 0.1421 - val_accuracy: 0.2249\n",
      "Epoch 57/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2028 - val_loss: 0.1421 - val_accuracy: 0.2130\n",
      "Epoch 58/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2011 - val_loss: 0.1421 - val_accuracy: 0.2073\n",
      "Epoch 59/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2018 - val_loss: 0.1421 - val_accuracy: 0.2102\n",
      "Epoch 60/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1425 - accuracy: 0.2013 - val_loss: 0.1421 - val_accuracy: 0.2276\n",
      "Epoch 61/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1425 - accuracy: 0.2030 - val_loss: 0.1421 - val_accuracy: 0.2265\n",
      "Epoch 62/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2033 - val_loss: 0.1421 - val_accuracy: 0.2267\n",
      "Epoch 63/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1425 - accuracy: 0.2018 - val_loss: 0.1421 - val_accuracy: 0.2295\n",
      "Epoch 64/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.1996 - val_loss: 0.1421 - val_accuracy: 0.2171\n",
      "Epoch 65/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2048 - val_loss: 0.1421 - val_accuracy: 0.1957\n",
      "Epoch 66/100\n",
      "57527/57527 [==============================] - 4s 71us/step - loss: 0.1425 - accuracy: 0.2027 - val_loss: 0.1421 - val_accuracy: 0.2310\n",
      "Epoch 67/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1425 - accuracy: 0.2053 - val_loss: 0.1421 - val_accuracy: 0.1825\n",
      "Epoch 68/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1425 - accuracy: 0.2011 - val_loss: 0.1421 - val_accuracy: 0.2084\n",
      "Epoch 69/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2033 - val_loss: 0.1421 - val_accuracy: 0.2080\n",
      "Epoch 70/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2010 - val_loss: 0.1421 - val_accuracy: 0.2268\n",
      "Epoch 71/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2027 - val_loss: 0.1421 - val_accuracy: 0.2217\n",
      "Epoch 72/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1425 - accuracy: 0.2037 - val_loss: 0.1421 - val_accuracy: 0.1772\n",
      "Epoch 73/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1425 - accuracy: 0.2020 - val_loss: 0.1421 - val_accuracy: 0.2315\n",
      "Epoch 74/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2029 - val_loss: 0.1421 - val_accuracy: 0.2062\n",
      "Epoch 75/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2036 - val_loss: 0.1421 - val_accuracy: 0.2277\n",
      "Epoch 76/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2051 - val_loss: 0.1421 - val_accuracy: 0.2279\n",
      "Epoch 77/100\n",
      "57527/57527 [==============================] - 4s 71us/step - loss: 0.1425 - accuracy: 0.2058 - val_loss: 0.1421 - val_accuracy: 0.1952\n",
      "Epoch 78/100\n",
      "57527/57527 [==============================] - 4s 72us/step - loss: 0.1425 - accuracy: 0.2024 - val_loss: 0.1421 - val_accuracy: 0.1992\n",
      "Epoch 79/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2039 - val_loss: 0.1421 - val_accuracy: 0.2304\n",
      "Epoch 80/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2020 - val_loss: 0.1421 - val_accuracy: 0.2114\n",
      "Epoch 81/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1425 - accuracy: 0.2040 - val_loss: 0.1421 - val_accuracy: 0.2009\n",
      "Epoch 82/100\n",
      "57527/57527 [==============================] - 4s 71us/step - loss: 0.1425 - accuracy: 0.2034 - val_loss: 0.1421 - val_accuracy: 0.1899\n",
      "Epoch 83/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2022 - val_loss: 0.1421 - val_accuracy: 0.2331\n",
      "Epoch 84/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2034 - val_loss: 0.1421 - val_accuracy: 0.2306\n",
      "Epoch 85/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2033 - val_loss: 0.1421 - val_accuracy: 0.2226\n",
      "Epoch 86/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1425 - accuracy: 0.2030 - val_loss: 0.1421 - val_accuracy: 0.2096\n",
      "Epoch 87/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2035 - val_loss: 0.1421 - val_accuracy: 0.2134\n",
      "Epoch 88/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2040 - val_loss: 0.1421 - val_accuracy: 0.2211\n",
      "Epoch 89/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1425 - accuracy: 0.2048 - val_loss: 0.1421 - val_accuracy: 0.2231\n",
      "Epoch 90/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1425 - accuracy: 0.2065 - val_loss: 0.1421 - val_accuracy: 0.1913\n",
      "Epoch 91/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2051 - val_loss: 0.1421 - val_accuracy: 0.2302\n",
      "Epoch 92/100\n",
      "57527/57527 [==============================] - 4s 76us/step - loss: 0.1425 - accuracy: 0.2048 - val_loss: 0.1421 - val_accuracy: 0.2242\n",
      "Epoch 93/100\n",
      "57527/57527 [==============================] - 4s 72us/step - loss: 0.1425 - accuracy: 0.2057 - val_loss: 0.1421 - val_accuracy: 0.2172\n",
      "Epoch 94/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1425 - accuracy: 0.2047 - val_loss: 0.1421 - val_accuracy: 0.2278\n",
      "Epoch 95/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2025 - val_loss: 0.1421 - val_accuracy: 0.2265\n",
      "Epoch 96/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2025 - val_loss: 0.1421 - val_accuracy: 0.2244\n",
      "Epoch 97/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2042 - val_loss: 0.1421 - val_accuracy: 0.2287\n",
      "Epoch 98/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2021 - val_loss: 0.1421 - val_accuracy: 0.2203\n",
      "Epoch 99/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2042 - val_loss: 0.1421 - val_accuracy: 0.2317\n",
      "Epoch 100/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2046 - val_loss: 0.1421 - val_accuracy: 0.2292\n",
      "training model-14\n",
      "Train on 57527 samples, validate on 14382 samples\n",
      "Epoch 1/100\n",
      "57527/57527 [==============================] - 6s 102us/step - loss: 0.0692 - accuracy: 0.2167 - val_loss: 0.0537 - val_accuracy: 0.2267\n",
      "Epoch 2/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0541 - accuracy: 0.2266 - val_loss: 0.0520 - val_accuracy: 0.2267\n",
      "Epoch 3/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0524 - accuracy: 0.2266 - val_loss: 0.0518 - val_accuracy: 0.2267\n",
      "Epoch 4/100\n",
      "57527/57527 [==============================] - 4s 68us/step - loss: 0.0519 - accuracy: 0.2266 - val_loss: 0.0495 - val_accuracy: 0.2267\n",
      "Epoch 5/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0459 - accuracy: 0.2266 - val_loss: 0.0417 - val_accuracy: 0.2267\n",
      "Epoch 6/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0387 - accuracy: 0.2196 - val_loss: 0.0310 - val_accuracy: 0.2267\n",
      "Epoch 7/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0334 - accuracy: 0.1950 - val_loss: 0.0293 - val_accuracy: 0.2086\n",
      "Epoch 8/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0320 - accuracy: 0.1738 - val_loss: 0.0286 - val_accuracy: 0.2086\n",
      "Epoch 9/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0313 - accuracy: 0.1694 - val_loss: 0.0281 - val_accuracy: 0.2089\n",
      "Epoch 10/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0311 - accuracy: 0.1619 - val_loss: 0.0278 - val_accuracy: 0.1958\n",
      "Epoch 11/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0307 - accuracy: 0.1645 - val_loss: 0.0273 - val_accuracy: 0.1970\n",
      "Epoch 12/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0304 - accuracy: 0.1658 - val_loss: 0.0272 - val_accuracy: 0.1969\n",
      "Epoch 13/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0304 - accuracy: 0.1660 - val_loss: 0.0270 - val_accuracy: 0.1965\n",
      "Epoch 14/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0301 - accuracy: 0.1646 - val_loss: 0.0268 - val_accuracy: 0.1978\n",
      "Epoch 15/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0297 - accuracy: 0.1668 - val_loss: 0.0269 - val_accuracy: 0.1987\n",
      "Epoch 16/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0289 - accuracy: 0.1623 - val_loss: 0.0266 - val_accuracy: 0.2098\n",
      "Epoch 17/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0283 - accuracy: 0.1588 - val_loss: 0.0264 - val_accuracy: 0.2046\n",
      "Epoch 18/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0275 - accuracy: 0.1598 - val_loss: 0.0254 - val_accuracy: 0.1815\n",
      "Epoch 19/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0270 - accuracy: 0.1561 - val_loss: 0.0251 - val_accuracy: 0.1894\n",
      "Epoch 20/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0267 - accuracy: 0.1560 - val_loss: 0.0249 - val_accuracy: 0.1818\n",
      "Epoch 21/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0265 - accuracy: 0.1506 - val_loss: 0.0249 - val_accuracy: 0.1815\n",
      "Epoch 22/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0264 - accuracy: 0.1528 - val_loss: 0.0248 - val_accuracy: 0.1770\n",
      "Epoch 23/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0263 - accuracy: 0.1524 - val_loss: 0.0246 - val_accuracy: 0.1733\n",
      "Epoch 24/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0261 - accuracy: 0.1501 - val_loss: 0.0245 - val_accuracy: 0.1717\n",
      "Epoch 25/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0260 - accuracy: 0.1528 - val_loss: 0.0244 - val_accuracy: 0.1671\n",
      "Epoch 26/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0259 - accuracy: 0.1538 - val_loss: 0.0243 - val_accuracy: 0.1692\n",
      "Epoch 27/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0258 - accuracy: 0.1564 - val_loss: 0.0242 - val_accuracy: 0.1713\n",
      "Epoch 28/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0257 - accuracy: 0.1595 - val_loss: 0.0240 - val_accuracy: 0.1637\n",
      "Epoch 29/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0255 - accuracy: 0.1591 - val_loss: 0.0236 - val_accuracy: 0.1625\n",
      "Epoch 30/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0249 - accuracy: 0.1604 - val_loss: 0.0221 - val_accuracy: 0.1690\n",
      "Epoch 31/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0236 - accuracy: 0.1574 - val_loss: 0.0201 - val_accuracy: 0.1681\n",
      "Epoch 32/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0225 - accuracy: 0.1549 - val_loss: 0.0192 - val_accuracy: 0.1765\n",
      "Epoch 33/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0218 - accuracy: 0.1570 - val_loss: 0.0187 - val_accuracy: 0.1822\n",
      "Epoch 34/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0211 - accuracy: 0.1548 - val_loss: 0.0183 - val_accuracy: 0.1818\n",
      "Epoch 35/100\n",
      "57527/57527 [==============================] - 4s 75us/step - loss: 0.0206 - accuracy: 0.1525 - val_loss: 0.0180 - val_accuracy: 0.1804\n",
      "Epoch 36/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0203 - accuracy: 0.1468 - val_loss: 0.0177 - val_accuracy: 0.1801\n",
      "Epoch 37/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0200 - accuracy: 0.1482 - val_loss: 0.0175 - val_accuracy: 0.1854\n",
      "Epoch 38/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0196 - accuracy: 0.1491 - val_loss: 0.0173 - val_accuracy: 0.1883\n",
      "Epoch 39/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0194 - accuracy: 0.1486 - val_loss: 0.0170 - val_accuracy: 0.1774\n",
      "Epoch 40/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0191 - accuracy: 0.1567 - val_loss: 0.0167 - val_accuracy: 0.1847\n",
      "Epoch 41/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0188 - accuracy: 0.1667 - val_loss: 0.0165 - val_accuracy: 0.1838\n",
      "Epoch 42/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0186 - accuracy: 0.1692 - val_loss: 0.0162 - val_accuracy: 0.1893\n",
      "Epoch 43/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0183 - accuracy: 0.1700 - val_loss: 0.0160 - val_accuracy: 0.1868\n",
      "Epoch 44/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0181 - accuracy: 0.1734 - val_loss: 0.0158 - val_accuracy: 0.1847\n",
      "Epoch 45/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0179 - accuracy: 0.1721 - val_loss: 0.0156 - val_accuracy: 0.1861\n",
      "Epoch 46/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0178 - accuracy: 0.1727 - val_loss: 0.0154 - val_accuracy: 0.1879\n",
      "Epoch 47/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0176 - accuracy: 0.1755 - val_loss: 0.0153 - val_accuracy: 0.1876\n",
      "Epoch 48/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0175 - accuracy: 0.1730 - val_loss: 0.0152 - val_accuracy: 0.1887\n",
      "Epoch 49/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0173 - accuracy: 0.1724 - val_loss: 0.0150 - val_accuracy: 0.1879\n",
      "Epoch 50/100\n",
      "57527/57527 [==============================] - 4s 71us/step - loss: 0.0171 - accuracy: 0.1717 - val_loss: 0.0149 - val_accuracy: 0.1806\n",
      "Epoch 51/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0171 - accuracy: 0.1724 - val_loss: 0.0148 - val_accuracy: 0.1842\n",
      "Epoch 52/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0169 - accuracy: 0.1719 - val_loss: 0.0147 - val_accuracy: 0.1833\n",
      "Epoch 53/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0167 - accuracy: 0.1738 - val_loss: 0.0145 - val_accuracy: 0.1868\n",
      "Epoch 54/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0166 - accuracy: 0.1717 - val_loss: 0.0144 - val_accuracy: 0.1865\n",
      "Epoch 55/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0165 - accuracy: 0.1741 - val_loss: 0.0144 - val_accuracy: 0.1926\n",
      "Epoch 56/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0163 - accuracy: 0.1760 - val_loss: 0.0142 - val_accuracy: 0.1908\n",
      "Epoch 57/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0163 - accuracy: 0.1755 - val_loss: 0.0141 - val_accuracy: 0.1934\n",
      "Epoch 58/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0162 - accuracy: 0.1770 - val_loss: 0.0140 - val_accuracy: 0.1947\n",
      "Epoch 59/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0160 - accuracy: 0.1766 - val_loss: 0.0139 - val_accuracy: 0.1969\n",
      "Epoch 60/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0159 - accuracy: 0.1737 - val_loss: 0.0138 - val_accuracy: 0.2009\n",
      "Epoch 61/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0159 - accuracy: 0.1769 - val_loss: 0.0138 - val_accuracy: 0.1984\n",
      "Epoch 62/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0157 - accuracy: 0.1748 - val_loss: 0.0137 - val_accuracy: 0.1920\n",
      "Epoch 63/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0156 - accuracy: 0.1738 - val_loss: 0.0137 - val_accuracy: 0.1934\n",
      "Epoch 64/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0156 - accuracy: 0.1749 - val_loss: 0.0136 - val_accuracy: 0.1950\n",
      "Epoch 65/100\n",
      "57527/57527 [==============================] - 4s 72us/step - loss: 0.0155 - accuracy: 0.1736 - val_loss: 0.0136 - val_accuracy: 0.2025\n",
      "Epoch 66/100\n",
      "57527/57527 [==============================] - 4s 73us/step - loss: 0.0154 - accuracy: 0.1743 - val_loss: 0.0135 - val_accuracy: 0.2013\n",
      "Epoch 67/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0153 - accuracy: 0.1769 - val_loss: 0.0134 - val_accuracy: 0.1959\n",
      "Epoch 68/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0152 - accuracy: 0.1763 - val_loss: 0.0133 - val_accuracy: 0.1934\n",
      "Epoch 69/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0151 - accuracy: 0.1770 - val_loss: 0.0132 - val_accuracy: 0.1952\n",
      "Epoch 70/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0149 - accuracy: 0.1812 - val_loss: 0.0130 - val_accuracy: 0.1934\n",
      "Epoch 71/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0148 - accuracy: 0.1805 - val_loss: 0.0130 - val_accuracy: 0.1920\n",
      "Epoch 72/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0147 - accuracy: 0.1796 - val_loss: 0.0129 - val_accuracy: 0.1919\n",
      "Epoch 73/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0147 - accuracy: 0.1829 - val_loss: 0.0128 - val_accuracy: 0.1961\n",
      "Epoch 74/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0146 - accuracy: 0.1833 - val_loss: 0.0128 - val_accuracy: 0.1887\n",
      "Epoch 75/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0145 - accuracy: 0.1832 - val_loss: 0.0127 - val_accuracy: 0.1973\n",
      "Epoch 76/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0144 - accuracy: 0.1831 - val_loss: 0.0127 - val_accuracy: 0.1865\n",
      "Epoch 77/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0144 - accuracy: 0.1841 - val_loss: 0.0127 - val_accuracy: 0.1968\n",
      "Epoch 78/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0143 - accuracy: 0.1842 - val_loss: 0.0127 - val_accuracy: 0.1963\n",
      "Epoch 79/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0143 - accuracy: 0.1852 - val_loss: 0.0126 - val_accuracy: 0.1995\n",
      "Epoch 80/100\n",
      "57527/57527 [==============================] - 4s 73us/step - loss: 0.0142 - accuracy: 0.1847 - val_loss: 0.0126 - val_accuracy: 0.2010\n",
      "Epoch 81/100\n",
      "57527/57527 [==============================] - 4s 72us/step - loss: 0.0142 - accuracy: 0.1833 - val_loss: 0.0126 - val_accuracy: 0.1973\n",
      "Epoch 82/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0142 - accuracy: 0.1827 - val_loss: 0.0126 - val_accuracy: 0.1975\n",
      "Epoch 83/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0141 - accuracy: 0.1829 - val_loss: 0.0126 - val_accuracy: 0.1991\n",
      "Epoch 84/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0141 - accuracy: 0.1816 - val_loss: 0.0126 - val_accuracy: 0.1904\n",
      "Epoch 85/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0140 - accuracy: 0.1841 - val_loss: 0.0125 - val_accuracy: 0.1944\n",
      "Epoch 86/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0140 - accuracy: 0.1845 - val_loss: 0.0125 - val_accuracy: 0.2021\n",
      "Epoch 87/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0140 - accuracy: 0.1837 - val_loss: 0.0125 - val_accuracy: 0.1982\n",
      "Epoch 88/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0139 - accuracy: 0.1805 - val_loss: 0.0125 - val_accuracy: 0.1922\n",
      "Epoch 89/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0139 - accuracy: 0.1819 - val_loss: 0.0124 - val_accuracy: 0.1789\n",
      "Epoch 90/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0139 - accuracy: 0.1799 - val_loss: 0.0125 - val_accuracy: 0.1956\n",
      "Epoch 91/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0139 - accuracy: 0.1840 - val_loss: 0.0125 - val_accuracy: 0.2007\n",
      "Epoch 92/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0139 - accuracy: 0.1825 - val_loss: 0.0124 - val_accuracy: 0.1987\n",
      "Epoch 93/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0139 - accuracy: 0.1832 - val_loss: 0.0124 - val_accuracy: 0.1898\n",
      "Epoch 94/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0138 - accuracy: 0.1819 - val_loss: 0.0124 - val_accuracy: 0.1960\n",
      "Epoch 95/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0138 - accuracy: 0.1846 - val_loss: 0.0124 - val_accuracy: 0.1886\n",
      "Epoch 96/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0138 - accuracy: 0.1822 - val_loss: 0.0124 - val_accuracy: 0.1903\n",
      "Epoch 97/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0137 - accuracy: 0.1798 - val_loss: 0.0124 - val_accuracy: 0.1984\n",
      "Epoch 98/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0137 - accuracy: 0.1807 - val_loss: 0.0124 - val_accuracy: 0.1921\n",
      "Epoch 99/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0137 - accuracy: 0.1837 - val_loss: 0.0124 - val_accuracy: 0.1964\n",
      "Epoch 100/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.0137 - accuracy: 0.1830 - val_loss: 0.0124 - val_accuracy: 0.2004\n",
      "training model-15\n",
      "Train on 57527 samples, validate on 14382 samples\n",
      "Epoch 1/100\n",
      "57527/57527 [==============================] - 6s 104us/step - loss: 0.1444 - accuracy: 0.1678 - val_loss: 0.1429 - val_accuracy: 0.1592\n",
      "Epoch 2/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1433 - accuracy: 0.1549 - val_loss: 0.1427 - val_accuracy: 0.1249\n",
      "Epoch 3/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1432 - accuracy: 0.1552 - val_loss: 0.1427 - val_accuracy: 0.1681\n",
      "Epoch 4/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1430 - accuracy: 0.1513 - val_loss: 0.1425 - val_accuracy: 0.1427\n",
      "Epoch 5/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1429 - accuracy: 0.1521 - val_loss: 0.1424 - val_accuracy: 0.1619\n",
      "Epoch 6/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1428 - accuracy: 0.1555 - val_loss: 0.1423 - val_accuracy: 0.1195\n",
      "Epoch 7/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1428 - accuracy: 0.1634 - val_loss: 0.1423 - val_accuracy: 0.1537\n",
      "Epoch 8/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1427 - accuracy: 0.1685 - val_loss: 0.1422 - val_accuracy: 0.1428\n",
      "Epoch 9/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1427 - accuracy: 0.1725 - val_loss: 0.1422 - val_accuracy: 0.1875\n",
      "Epoch 10/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1427 - accuracy: 0.1737 - val_loss: 0.1422 - val_accuracy: 0.1911\n",
      "Epoch 11/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1427 - accuracy: 0.1806 - val_loss: 0.1422 - val_accuracy: 0.2030\n",
      "Epoch 12/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1426 - accuracy: 0.1817 - val_loss: 0.1421 - val_accuracy: 0.2173\n",
      "Epoch 13/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1426 - accuracy: 0.1837 - val_loss: 0.1421 - val_accuracy: 0.2244\n",
      "Epoch 14/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1426 - accuracy: 0.1863 - val_loss: 0.1421 - val_accuracy: 0.2040\n",
      "Epoch 15/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1426 - accuracy: 0.1893 - val_loss: 0.1421 - val_accuracy: 0.2136\n",
      "Epoch 16/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1426 - accuracy: 0.1886 - val_loss: 0.1421 - val_accuracy: 0.2137\n",
      "Epoch 17/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1426 - accuracy: 0.1924 - val_loss: 0.1421 - val_accuracy: 0.2274\n",
      "Epoch 18/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1426 - accuracy: 0.1932 - val_loss: 0.1421 - val_accuracy: 0.2262\n",
      "Epoch 19/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1426 - accuracy: 0.1936 - val_loss: 0.1421 - val_accuracy: 0.2170\n",
      "Epoch 20/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1426 - accuracy: 0.1970 - val_loss: 0.1421 - val_accuracy: 0.2192\n",
      "Epoch 21/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1426 - accuracy: 0.1954 - val_loss: 0.1421 - val_accuracy: 0.2164\n",
      "Epoch 22/100\n",
      "57527/57527 [==============================] - 4s 71us/step - loss: 0.1425 - accuracy: 0.1954 - val_loss: 0.1421 - val_accuracy: 0.2185\n",
      "Epoch 23/100\n",
      "57527/57527 [==============================] - 4s 75us/step - loss: 0.1425 - accuracy: 0.1986 - val_loss: 0.1421 - val_accuracy: 0.2274\n",
      "Epoch 24/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.1970 - val_loss: 0.1421 - val_accuracy: 0.2290\n",
      "Epoch 25/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.1973 - val_loss: 0.1421 - val_accuracy: 0.2038\n",
      "Epoch 26/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.1993 - val_loss: 0.1421 - val_accuracy: 0.2287\n",
      "Epoch 27/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.1987 - val_loss: 0.1421 - val_accuracy: 0.2196\n",
      "Epoch 28/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2032 - val_loss: 0.1421 - val_accuracy: 0.2289\n",
      "Epoch 29/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2016 - val_loss: 0.1421 - val_accuracy: 0.1709\n",
      "Epoch 30/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2021 - val_loss: 0.1421 - val_accuracy: 0.2066\n",
      "Epoch 31/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2007 - val_loss: 0.1421 - val_accuracy: 0.2244\n",
      "Epoch 32/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1425 - accuracy: 0.2032 - val_loss: 0.1421 - val_accuracy: 0.2316\n",
      "Epoch 33/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2045 - val_loss: 0.1421 - val_accuracy: 0.2186\n",
      "Epoch 34/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1425 - accuracy: 0.2040 - val_loss: 0.1421 - val_accuracy: 0.1974\n",
      "Epoch 35/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1425 - accuracy: 0.2038 - val_loss: 0.1421 - val_accuracy: 0.1756\n",
      "Epoch 36/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2044 - val_loss: 0.1421 - val_accuracy: 0.2034\n",
      "Epoch 37/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2033 - val_loss: 0.1421 - val_accuracy: 0.1905\n",
      "Epoch 38/100\n",
      "57527/57527 [==============================] - 4s 71us/step - loss: 0.1425 - accuracy: 0.2042 - val_loss: 0.1421 - val_accuracy: 0.2195\n",
      "Epoch 39/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2043 - val_loss: 0.1421 - val_accuracy: 0.2244\n",
      "Epoch 40/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2035 - val_loss: 0.1421 - val_accuracy: 0.2109\n",
      "Epoch 41/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2042 - val_loss: 0.1421 - val_accuracy: 0.1735\n",
      "Epoch 42/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2061 - val_loss: 0.1421 - val_accuracy: 0.1932\n",
      "Epoch 43/100\n",
      "57527/57527 [==============================] - 4s 71us/step - loss: 0.1425 - accuracy: 0.2037 - val_loss: 0.1421 - val_accuracy: 0.2087\n",
      "Epoch 44/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2055 - val_loss: 0.1421 - val_accuracy: 0.2190\n",
      "Epoch 45/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2049 - val_loss: 0.1421 - val_accuracy: 0.2249\n",
      "Epoch 46/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2048 - val_loss: 0.1421 - val_accuracy: 0.2321\n",
      "Epoch 47/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2075 - val_loss: 0.1421 - val_accuracy: 0.2324\n",
      "Epoch 48/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2086 - val_loss: 0.1421 - val_accuracy: 0.1871\n",
      "Epoch 49/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2057 - val_loss: 0.1421 - val_accuracy: 0.1909\n",
      "Epoch 50/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2053 - val_loss: 0.1421 - val_accuracy: 0.2233\n",
      "Epoch 51/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1425 - accuracy: 0.2077 - val_loss: 0.1421 - val_accuracy: 0.1856\n",
      "Epoch 52/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2057 - val_loss: 0.1421 - val_accuracy: 0.2296\n",
      "Epoch 53/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2079 - val_loss: 0.1421 - val_accuracy: 0.2136\n",
      "Epoch 54/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2079 - val_loss: 0.1421 - val_accuracy: 0.2256\n",
      "Epoch 55/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2065 - val_loss: 0.1421 - val_accuracy: 0.2138\n",
      "Epoch 56/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2069 - val_loss: 0.1421 - val_accuracy: 0.2132\n",
      "Epoch 57/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2070 - val_loss: 0.1421 - val_accuracy: 0.1852\n",
      "Epoch 58/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2051 - val_loss: 0.1421 - val_accuracy: 0.2229\n",
      "Epoch 59/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2082 - val_loss: 0.1421 - val_accuracy: 0.1775\n",
      "Epoch 60/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2068 - val_loss: 0.1421 - val_accuracy: 0.2224\n",
      "Epoch 61/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1425 - accuracy: 0.2072 - val_loss: 0.1421 - val_accuracy: 0.2260\n",
      "Epoch 62/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2083 - val_loss: 0.1421 - val_accuracy: 0.2196\n",
      "Epoch 63/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2078 - val_loss: 0.1421 - val_accuracy: 0.2308\n",
      "Epoch 64/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2081 - val_loss: 0.1421 - val_accuracy: 0.2321\n",
      "Epoch 65/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2086 - val_loss: 0.1421 - val_accuracy: 0.2138\n",
      "Epoch 66/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2077 - val_loss: 0.1421 - val_accuracy: 0.1930\n",
      "Epoch 67/100\n",
      "57527/57527 [==============================] - 4s 73us/step - loss: 0.1425 - accuracy: 0.2098 - val_loss: 0.1421 - val_accuracy: 0.2119\n",
      "Epoch 68/100\n",
      "57527/57527 [==============================] - 4s 74us/step - loss: 0.1425 - accuracy: 0.2077 - val_loss: 0.1421 - val_accuracy: 0.2182\n",
      "Epoch 69/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2066 - val_loss: 0.1421 - val_accuracy: 0.2238\n",
      "Epoch 70/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2087 - val_loss: 0.1421 - val_accuracy: 0.2326\n",
      "Epoch 71/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2110 - val_loss: 0.1421 - val_accuracy: 0.2293\n",
      "Epoch 72/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2090 - val_loss: 0.1421 - val_accuracy: 0.2305\n",
      "Epoch 73/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2095 - val_loss: 0.1421 - val_accuracy: 0.1644\n",
      "Epoch 74/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2079 - val_loss: 0.1421 - val_accuracy: 0.2194\n",
      "Epoch 75/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2096 - val_loss: 0.1421 - val_accuracy: 0.2331\n",
      "Epoch 76/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2083 - val_loss: 0.1421 - val_accuracy: 0.2323\n",
      "Epoch 77/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2113 - val_loss: 0.1421 - val_accuracy: 0.2061\n",
      "Epoch 78/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2098 - val_loss: 0.1421 - val_accuracy: 0.2260\n",
      "Epoch 79/100\n",
      "57527/57527 [==============================] - 4s 69us/step - loss: 0.1425 - accuracy: 0.2083 - val_loss: 0.1421 - val_accuracy: 0.2311\n",
      "Epoch 80/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2101 - val_loss: 0.1421 - val_accuracy: 0.2276\n",
      "Epoch 81/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2100 - val_loss: 0.1421 - val_accuracy: 0.2317\n",
      "Epoch 82/100\n",
      "57527/57527 [==============================] - 4s 71us/step - loss: 0.1425 - accuracy: 0.2111 - val_loss: 0.1421 - val_accuracy: 0.1909\n",
      "Epoch 83/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2091 - val_loss: 0.1421 - val_accuracy: 0.2312\n",
      "Epoch 84/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2103 - val_loss: 0.1421 - val_accuracy: 0.2096\n",
      "Epoch 85/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2088 - val_loss: 0.1421 - val_accuracy: 0.2216\n",
      "Epoch 86/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2110 - val_loss: 0.1421 - val_accuracy: 0.2187\n",
      "Epoch 87/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2102 - val_loss: 0.1421 - val_accuracy: 0.2196\n",
      "Epoch 88/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2083 - val_loss: 0.1421 - val_accuracy: 0.2237\n",
      "Epoch 89/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2098 - val_loss: 0.1421 - val_accuracy: 0.2311\n",
      "Epoch 90/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2108 - val_loss: 0.1421 - val_accuracy: 0.2117\n",
      "Epoch 91/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2112 - val_loss: 0.1421 - val_accuracy: 0.2055\n",
      "Epoch 92/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2087 - val_loss: 0.1421 - val_accuracy: 0.1879\n",
      "Epoch 93/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2107 - val_loss: 0.1421 - val_accuracy: 0.2310\n",
      "Epoch 94/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2105 - val_loss: 0.1421 - val_accuracy: 0.2317\n",
      "Epoch 95/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2114 - val_loss: 0.1421 - val_accuracy: 0.2124\n",
      "Epoch 96/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2094 - val_loss: 0.1421 - val_accuracy: 0.2096\n",
      "Epoch 97/100\n",
      "57527/57527 [==============================] - 4s 73us/step - loss: 0.1425 - accuracy: 0.2095 - val_loss: 0.1421 - val_accuracy: 0.1829\n",
      "Epoch 98/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2101 - val_loss: 0.1421 - val_accuracy: 0.2317\n",
      "Epoch 99/100\n",
      "57527/57527 [==============================] - 4s 71us/step - loss: 0.1425 - accuracy: 0.2112 - val_loss: 0.1421 - val_accuracy: 0.2076\n",
      "Epoch 100/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.1425 - accuracy: 0.2094 - val_loss: 0.1421 - val_accuracy: 0.2007\n",
      "training model-16\n",
      "Train on 57527 samples, validate on 14382 samples\n",
      "Epoch 1/100\n",
      "57527/57527 [==============================] - 6s 107us/step - loss: 0.0390 - accuracy: 0.1684 - val_loss: 0.0228 - val_accuracy: 0.1619\n",
      "Epoch 2/100\n",
      "57527/57527 [==============================] - 4s 71us/step - loss: 0.0232 - accuracy: 0.1624 - val_loss: 0.0182 - val_accuracy: 0.1727\n",
      "Epoch 3/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0206 - accuracy: 0.1602 - val_loss: 0.0163 - val_accuracy: 0.1695\n",
      "Epoch 4/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0191 - accuracy: 0.1637 - val_loss: 0.0152 - val_accuracy: 0.1883\n",
      "Epoch 5/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0181 - accuracy: 0.1602 - val_loss: 0.0144 - val_accuracy: 0.1934\n",
      "Epoch 6/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0173 - accuracy: 0.1613 - val_loss: 0.0138 - val_accuracy: 0.1966\n",
      "Epoch 7/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0167 - accuracy: 0.1586 - val_loss: 0.0134 - val_accuracy: 0.1927\n",
      "Epoch 8/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0161 - accuracy: 0.1601 - val_loss: 0.0131 - val_accuracy: 0.2056\n",
      "Epoch 9/100\n",
      "57527/57527 [==============================] - 4s 74us/step - loss: 0.0159 - accuracy: 0.1623 - val_loss: 0.0130 - val_accuracy: 0.2052\n",
      "Epoch 10/100\n",
      "57527/57527 [==============================] - 4s 72us/step - loss: 0.0156 - accuracy: 0.1627 - val_loss: 0.0128 - val_accuracy: 0.1984\n",
      "Epoch 11/100\n",
      "57527/57527 [==============================] - 4s 71us/step - loss: 0.0154 - accuracy: 0.1642 - val_loss: 0.0127 - val_accuracy: 0.1982\n",
      "Epoch 12/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0152 - accuracy: 0.1623 - val_loss: 0.0127 - val_accuracy: 0.2000\n",
      "Epoch 13/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0151 - accuracy: 0.1631 - val_loss: 0.0126 - val_accuracy: 0.2025\n",
      "Epoch 14/100\n",
      "57527/57527 [==============================] - 4s 71us/step - loss: 0.0149 - accuracy: 0.1609 - val_loss: 0.0126 - val_accuracy: 0.2037\n",
      "Epoch 15/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0148 - accuracy: 0.1588 - val_loss: 0.0125 - val_accuracy: 0.2073\n",
      "Epoch 16/100\n",
      "57527/57527 [==============================] - 4s 71us/step - loss: 0.0147 - accuracy: 0.1614 - val_loss: 0.0125 - val_accuracy: 0.2162\n",
      "Epoch 17/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0146 - accuracy: 0.1590 - val_loss: 0.0124 - val_accuracy: 0.2128\n",
      "Epoch 18/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0145 - accuracy: 0.1584 - val_loss: 0.0124 - val_accuracy: 0.2060\n",
      "Epoch 19/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0144 - accuracy: 0.1602 - val_loss: 0.0125 - val_accuracy: 0.2090\n",
      "Epoch 20/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0143 - accuracy: 0.1593 - val_loss: 0.0124 - val_accuracy: 0.2236\n",
      "Epoch 21/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0143 - accuracy: 0.1628 - val_loss: 0.0124 - val_accuracy: 0.2215\n",
      "Epoch 22/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0142 - accuracy: 0.1588 - val_loss: 0.0125 - val_accuracy: 0.2021\n",
      "Epoch 23/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0142 - accuracy: 0.1619 - val_loss: 0.0123 - val_accuracy: 0.2066\n",
      "Epoch 24/100\n",
      "57527/57527 [==============================] - 4s 71us/step - loss: 0.0142 - accuracy: 0.1599 - val_loss: 0.0123 - val_accuracy: 0.2139\n",
      "Epoch 25/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0141 - accuracy: 0.1594 - val_loss: 0.0124 - val_accuracy: 0.2038\n",
      "Epoch 26/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0141 - accuracy: 0.1597 - val_loss: 0.0124 - val_accuracy: 0.2097\n",
      "Epoch 27/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0140 - accuracy: 0.1604 - val_loss: 0.0123 - val_accuracy: 0.2257\n",
      "Epoch 28/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0141 - accuracy: 0.1604 - val_loss: 0.0123 - val_accuracy: 0.2162\n",
      "Epoch 29/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0140 - accuracy: 0.1615 - val_loss: 0.0123 - val_accuracy: 0.2129\n",
      "Epoch 30/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0140 - accuracy: 0.1578 - val_loss: 0.0123 - val_accuracy: 0.2128\n",
      "Epoch 31/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0140 - accuracy: 0.1591 - val_loss: 0.0123 - val_accuracy: 0.2233\n",
      "Epoch 32/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0139 - accuracy: 0.1598 - val_loss: 0.0123 - val_accuracy: 0.2212\n",
      "Epoch 33/100\n",
      "57527/57527 [==============================] - 4s 71us/step - loss: 0.0139 - accuracy: 0.1608 - val_loss: 0.0123 - val_accuracy: 0.2199\n",
      "Epoch 34/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0139 - accuracy: 0.1607 - val_loss: 0.0123 - val_accuracy: 0.2192\n",
      "Epoch 35/100\n",
      "57527/57527 [==============================] - 4s 71us/step - loss: 0.0138 - accuracy: 0.1611 - val_loss: 0.0123 - val_accuracy: 0.2266\n",
      "Epoch 36/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0138 - accuracy: 0.1633 - val_loss: 0.0123 - val_accuracy: 0.2137\n",
      "Epoch 37/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0138 - accuracy: 0.1607 - val_loss: 0.0122 - val_accuracy: 0.2003\n",
      "Epoch 38/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0138 - accuracy: 0.1631 - val_loss: 0.0122 - val_accuracy: 0.2164\n",
      "Epoch 39/100\n",
      "57527/57527 [==============================] - 4s 71us/step - loss: 0.0138 - accuracy: 0.1600 - val_loss: 0.0122 - val_accuracy: 0.2209\n",
      "Epoch 40/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0137 - accuracy: 0.1630 - val_loss: 0.0123 - val_accuracy: 0.2196\n",
      "Epoch 41/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0137 - accuracy: 0.1610 - val_loss: 0.0122 - val_accuracy: 0.2139\n",
      "Epoch 42/100\n",
      "57527/57527 [==============================] - 4s 71us/step - loss: 0.0137 - accuracy: 0.1626 - val_loss: 0.0123 - val_accuracy: 0.2201\n",
      "Epoch 43/100\n",
      "57527/57527 [==============================] - 4s 71us/step - loss: 0.0137 - accuracy: 0.1605 - val_loss: 0.0123 - val_accuracy: 0.2141\n",
      "Epoch 44/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0137 - accuracy: 0.1618 - val_loss: 0.0122 - val_accuracy: 0.2128\n",
      "Epoch 45/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0137 - accuracy: 0.1619 - val_loss: 0.0122 - val_accuracy: 0.2043\n",
      "Epoch 46/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0137 - accuracy: 0.1620 - val_loss: 0.0122 - val_accuracy: 0.2107\n",
      "Epoch 47/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0136 - accuracy: 0.1638 - val_loss: 0.0122 - val_accuracy: 0.2232\n",
      "Epoch 48/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0137 - accuracy: 0.1616 - val_loss: 0.0122 - val_accuracy: 0.2127\n",
      "Epoch 49/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0137 - accuracy: 0.1601 - val_loss: 0.0122 - val_accuracy: 0.2010\n",
      "Epoch 50/100\n",
      "57527/57527 [==============================] - 4s 71us/step - loss: 0.0136 - accuracy: 0.1632 - val_loss: 0.0122 - val_accuracy: 0.2214\n",
      "Epoch 51/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0136 - accuracy: 0.1623 - val_loss: 0.0122 - val_accuracy: 0.2256\n",
      "Epoch 52/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0136 - accuracy: 0.1611 - val_loss: 0.0122 - val_accuracy: 0.2012\n",
      "Epoch 53/100\n",
      "57527/57527 [==============================] - 4s 71us/step - loss: 0.0136 - accuracy: 0.1611 - val_loss: 0.0122 - val_accuracy: 0.2276\n",
      "Epoch 54/100\n",
      "57527/57527 [==============================] - 4s 75us/step - loss: 0.0136 - accuracy: 0.1613 - val_loss: 0.0122 - val_accuracy: 0.2126\n",
      "Epoch 55/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0136 - accuracy: 0.1621 - val_loss: 0.0122 - val_accuracy: 0.2306\n",
      "Epoch 56/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0136 - accuracy: 0.1607 - val_loss: 0.0122 - val_accuracy: 0.2238\n",
      "Epoch 57/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0136 - accuracy: 0.1614 - val_loss: 0.0121 - val_accuracy: 0.2061\n",
      "Epoch 58/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0136 - accuracy: 0.1636 - val_loss: 0.0121 - val_accuracy: 0.2089\n",
      "Epoch 59/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0135 - accuracy: 0.1618 - val_loss: 0.0122 - val_accuracy: 0.2155\n",
      "Epoch 60/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0135 - accuracy: 0.1618 - val_loss: 0.0122 - val_accuracy: 0.2253\n",
      "Epoch 61/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0135 - accuracy: 0.1610 - val_loss: 0.0122 - val_accuracy: 0.2290\n",
      "Epoch 62/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0135 - accuracy: 0.1619 - val_loss: 0.0122 - val_accuracy: 0.2253\n",
      "Epoch 63/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0135 - accuracy: 0.1620 - val_loss: 0.0122 - val_accuracy: 0.2247\n",
      "Epoch 64/100\n",
      "57527/57527 [==============================] - 4s 71us/step - loss: 0.0135 - accuracy: 0.1614 - val_loss: 0.0121 - val_accuracy: 0.2162\n",
      "Epoch 65/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0135 - accuracy: 0.1637 - val_loss: 0.0121 - val_accuracy: 0.2285\n",
      "Epoch 66/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0135 - accuracy: 0.1637 - val_loss: 0.0122 - val_accuracy: 0.2292\n",
      "Epoch 67/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0135 - accuracy: 0.1616 - val_loss: 0.0121 - val_accuracy: 0.2052\n",
      "Epoch 68/100\n",
      "57527/57527 [==============================] - 4s 71us/step - loss: 0.0135 - accuracy: 0.1614 - val_loss: 0.0123 - val_accuracy: 0.2206\n",
      "Epoch 69/100\n",
      "57527/57527 [==============================] - 4s 72us/step - loss: 0.0135 - accuracy: 0.1618 - val_loss: 0.0122 - val_accuracy: 0.2264\n",
      "Epoch 70/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0135 - accuracy: 0.1632 - val_loss: 0.0122 - val_accuracy: 0.1991\n",
      "Epoch 71/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0135 - accuracy: 0.1634 - val_loss: 0.0121 - val_accuracy: 0.2147\n",
      "Epoch 72/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0134 - accuracy: 0.1607 - val_loss: 0.0121 - val_accuracy: 0.2153\n",
      "Epoch 73/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0135 - accuracy: 0.1636 - val_loss: 0.0122 - val_accuracy: 0.2231\n",
      "Epoch 74/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0134 - accuracy: 0.1623 - val_loss: 0.0121 - val_accuracy: 0.2237\n",
      "Epoch 75/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0134 - accuracy: 0.1609 - val_loss: 0.0122 - val_accuracy: 0.2185\n",
      "Epoch 76/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0134 - accuracy: 0.1621 - val_loss: 0.0121 - val_accuracy: 0.2232\n",
      "Epoch 77/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0134 - accuracy: 0.1632 - val_loss: 0.0121 - val_accuracy: 0.2218\n",
      "Epoch 78/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0134 - accuracy: 0.1605 - val_loss: 0.0121 - val_accuracy: 0.2042\n",
      "Epoch 79/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0134 - accuracy: 0.1642 - val_loss: 0.0121 - val_accuracy: 0.2114\n",
      "Epoch 80/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0134 - accuracy: 0.1623 - val_loss: 0.0123 - val_accuracy: 0.2165\n",
      "Epoch 81/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0134 - accuracy: 0.1620 - val_loss: 0.0121 - val_accuracy: 0.2035\n",
      "Epoch 82/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0134 - accuracy: 0.1631 - val_loss: 0.0121 - val_accuracy: 0.2125\n",
      "Epoch 83/100\n",
      "57527/57527 [==============================] - 4s 71us/step - loss: 0.0134 - accuracy: 0.1608 - val_loss: 0.0122 - val_accuracy: 0.2157\n",
      "Epoch 84/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0134 - accuracy: 0.1633 - val_loss: 0.0121 - val_accuracy: 0.2190\n",
      "Epoch 85/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0134 - accuracy: 0.1633 - val_loss: 0.0121 - val_accuracy: 0.2123\n",
      "Epoch 86/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0134 - accuracy: 0.1626 - val_loss: 0.0121 - val_accuracy: 0.2235\n",
      "Epoch 87/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0134 - accuracy: 0.1614 - val_loss: 0.0121 - val_accuracy: 0.2293\n",
      "Epoch 88/100\n",
      "57527/57527 [==============================] - 4s 71us/step - loss: 0.0134 - accuracy: 0.1619 - val_loss: 0.0121 - val_accuracy: 0.2178\n",
      "Epoch 89/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0134 - accuracy: 0.1638 - val_loss: 0.0121 - val_accuracy: 0.2250\n",
      "Epoch 90/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0134 - accuracy: 0.1624 - val_loss: 0.0121 - val_accuracy: 0.2107\n",
      "Epoch 91/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0134 - accuracy: 0.1631 - val_loss: 0.0121 - val_accuracy: 0.2192\n",
      "Epoch 92/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0133 - accuracy: 0.1661 - val_loss: 0.0122 - val_accuracy: 0.2070\n",
      "Epoch 93/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0134 - accuracy: 0.1648 - val_loss: 0.0121 - val_accuracy: 0.1923\n",
      "Epoch 94/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0134 - accuracy: 0.1624 - val_loss: 0.0121 - val_accuracy: 0.2207\n",
      "Epoch 95/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0133 - accuracy: 0.1620 - val_loss: 0.0121 - val_accuracy: 0.2109\n",
      "Epoch 96/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0133 - accuracy: 0.1620 - val_loss: 0.0121 - val_accuracy: 0.2253\n",
      "Epoch 97/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0133 - accuracy: 0.1619 - val_loss: 0.0122 - val_accuracy: 0.1904\n",
      "Epoch 98/100\n",
      "57527/57527 [==============================] - 4s 76us/step - loss: 0.0133 - accuracy: 0.1641 - val_loss: 0.0121 - val_accuracy: 0.2224\n",
      "Epoch 99/100\n",
      "57527/57527 [==============================] - 4s 71us/step - loss: 0.0133 - accuracy: 0.1622 - val_loss: 0.0121 - val_accuracy: 0.2130\n",
      "Epoch 100/100\n",
      "57527/57527 [==============================] - 4s 70us/step - loss: 0.0133 - accuracy: 0.1634 - val_loss: 0.0122 - val_accuracy: 0.2203\n",
      "training model-17\n",
      "Train on 57527 samples, validate on 14382 samples\n",
      "Epoch 1/100\n",
      "57527/57527 [==============================] - 7s 123us/step - loss: 0.0273 - accuracy: 0.1588 - val_loss: 0.0178 - val_accuracy: 0.1621\n",
      "Epoch 2/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0175 - accuracy: 0.1523 - val_loss: 0.0143 - val_accuracy: 0.1746\n",
      "Epoch 3/100\n",
      "57527/57527 [==============================] - 5s 86us/step - loss: 0.0154 - accuracy: 0.1526 - val_loss: 0.0134 - val_accuracy: 0.1756\n",
      "Epoch 4/100\n",
      "57527/57527 [==============================] - 5s 86us/step - loss: 0.0147 - accuracy: 0.1559 - val_loss: 0.0130 - val_accuracy: 0.1643\n",
      "Epoch 5/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0145 - accuracy: 0.1558 - val_loss: 0.0130 - val_accuracy: 0.1831\n",
      "Epoch 6/100\n",
      "57527/57527 [==============================] - 5s 86us/step - loss: 0.0143 - accuracy: 0.1570 - val_loss: 0.0128 - val_accuracy: 0.1658\n",
      "Epoch 7/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0142 - accuracy: 0.1540 - val_loss: 0.0128 - val_accuracy: 0.1920\n",
      "Epoch 8/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0141 - accuracy: 0.1547 - val_loss: 0.0128 - val_accuracy: 0.1809\n",
      "Epoch 9/100\n",
      "57527/57527 [==============================] - 5s 86us/step - loss: 0.0141 - accuracy: 0.1553 - val_loss: 0.0127 - val_accuracy: 0.1628\n",
      "Epoch 10/100\n",
      "57527/57527 [==============================] - 5s 86us/step - loss: 0.0140 - accuracy: 0.1569 - val_loss: 0.0128 - val_accuracy: 0.1797\n",
      "Epoch 11/100\n",
      "57527/57527 [==============================] - 5s 86us/step - loss: 0.0140 - accuracy: 0.1564 - val_loss: 0.0127 - val_accuracy: 0.1741\n",
      "Epoch 12/100\n",
      "57527/57527 [==============================] - 5s 86us/step - loss: 0.0140 - accuracy: 0.1540 - val_loss: 0.0128 - val_accuracy: 0.1950\n",
      "Epoch 13/100\n",
      "57527/57527 [==============================] - 5s 86us/step - loss: 0.0139 - accuracy: 0.1588 - val_loss: 0.0127 - val_accuracy: 0.1939\n",
      "Epoch 14/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0139 - accuracy: 0.1582 - val_loss: 0.0128 - val_accuracy: 0.2034\n",
      "Epoch 15/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0139 - accuracy: 0.1553 - val_loss: 0.0128 - val_accuracy: 0.2021\n",
      "Epoch 16/100\n",
      "57527/57527 [==============================] - 5s 86us/step - loss: 0.0139 - accuracy: 0.1583 - val_loss: 0.0127 - val_accuracy: 0.1701\n",
      "Epoch 17/100\n",
      "57527/57527 [==============================] - 5s 86us/step - loss: 0.0139 - accuracy: 0.1564 - val_loss: 0.0127 - val_accuracy: 0.1702\n",
      "Epoch 18/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0139 - accuracy: 0.1563 - val_loss: 0.0127 - val_accuracy: 0.2153\n",
      "Epoch 19/100\n",
      "57527/57527 [==============================] - 5s 86us/step - loss: 0.0138 - accuracy: 0.1558 - val_loss: 0.0127 - val_accuracy: 0.1744\n",
      "Epoch 20/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0138 - accuracy: 0.1551 - val_loss: 0.0127 - val_accuracy: 0.1947\n",
      "Epoch 21/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0138 - accuracy: 0.1554 - val_loss: 0.0126 - val_accuracy: 0.2036\n",
      "Epoch 22/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0138 - accuracy: 0.1543 - val_loss: 0.0127 - val_accuracy: 0.1859\n",
      "Epoch 23/100\n",
      "57527/57527 [==============================] - 5s 86us/step - loss: 0.0138 - accuracy: 0.1552 - val_loss: 0.0126 - val_accuracy: 0.1845\n",
      "Epoch 24/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0137 - accuracy: 0.1557 - val_loss: 0.0127 - val_accuracy: 0.2018\n",
      "Epoch 25/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0137 - accuracy: 0.1554 - val_loss: 0.0127 - val_accuracy: 0.2116\n",
      "Epoch 26/100\n",
      "57527/57527 [==============================] - 5s 86us/step - loss: 0.0137 - accuracy: 0.1553 - val_loss: 0.0130 - val_accuracy: 0.1701\n",
      "Epoch 27/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0137 - accuracy: 0.1548 - val_loss: 0.0127 - val_accuracy: 0.1991\n",
      "Epoch 28/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0137 - accuracy: 0.1562 - val_loss: 0.0127 - val_accuracy: 0.1840\n",
      "Epoch 29/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0137 - accuracy: 0.1558 - val_loss: 0.0127 - val_accuracy: 0.1758\n",
      "Epoch 30/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0137 - accuracy: 0.1557 - val_loss: 0.0125 - val_accuracy: 0.2004\n",
      "Epoch 31/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0137 - accuracy: 0.1570 - val_loss: 0.0127 - val_accuracy: 0.1951\n",
      "Epoch 32/100\n",
      "57527/57527 [==============================] - 5s 95us/step - loss: 0.0137 - accuracy: 0.1555 - val_loss: 0.0126 - val_accuracy: 0.2255\n",
      "Epoch 33/100\n",
      "57527/57527 [==============================] - 5s 94us/step - loss: 0.0137 - accuracy: 0.1536 - val_loss: 0.0127 - val_accuracy: 0.2109\n",
      "Epoch 34/100\n",
      "57527/57527 [==============================] - 5s 90us/step - loss: 0.0137 - accuracy: 0.1565 - val_loss: 0.0127 - val_accuracy: 0.1828\n",
      "Epoch 35/100\n",
      "57527/57527 [==============================] - 5s 86us/step - loss: 0.0137 - accuracy: 0.1557 - val_loss: 0.0130 - val_accuracy: 0.1859\n",
      "Epoch 36/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0137 - accuracy: 0.1551 - val_loss: 0.0126 - val_accuracy: 0.1706\n",
      "Epoch 37/100\n",
      "57527/57527 [==============================] - 5s 89us/step - loss: 0.0137 - accuracy: 0.1557 - val_loss: 0.0127 - val_accuracy: 0.1989\n",
      "Epoch 38/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0137 - accuracy: 0.1566 - val_loss: 0.0128 - val_accuracy: 0.2167\n",
      "Epoch 39/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0136 - accuracy: 0.1587 - val_loss: 0.0126 - val_accuracy: 0.1844\n",
      "Epoch 40/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0136 - accuracy: 0.1559 - val_loss: 0.0125 - val_accuracy: 0.1966\n",
      "Epoch 41/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0136 - accuracy: 0.1550 - val_loss: 0.0126 - val_accuracy: 0.1993\n",
      "Epoch 42/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0136 - accuracy: 0.1552 - val_loss: 0.0126 - val_accuracy: 0.1741\n",
      "Epoch 43/100\n",
      "57527/57527 [==============================] - 5s 86us/step - loss: 0.0137 - accuracy: 0.1549 - val_loss: 0.0128 - val_accuracy: 0.1571\n",
      "Epoch 44/100\n",
      "57527/57527 [==============================] - 5s 89us/step - loss: 0.0136 - accuracy: 0.1566 - val_loss: 0.0126 - val_accuracy: 0.1836\n",
      "Epoch 45/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0136 - accuracy: 0.1566 - val_loss: 0.0126 - val_accuracy: 0.1954\n",
      "Epoch 46/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0136 - accuracy: 0.1559 - val_loss: 0.0126 - val_accuracy: 0.2118\n",
      "Epoch 47/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0136 - accuracy: 0.1561 - val_loss: 0.0126 - val_accuracy: 0.2155\n",
      "Epoch 48/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0136 - accuracy: 0.1549 - val_loss: 0.0125 - val_accuracy: 0.1712\n",
      "Epoch 49/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0136 - accuracy: 0.1548 - val_loss: 0.0127 - val_accuracy: 0.2091\n",
      "Epoch 50/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0136 - accuracy: 0.1561 - val_loss: 0.0126 - val_accuracy: 0.1951\n",
      "Epoch 51/100\n",
      "57527/57527 [==============================] - 5s 86us/step - loss: 0.0136 - accuracy: 0.1585 - val_loss: 0.0126 - val_accuracy: 0.1848\n",
      "Epoch 52/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0136 - accuracy: 0.1551 - val_loss: 0.0126 - val_accuracy: 0.2178\n",
      "Epoch 53/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0136 - accuracy: 0.1579 - val_loss: 0.0126 - val_accuracy: 0.1829\n",
      "Epoch 54/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0136 - accuracy: 0.1561 - val_loss: 0.0127 - val_accuracy: 0.2163\n",
      "Epoch 55/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0136 - accuracy: 0.1563 - val_loss: 0.0125 - val_accuracy: 0.2205\n",
      "Epoch 56/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0137 - accuracy: 0.1582 - val_loss: 0.0126 - val_accuracy: 0.1781\n",
      "Epoch 57/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0136 - accuracy: 0.1553 - val_loss: 0.0128 - val_accuracy: 0.2265\n",
      "Epoch 58/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0136 - accuracy: 0.1560 - val_loss: 0.0126 - val_accuracy: 0.1826\n",
      "Epoch 59/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0136 - accuracy: 0.1582 - val_loss: 0.0128 - val_accuracy: 0.2234\n",
      "Epoch 60/100\n",
      "57527/57527 [==============================] - 5s 86us/step - loss: 0.0136 - accuracy: 0.1546 - val_loss: 0.0126 - val_accuracy: 0.2224\n",
      "Epoch 61/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0135 - accuracy: 0.1560 - val_loss: 0.0126 - val_accuracy: 0.1941\n",
      "Epoch 62/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0136 - accuracy: 0.1564 - val_loss: 0.0126 - val_accuracy: 0.2294\n",
      "Epoch 63/100\n",
      "57527/57527 [==============================] - 5s 86us/step - loss: 0.0136 - accuracy: 0.1552 - val_loss: 0.0127 - val_accuracy: 0.1807\n",
      "Epoch 64/100\n",
      "57527/57527 [==============================] - 5s 86us/step - loss: 0.0136 - accuracy: 0.1572 - val_loss: 0.0127 - val_accuracy: 0.1729\n",
      "Epoch 65/100\n",
      "57527/57527 [==============================] - 5s 86us/step - loss: 0.0136 - accuracy: 0.1566 - val_loss: 0.0127 - val_accuracy: 0.2167\n",
      "Epoch 66/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0136 - accuracy: 0.1567 - val_loss: 0.0126 - val_accuracy: 0.2001\n",
      "Epoch 67/100\n",
      "57527/57527 [==============================] - 5s 86us/step - loss: 0.0135 - accuracy: 0.1575 - val_loss: 0.0126 - val_accuracy: 0.1886\n",
      "Epoch 68/100\n",
      "57527/57527 [==============================] - 6s 99us/step - loss: 0.0136 - accuracy: 0.1565 - val_loss: 0.0128 - val_accuracy: 0.2112\n",
      "Epoch 69/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0136 - accuracy: 0.1578 - val_loss: 0.0127 - val_accuracy: 0.2025\n",
      "Epoch 70/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0136 - accuracy: 0.1548 - val_loss: 0.0127 - val_accuracy: 0.2106\n",
      "Epoch 71/100\n",
      "57527/57527 [==============================] - 5s 91us/step - loss: 0.0136 - accuracy: 0.1578 - val_loss: 0.0127 - val_accuracy: 0.2089\n",
      "Epoch 72/100\n",
      "57527/57527 [==============================] - 5s 89us/step - loss: 0.0136 - accuracy: 0.1554 - val_loss: 0.0126 - val_accuracy: 0.2097\n",
      "Epoch 73/100\n",
      "57527/57527 [==============================] - 5s 86us/step - loss: 0.0136 - accuracy: 0.1542 - val_loss: 0.0128 - val_accuracy: 0.2072\n",
      "Epoch 74/100\n",
      "57527/57527 [==============================] - 5s 89us/step - loss: 0.0136 - accuracy: 0.1588 - val_loss: 0.0126 - val_accuracy: 0.1911\n",
      "Epoch 75/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0136 - accuracy: 0.1553 - val_loss: 0.0126 - val_accuracy: 0.2194\n",
      "Epoch 76/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0136 - accuracy: 0.1559 - val_loss: 0.0125 - val_accuracy: 0.1980\n",
      "Epoch 77/100\n",
      "57527/57527 [==============================] - 5s 86us/step - loss: 0.0136 - accuracy: 0.1558 - val_loss: 0.0127 - val_accuracy: 0.2123\n",
      "Epoch 78/100\n",
      "57527/57527 [==============================] - 5s 86us/step - loss: 0.0135 - accuracy: 0.1563 - val_loss: 0.0126 - val_accuracy: 0.1676\n",
      "Epoch 79/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0135 - accuracy: 0.1554 - val_loss: 0.0126 - val_accuracy: 0.2071\n",
      "Epoch 80/100\n",
      "57527/57527 [==============================] - 5s 91us/step - loss: 0.0136 - accuracy: 0.1562 - val_loss: 0.0125 - val_accuracy: 0.1681\n",
      "Epoch 81/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0136 - accuracy: 0.1559 - val_loss: 0.0126 - val_accuracy: 0.1926\n",
      "Epoch 82/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0135 - accuracy: 0.1579 - val_loss: 0.0125 - val_accuracy: 0.2050\n",
      "Epoch 83/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0136 - accuracy: 0.1545 - val_loss: 0.0126 - val_accuracy: 0.1816\n",
      "Epoch 84/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0135 - accuracy: 0.1550 - val_loss: 0.0126 - val_accuracy: 0.1718\n",
      "Epoch 85/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0136 - accuracy: 0.1557 - val_loss: 0.0126 - val_accuracy: 0.2034\n",
      "Epoch 86/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0135 - accuracy: 0.1557 - val_loss: 0.0128 - val_accuracy: 0.2011\n",
      "Epoch 87/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0135 - accuracy: 0.1581 - val_loss: 0.0126 - val_accuracy: 0.1789\n",
      "Epoch 88/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0136 - accuracy: 0.1588 - val_loss: 0.0127 - val_accuracy: 0.1935\n",
      "Epoch 89/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0136 - accuracy: 0.1560 - val_loss: 0.0126 - val_accuracy: 0.2032\n",
      "Epoch 90/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0135 - accuracy: 0.1571 - val_loss: 0.0126 - val_accuracy: 0.1934\n",
      "Epoch 91/100\n",
      "57527/57527 [==============================] - 5s 86us/step - loss: 0.0135 - accuracy: 0.1571 - val_loss: 0.0126 - val_accuracy: 0.2080\n",
      "Epoch 92/100\n",
      "57527/57527 [==============================] - 5s 90us/step - loss: 0.0135 - accuracy: 0.1578 - val_loss: 0.0127 - val_accuracy: 0.2143\n",
      "Epoch 93/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0136 - accuracy: 0.1586 - val_loss: 0.0127 - val_accuracy: 0.2030\n",
      "Epoch 94/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0136 - accuracy: 0.1571 - val_loss: 0.0127 - val_accuracy: 0.1736\n",
      "Epoch 95/100\n",
      "57527/57527 [==============================] - 5s 86us/step - loss: 0.0136 - accuracy: 0.1582 - val_loss: 0.0128 - val_accuracy: 0.2132\n",
      "Epoch 96/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0135 - accuracy: 0.1558 - val_loss: 0.0125 - val_accuracy: 0.1761\n",
      "Epoch 97/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0135 - accuracy: 0.1568 - val_loss: 0.0127 - val_accuracy: 0.1827\n",
      "Epoch 98/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0136 - accuracy: 0.1587 - val_loss: 0.0128 - val_accuracy: 0.2054\n",
      "Epoch 99/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0136 - accuracy: 0.1575 - val_loss: 0.0127 - val_accuracy: 0.1864\n",
      "Epoch 100/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0135 - accuracy: 0.1578 - val_loss: 0.0126 - val_accuracy: 0.2227\n",
      "training model-18\n",
      "Train on 57527 samples, validate on 14382 samples\n",
      "Epoch 1/100\n",
      "57527/57527 [==============================] - 7s 127us/step - loss: 0.0253 - accuracy: 0.1565 - val_loss: 0.0167 - val_accuracy: 0.1633\n",
      "Epoch 2/100\n",
      "57527/57527 [==============================] - 5s 92us/step - loss: 0.0164 - accuracy: 0.1505 - val_loss: 0.0139 - val_accuracy: 0.1547\n",
      "Epoch 3/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0145 - accuracy: 0.1534 - val_loss: 0.0131 - val_accuracy: 0.1583\n",
      "Epoch 4/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0139 - accuracy: 0.1543 - val_loss: 0.0129 - val_accuracy: 0.1885\n",
      "Epoch 5/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0136 - accuracy: 0.1535 - val_loss: 0.0126 - val_accuracy: 0.1829\n",
      "Epoch 6/100\n",
      "57527/57527 [==============================] - 5s 89us/step - loss: 0.0135 - accuracy: 0.1527 - val_loss: 0.0127 - val_accuracy: 0.1751\n",
      "Epoch 7/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0134 - accuracy: 0.1538 - val_loss: 0.0126 - val_accuracy: 0.1864\n",
      "Epoch 8/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0133 - accuracy: 0.1526 - val_loss: 0.0128 - val_accuracy: 0.1810\n",
      "Epoch 9/100\n",
      "57527/57527 [==============================] - 5s 89us/step - loss: 0.0133 - accuracy: 0.1577 - val_loss: 0.0126 - val_accuracy: 0.1987\n",
      "Epoch 10/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0132 - accuracy: 0.1539 - val_loss: 0.0125 - val_accuracy: 0.1861\n",
      "Epoch 11/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0132 - accuracy: 0.1552 - val_loss: 0.0125 - val_accuracy: 0.1526\n",
      "Epoch 12/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0132 - accuracy: 0.1564 - val_loss: 0.0124 - val_accuracy: 0.2088\n",
      "Epoch 13/100\n",
      "57527/57527 [==============================] - 5s 89us/step - loss: 0.0131 - accuracy: 0.1552 - val_loss: 0.0124 - val_accuracy: 0.1998\n",
      "Epoch 14/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0131 - accuracy: 0.1546 - val_loss: 0.0124 - val_accuracy: 0.1875\n",
      "Epoch 15/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0131 - accuracy: 0.1568 - val_loss: 0.0124 - val_accuracy: 0.2057\n",
      "Epoch 16/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0131 - accuracy: 0.1585 - val_loss: 0.0124 - val_accuracy: 0.2196\n",
      "Epoch 17/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0131 - accuracy: 0.1566 - val_loss: 0.0124 - val_accuracy: 0.1493\n",
      "Epoch 18/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0131 - accuracy: 0.1604 - val_loss: 0.0123 - val_accuracy: 0.1975\n",
      "Epoch 19/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0131 - accuracy: 0.1559 - val_loss: 0.0123 - val_accuracy: 0.1937\n",
      "Epoch 20/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0130 - accuracy: 0.1594 - val_loss: 0.0124 - val_accuracy: 0.1996\n",
      "Epoch 21/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0130 - accuracy: 0.1573 - val_loss: 0.0123 - val_accuracy: 0.2094\n",
      "Epoch 22/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0130 - accuracy: 0.1586 - val_loss: 0.0124 - val_accuracy: 0.1852\n",
      "Epoch 23/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0130 - accuracy: 0.1560 - val_loss: 0.0124 - val_accuracy: 0.1749\n",
      "Epoch 24/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0130 - accuracy: 0.1570 - val_loss: 0.0123 - val_accuracy: 0.2044\n",
      "Epoch 25/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0130 - accuracy: 0.1583 - val_loss: 0.0123 - val_accuracy: 0.1608\n",
      "Epoch 26/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0130 - accuracy: 0.1572 - val_loss: 0.0123 - val_accuracy: 0.2060\n",
      "Epoch 27/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0130 - accuracy: 0.1593 - val_loss: 0.0123 - val_accuracy: 0.1939\n",
      "Epoch 28/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0130 - accuracy: 0.1557 - val_loss: 0.0123 - val_accuracy: 0.2003\n",
      "Epoch 29/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0130 - accuracy: 0.1577 - val_loss: 0.0124 - val_accuracy: 0.2071\n",
      "Epoch 30/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0130 - accuracy: 0.1581 - val_loss: 0.0122 - val_accuracy: 0.2158\n",
      "Epoch 31/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0130 - accuracy: 0.1564 - val_loss: 0.0123 - val_accuracy: 0.1991\n",
      "Epoch 32/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0130 - accuracy: 0.1579 - val_loss: 0.0123 - val_accuracy: 0.1585\n",
      "Epoch 33/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0129 - accuracy: 0.1574 - val_loss: 0.0123 - val_accuracy: 0.2133\n",
      "Epoch 34/100\n",
      "57527/57527 [==============================] - 5s 86us/step - loss: 0.0130 - accuracy: 0.1564 - val_loss: 0.0122 - val_accuracy: 0.2089\n",
      "Epoch 35/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0130 - accuracy: 0.1582 - val_loss: 0.0123 - val_accuracy: 0.1847\n",
      "Epoch 36/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0130 - accuracy: 0.1574 - val_loss: 0.0123 - val_accuracy: 0.2084\n",
      "Epoch 37/100\n",
      "57527/57527 [==============================] - 6s 97us/step - loss: 0.0130 - accuracy: 0.1565 - val_loss: 0.0123 - val_accuracy: 0.2199\n",
      "Epoch 38/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0130 - accuracy: 0.1565 - val_loss: 0.0123 - val_accuracy: 0.2148\n",
      "Epoch 39/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0130 - accuracy: 0.1598 - val_loss: 0.0123 - val_accuracy: 0.1878\n",
      "Epoch 40/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0130 - accuracy: 0.1579 - val_loss: 0.0123 - val_accuracy: 0.1510\n",
      "Epoch 41/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0130 - accuracy: 0.1593 - val_loss: 0.0123 - val_accuracy: 0.2047\n",
      "Epoch 42/100\n",
      "57527/57527 [==============================] - 5s 86us/step - loss: 0.0130 - accuracy: 0.1580 - val_loss: 0.0123 - val_accuracy: 0.1692\n",
      "Epoch 43/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0130 - accuracy: 0.1597 - val_loss: 0.0123 - val_accuracy: 0.1932\n",
      "Epoch 44/100\n",
      "57527/57527 [==============================] - 5s 86us/step - loss: 0.0130 - accuracy: 0.1564 - val_loss: 0.0122 - val_accuracy: 0.2070\n",
      "Epoch 45/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0129 - accuracy: 0.1588 - val_loss: 0.0123 - val_accuracy: 0.1669\n",
      "Epoch 46/100\n",
      "57527/57527 [==============================] - 5s 86us/step - loss: 0.0130 - accuracy: 0.1584 - val_loss: 0.0122 - val_accuracy: 0.1770\n",
      "Epoch 47/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0130 - accuracy: 0.1585 - val_loss: 0.0123 - val_accuracy: 0.2228\n",
      "Epoch 48/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0129 - accuracy: 0.1590 - val_loss: 0.0122 - val_accuracy: 0.2121\n",
      "Epoch 49/100\n",
      "57527/57527 [==============================] - 5s 91us/step - loss: 0.0129 - accuracy: 0.1602 - val_loss: 0.0123 - val_accuracy: 0.1666\n",
      "Epoch 50/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0129 - accuracy: 0.1579 - val_loss: 0.0123 - val_accuracy: 0.1904\n",
      "Epoch 51/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0129 - accuracy: 0.1600 - val_loss: 0.0122 - val_accuracy: 0.1888\n",
      "Epoch 52/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0129 - accuracy: 0.1588 - val_loss: 0.0122 - val_accuracy: 0.1833\n",
      "Epoch 53/100\n",
      "57527/57527 [==============================] - 5s 89us/step - loss: 0.0129 - accuracy: 0.1610 - val_loss: 0.0124 - val_accuracy: 0.1672\n",
      "Epoch 54/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0129 - accuracy: 0.1595 - val_loss: 0.0123 - val_accuracy: 0.1729\n",
      "Epoch 55/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0129 - accuracy: 0.1595 - val_loss: 0.0123 - val_accuracy: 0.1912\n",
      "Epoch 56/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0129 - accuracy: 0.1583 - val_loss: 0.0123 - val_accuracy: 0.1946\n",
      "Epoch 57/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0129 - accuracy: 0.1580 - val_loss: 0.0122 - val_accuracy: 0.1668\n",
      "Epoch 58/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0129 - accuracy: 0.1589 - val_loss: 0.0123 - val_accuracy: 0.1950\n",
      "Epoch 59/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0129 - accuracy: 0.1602 - val_loss: 0.0123 - val_accuracy: 0.2281\n",
      "Epoch 60/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0129 - accuracy: 0.1624 - val_loss: 0.0123 - val_accuracy: 0.1890\n",
      "Epoch 61/100\n",
      "57527/57527 [==============================] - 5s 89us/step - loss: 0.0129 - accuracy: 0.1608 - val_loss: 0.0123 - val_accuracy: 0.2149\n",
      "Epoch 62/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0129 - accuracy: 0.1601 - val_loss: 0.0122 - val_accuracy: 0.1774\n",
      "Epoch 63/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0129 - accuracy: 0.1618 - val_loss: 0.0123 - val_accuracy: 0.1907\n",
      "Epoch 64/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0129 - accuracy: 0.1593 - val_loss: 0.0122 - val_accuracy: 0.2036\n",
      "Epoch 65/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0129 - accuracy: 0.1587 - val_loss: 0.0122 - val_accuracy: 0.2006\n",
      "Epoch 66/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0129 - accuracy: 0.1603 - val_loss: 0.0123 - val_accuracy: 0.1614\n",
      "Epoch 67/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0129 - accuracy: 0.1602 - val_loss: 0.0122 - val_accuracy: 0.1927\n",
      "Epoch 68/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0129 - accuracy: 0.1590 - val_loss: 0.0122 - val_accuracy: 0.1924\n",
      "Epoch 69/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0129 - accuracy: 0.1590 - val_loss: 0.0122 - val_accuracy: 0.2018\n",
      "Epoch 70/100\n",
      "57527/57527 [==============================] - 5s 89us/step - loss: 0.0129 - accuracy: 0.1590 - val_loss: 0.0123 - val_accuracy: 0.1639\n",
      "Epoch 71/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0129 - accuracy: 0.1582 - val_loss: 0.0122 - val_accuracy: 0.1867\n",
      "Epoch 72/100\n",
      "57527/57527 [==============================] - 5s 87us/step - loss: 0.0129 - accuracy: 0.1612 - val_loss: 0.0122 - val_accuracy: 0.2041\n",
      "Epoch 73/100\n",
      "57527/57527 [==============================] - 6s 100us/step - loss: 0.0129 - accuracy: 0.1596 - val_loss: 0.0123 - val_accuracy: 0.1970\n",
      "Epoch 74/100\n",
      "57527/57527 [==============================] - 5s 88us/step - loss: 0.0129 - accuracy: 0.1596 - val_loss: 0.0122 - val_accuracy: 0.1961\n",
      "Epoch 75/100\n",
      "15456/57527 [=======>......................] - ETA: 3s - loss: 0.0128 - accuracy: 0.1612"
     ]
    }
   ],
   "source": [
    "for model_name, model in models_1st_layer.items():\n",
    "    print('training ' + model_name)\n",
    "    model.fit(X_train, Y_train, validation_data = (X_val, Y_val), epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57527 samples, validate on 14382 samples\n",
      "Epoch 1/80\n",
      "57527/57527 [==============================] - 3s 59us/step - loss: 0.1444 - accuracy: 0.1692 - val_loss: 0.1430 - val_accuracy: 0.1813\n",
      "Epoch 2/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1433 - accuracy: 0.1602 - val_loss: 0.1427 - val_accuracy: 0.1506\n",
      "Epoch 3/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1430 - accuracy: 0.1629 - val_loss: 0.1425 - val_accuracy: 0.1887\n",
      "Epoch 4/80\n",
      "57527/57527 [==============================] - 3s 44us/step - loss: 0.1429 - accuracy: 0.1693 - val_loss: 0.1425 - val_accuracy: 0.1486\n",
      "Epoch 5/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1429 - accuracy: 0.1741 - val_loss: 0.1424 - val_accuracy: 0.1626\n",
      "Epoch 6/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1428 - accuracy: 0.1755 - val_loss: 0.1424 - val_accuracy: 0.1896\n",
      "Epoch 7/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1428 - accuracy: 0.1765 - val_loss: 0.1424 - val_accuracy: 0.1865\n",
      "Epoch 8/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1428 - accuracy: 0.1766 - val_loss: 0.1424 - val_accuracy: 0.1854\n",
      "Epoch 9/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1428 - accuracy: 0.1777 - val_loss: 0.1423 - val_accuracy: 0.1982\n",
      "Epoch 10/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1428 - accuracy: 0.1798 - val_loss: 0.1423 - val_accuracy: 0.2027\n",
      "Epoch 11/80\n",
      "57527/57527 [==============================] - 3s 44us/step - loss: 0.1428 - accuracy: 0.1786 - val_loss: 0.1423 - val_accuracy: 0.1850\n",
      "Epoch 12/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1428 - accuracy: 0.1794 - val_loss: 0.1423 - val_accuracy: 0.1843\n",
      "Epoch 13/80\n",
      "57527/57527 [==============================] - 3s 44us/step - loss: 0.1427 - accuracy: 0.1824 - val_loss: 0.1423 - val_accuracy: 0.1847\n",
      "Epoch 14/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1839 - val_loss: 0.1423 - val_accuracy: 0.1936\n",
      "Epoch 15/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1852 - val_loss: 0.1423 - val_accuracy: 0.1964\n",
      "Epoch 16/80\n",
      "57527/57527 [==============================] - 3s 44us/step - loss: 0.1427 - accuracy: 0.1872 - val_loss: 0.1423 - val_accuracy: 0.1746\n",
      "Epoch 17/80\n",
      "57527/57527 [==============================] - 3s 44us/step - loss: 0.1427 - accuracy: 0.1879 - val_loss: 0.1423 - val_accuracy: 0.1948\n",
      "Epoch 18/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1862 - val_loss: 0.1423 - val_accuracy: 0.2138\n",
      "Epoch 19/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1865 - val_loss: 0.1423 - val_accuracy: 0.1713\n",
      "Epoch 20/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1890 - val_loss: 0.1423 - val_accuracy: 0.1910\n",
      "Epoch 21/80\n",
      "57527/57527 [==============================] - 3s 44us/step - loss: 0.1427 - accuracy: 0.1918 - val_loss: 0.1423 - val_accuracy: 0.2064\n",
      "Epoch 22/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1922 - val_loss: 0.1423 - val_accuracy: 0.2075\n",
      "Epoch 23/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1910 - val_loss: 0.1423 - val_accuracy: 0.2032\n",
      "Epoch 24/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1911 - val_loss: 0.1423 - val_accuracy: 0.2076\n",
      "Epoch 25/80\n",
      "57527/57527 [==============================] - 3s 44us/step - loss: 0.1427 - accuracy: 0.1918 - val_loss: 0.1423 - val_accuracy: 0.1783\n",
      "Epoch 26/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1893 - val_loss: 0.1423 - val_accuracy: 0.1961\n",
      "Epoch 27/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1897 - val_loss: 0.1423 - val_accuracy: 0.2006\n",
      "Epoch 28/80\n",
      "57527/57527 [==============================] - 3s 44us/step - loss: 0.1427 - accuracy: 0.1927 - val_loss: 0.1423 - val_accuracy: 0.1980\n",
      "Epoch 29/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1916 - val_loss: 0.1423 - val_accuracy: 0.2113\n",
      "Epoch 30/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1908 - val_loss: 0.1423 - val_accuracy: 0.2198\n",
      "Epoch 31/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1917 - val_loss: 0.1423 - val_accuracy: 0.1809\n",
      "Epoch 32/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1911 - val_loss: 0.1423 - val_accuracy: 0.2152\n",
      "Epoch 33/80\n",
      "57527/57527 [==============================] - 3s 44us/step - loss: 0.1427 - accuracy: 0.1920 - val_loss: 0.1423 - val_accuracy: 0.2115\n",
      "Epoch 34/80\n",
      "57527/57527 [==============================] - 3s 44us/step - loss: 0.1427 - accuracy: 0.1922 - val_loss: 0.1423 - val_accuracy: 0.2166\n",
      "Epoch 35/80\n",
      "57527/57527 [==============================] - 3s 44us/step - loss: 0.1427 - accuracy: 0.1932 - val_loss: 0.1423 - val_accuracy: 0.1996\n",
      "Epoch 36/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1937 - val_loss: 0.1423 - val_accuracy: 0.1876\n",
      "Epoch 37/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1935 - val_loss: 0.1423 - val_accuracy: 0.2223\n",
      "Epoch 38/80\n",
      "57527/57527 [==============================] - 3s 44us/step - loss: 0.1427 - accuracy: 0.1940 - val_loss: 0.1423 - val_accuracy: 0.1929\n",
      "Epoch 39/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1945 - val_loss: 0.1423 - val_accuracy: 0.2249\n",
      "Epoch 40/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1922 - val_loss: 0.1423 - val_accuracy: 0.2041\n",
      "Epoch 41/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1939 - val_loss: 0.1423 - val_accuracy: 0.2248\n",
      "Epoch 42/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1944 - val_loss: 0.1423 - val_accuracy: 0.2085\n",
      "Epoch 43/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1944 - val_loss: 0.1423 - val_accuracy: 0.2076\n",
      "Epoch 44/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1954 - val_loss: 0.1423 - val_accuracy: 0.1999\n",
      "Epoch 45/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1945 - val_loss: 0.1423 - val_accuracy: 0.1905\n",
      "Epoch 46/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1966 - val_loss: 0.1423 - val_accuracy: 0.2110\n",
      "Epoch 47/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1956 - val_loss: 0.1423 - val_accuracy: 0.2274\n",
      "Epoch 48/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1948 - val_loss: 0.1423 - val_accuracy: 0.2226\n",
      "Epoch 49/80\n",
      "57527/57527 [==============================] - 3s 44us/step - loss: 0.1427 - accuracy: 0.1964 - val_loss: 0.1423 - val_accuracy: 0.1934\n",
      "Epoch 50/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1978 - val_loss: 0.1423 - val_accuracy: 0.2135\n",
      "Epoch 51/80\n",
      "57527/57527 [==============================] - 3s 44us/step - loss: 0.1427 - accuracy: 0.1946 - val_loss: 0.1423 - val_accuracy: 0.1972\n",
      "Epoch 52/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1970 - val_loss: 0.1423 - val_accuracy: 0.2020\n",
      "Epoch 53/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1967 - val_loss: 0.1423 - val_accuracy: 0.2077\n",
      "Epoch 54/80\n",
      "57527/57527 [==============================] - 3s 47us/step - loss: 0.1427 - accuracy: 0.1973 - val_loss: 0.1423 - val_accuracy: 0.2267\n",
      "Epoch 55/80\n",
      "57527/57527 [==============================] - 3s 47us/step - loss: 0.1427 - accuracy: 0.1963 - val_loss: 0.1423 - val_accuracy: 0.2133\n",
      "Epoch 56/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1976 - val_loss: 0.1423 - val_accuracy: 0.1942\n",
      "Epoch 57/80\n",
      "57527/57527 [==============================] - 3s 44us/step - loss: 0.1427 - accuracy: 0.1989 - val_loss: 0.1423 - val_accuracy: 0.2200\n",
      "Epoch 58/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1979 - val_loss: 0.1423 - val_accuracy: 0.2204\n",
      "Epoch 59/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1987 - val_loss: 0.1423 - val_accuracy: 0.1721\n",
      "Epoch 60/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1996 - val_loss: 0.1423 - val_accuracy: 0.2194\n",
      "Epoch 61/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1975 - val_loss: 0.1423 - val_accuracy: 0.2215\n",
      "Epoch 62/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1976 - val_loss: 0.1423 - val_accuracy: 0.1949\n",
      "Epoch 63/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1969 - val_loss: 0.1423 - val_accuracy: 0.1830\n",
      "Epoch 64/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1993 - val_loss: 0.1423 - val_accuracy: 0.2123\n",
      "Epoch 65/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.2004 - val_loss: 0.1423 - val_accuracy: 0.2230\n",
      "Epoch 66/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1970 - val_loss: 0.1423 - val_accuracy: 0.2242\n",
      "Epoch 67/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1994 - val_loss: 0.1423 - val_accuracy: 0.2025\n",
      "Epoch 68/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1982 - val_loss: 0.1423 - val_accuracy: 0.2090\n",
      "Epoch 69/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1991 - val_loss: 0.1423 - val_accuracy: 0.1761\n",
      "Epoch 70/80\n",
      "57527/57527 [==============================] - 3s 44us/step - loss: 0.1427 - accuracy: 0.1995 - val_loss: 0.1423 - val_accuracy: 0.1950\n",
      "Epoch 71/80\n",
      "57527/57527 [==============================] - 3s 44us/step - loss: 0.1427 - accuracy: 0.1975 - val_loss: 0.1423 - val_accuracy: 0.2075\n",
      "Epoch 72/80\n",
      "57527/57527 [==============================] - 3s 44us/step - loss: 0.1427 - accuracy: 0.2005 - val_loss: 0.1423 - val_accuracy: 0.2012\n",
      "Epoch 73/80\n",
      "57527/57527 [==============================] - 3s 44us/step - loss: 0.1427 - accuracy: 0.1955 - val_loss: 0.1423 - val_accuracy: 0.2207\n",
      "Epoch 74/80\n",
      "57527/57527 [==============================] - 3s 44us/step - loss: 0.1427 - accuracy: 0.1995 - val_loss: 0.1423 - val_accuracy: 0.2277\n",
      "Epoch 75/80\n",
      "57527/57527 [==============================] - 3s 44us/step - loss: 0.1427 - accuracy: 0.1990 - val_loss: 0.1423 - val_accuracy: 0.2215\n",
      "Epoch 76/80\n",
      "57527/57527 [==============================] - 3s 44us/step - loss: 0.1427 - accuracy: 0.1987 - val_loss: 0.1423 - val_accuracy: 0.2082\n",
      "Epoch 77/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1989 - val_loss: 0.1423 - val_accuracy: 0.2092\n",
      "Epoch 78/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1981 - val_loss: 0.1423 - val_accuracy: 0.2201\n",
      "Epoch 79/80\n",
      "57527/57527 [==============================] - 3s 44us/step - loss: 0.1427 - accuracy: 0.1985 - val_loss: 0.1423 - val_accuracy: 0.2176\n",
      "Epoch 80/80\n",
      "57527/57527 [==============================] - 3s 45us/step - loss: 0.1427 - accuracy: 0.1987 - val_loss: 0.1423 - val_accuracy: 0.2151\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, validation_data = (X_val, Y_val), epochs=80, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss']) \n",
    "plt.plot(history.history['val_loss']) \n",
    "plt.title('Model loss') \n",
    "plt.ylabel('Loss') \n",
    "plt.xlabel('Epoch') \n",
    "plt.legend(['Train', 'Test'], loc='upper right') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Save Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Convert your existing model to JSON\n",
    "saved_model = model.to_json()\n",
    "\n",
    "# Write JSON object to S3 as \"keras-model.json\"\n",
    "client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'BFE2AC49A7F2C1AE',\n",
       "  'HostId': 'htVLb3Ts8AwrM5iGZ+G8akpn586sjnGX8IOomy0pIJdqls8HO334uJC/qAAWbVsQvdTDJd04TbE=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'htVLb3Ts8AwrM5iGZ+G8akpn586sjnGX8IOomy0pIJdqls8HO334uJC/qAAWbVsQvdTDJd04TbE=',\n",
       "   'x-amz-request-id': 'BFE2AC49A7F2C1AE',\n",
       "   'date': 'Sun, 29 Dec 2019 01:43:23 GMT',\n",
       "   'etag': '\"5ea0fa74db07e5b96396412f5cb64961\"',\n",
       "   'content-length': '0',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"5ea0fa74db07e5b96396412f5cb64961\"'}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.put_object(Body=saved_model,\n",
    "                  Bucket='bme-bucket',\n",
    "                  Key='models/keras-model-8.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>method 2</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import io\n",
    "import pickle\n",
    "\n",
    "s3_client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array_data = io.BytesIO()\n",
    "pickle.dump(FITTED_ESTIMATORS, my_array_data)\n",
    "my_array_data.seek(0)\n",
    "s3_client.upload_fileobj(my_array_data, 'bme-bucket', 'models/experiment-0/2nd-layer-models/models_dict.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
